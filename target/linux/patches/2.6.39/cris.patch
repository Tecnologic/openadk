diff -Nur linux-2.6.39.orig/arch/cris/arch-v10/drivers/axisflashmap.c linux-2.6.39/arch/cris/arch-v10/drivers/axisflashmap.c
--- linux-2.6.39.orig/arch/cris/arch-v10/drivers/axisflashmap.c	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/arch-v10/drivers/axisflashmap.c	2011-07-28 16:16:35.633425525 +0200
@@ -113,7 +113,7 @@
 
 /* If no partition-table was found, we use this default-set. */
 #define MAX_PARTITIONS         7
-#define NUM_DEFAULT_PARTITIONS 3
+#define NUM_DEFAULT_PARTITIONS 4
 
 /*
  * Default flash size is 2MB. CONFIG_ETRAX_PTABLE_SECTOR is most likely the
@@ -122,19 +122,24 @@
  */
 static struct mtd_partition axis_default_partitions[NUM_DEFAULT_PARTITIONS] = {
 	{
-		.name = "boot firmware",
-		.size = CONFIG_ETRAX_PTABLE_SECTOR,
+		.name = "kernel",
+		.size = 0x00,
 		.offset = 0
 	},
 	{
-		.name = "kernel",
-		.size = 0x200000 - (6 * CONFIG_ETRAX_PTABLE_SECTOR),
-		.offset = CONFIG_ETRAX_PTABLE_SECTOR
+		.name = "rootfs",
+		.size = 0x200000 ,
+		.offset = 0x200000
+	},
+	{
+		.name = "cfgfs",
+		.size = 0x20000 ,
+		.offset = CONFIG_ETRAX_MTD_SIZE - 0x20000
 	},
 	{
-		.name = "filesystem",
-		.size = 5 * CONFIG_ETRAX_PTABLE_SECTOR,
-		.offset = 0x200000 - (5 * CONFIG_ETRAX_PTABLE_SECTOR)
+		.name = "linux",
+		.size = CONFIG_ETRAX_MTD_SIZE - 0x20000,
+		.offset = 0
 	}
 };
 
@@ -275,6 +280,11 @@
 	struct partitiontable_entry *ptable;
 	int use_default_ptable = 1; /* Until proven otherwise. */
 	const char pmsg[] = "  /dev/flash%d at 0x%08x, size 0x%08x\n";
+	unsigned int kernel_part_size = 0;
+	unsigned char *flash_mem = (unsigned char*)(FLASH_CACHED_ADDR);
+	unsigned int flash_scan_count = 0;
+	const char *part_magic = "ACME_PART_MAGIC";
+	unsigned int magic_len = strlen(part_magic);
 
 	if (!(mymtd = flash_probe())) {
 		/* There's no reason to use this module if no flash chip can
@@ -286,6 +296,31 @@
 		       mymtd->name, mymtd->size);
 		axisflash_mtd = mymtd;
 	}
+	/* scan flash to findout where out partition starts */
+
+	printk(KERN_INFO "Scanning flash for end of kernel magic\n");
+	for(flash_scan_count = 0; flash_scan_count < 100000; flash_scan_count++){
+		if(strncmp(&flash_mem[flash_scan_count], part_magic, magic_len - 1) == 0)
+		{
+			kernel_part_size = flash_mem[flash_scan_count + magic_len ];
+			kernel_part_size <<= 8;
+			kernel_part_size += flash_mem[flash_scan_count + magic_len + 2];
+			kernel_part_size <<= 8;
+			kernel_part_size += flash_mem[flash_scan_count + magic_len + 1];
+			kernel_part_size <<= 8;
+			kernel_part_size += flash_mem[flash_scan_count + magic_len + 3];
+			printk(KERN_INFO "Kernel ends at 0x%.08X\n", kernel_part_size);
+			flash_scan_count = 1100000;
+		}
+	}
+
+
+	if(kernel_part_size){
+		kernel_part_size = (kernel_part_size & 0xffff0000);
+		axis_default_partitions[0].size = kernel_part_size;
+		axis_default_partitions[1].size =  mymtd->size - axis_default_partitions[0].size - axis_default_partitions[2].size;
+		axis_default_partitions[1].offset = axis_default_partitions[0].size;
+	}
 
 	if (mymtd) {
 		mymtd->owner = THIS_MODULE;
@@ -354,21 +389,6 @@
 		use_default_ptable = !ptable_ok;
 	}
 
-	if (romfs_in_flash) {
-		/* Add an overlapping device for the root partition (romfs). */
-
-		axis_partitions[pidx].name = "romfs";
-		axis_partitions[pidx].size = romfs_length;
-		axis_partitions[pidx].offset = romfs_start - FLASH_CACHED_ADDR;
-		axis_partitions[pidx].mask_flags |= MTD_WRITEABLE;
-
-		printk(KERN_INFO
-                       " Adding readonly flash partition for romfs image:\n");
-		printk(pmsg, pidx, axis_partitions[pidx].offset,
-		       axis_partitions[pidx].size);
-		pidx++;
-	}
-
 #ifdef CONFIG_ETRAX_AXISFLASHMAP_MTD0WHOLE
 	if (mymtd) {
 		main_partition.size = mymtd->size;
@@ -391,36 +411,6 @@
 		if (err)
 			panic("axisflashmap could not add MTD partitions!\n");
 	}
-
-	if (!romfs_in_flash) {
-		/* Create an RAM device for the root partition (romfs). */
-
-#if !defined(CONFIG_MTD_MTDRAM) || (CONFIG_MTDRAM_TOTAL_SIZE != 0) || (CONFIG_MTDRAM_ABS_POS != 0)
-		/* No use trying to boot this kernel from RAM. Panic! */
-		printk(KERN_EMERG "axisflashmap: Cannot create an MTD RAM "
-		       "device due to kernel (mis)configuration!\n");
-		panic("This kernel cannot boot from RAM!\n");
-#else
-		struct mtd_info *mtd_ram;
-
-		mtd_ram = kmalloc(sizeof(struct mtd_info), GFP_KERNEL);
-		if (!mtd_ram)
-			panic("axisflashmap couldn't allocate memory for "
-			      "mtd_info!\n");
-
-		printk(KERN_INFO " Adding RAM partition for romfs image:\n");
-		printk(pmsg, pidx, (unsigned)romfs_start,
-			(unsigned)romfs_length);
-
-		err = mtdram_init_device(mtd_ram,
-			(void *)romfs_start,
-			romfs_length,
-			"romfs");
-		if (err)
-			panic("axisflashmap could not initialize MTD RAM "
-			      "device!\n");
-#endif
-	}
 	return err;
 }
 
diff -Nur linux-2.6.39.orig/arch/cris/arch-v10/drivers/axisflashmap.c.orig linux-2.6.39/arch/cris/arch-v10/drivers/axisflashmap.c.orig
--- linux-2.6.39.orig/arch/cris/arch-v10/drivers/axisflashmap.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.39/arch/cris/arch-v10/drivers/axisflashmap.c.orig	2011-05-19 06:06:34.000000000 +0200
@@ -0,0 +1,430 @@
+/*
+ * Physical mapping layer for MTD using the Axis partitiontable format
+ *
+ * Copyright (c) 2001, 2002 Axis Communications AB
+ *
+ * This file is under the GPL.
+ *
+ * First partition is always sector 0 regardless of if we find a partitiontable
+ * or not. In the start of the next sector, there can be a partitiontable that
+ * tells us what other partitions to define. If there isn't, we use a default
+ * partition split defined below.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+
+#include <linux/mtd/concat.h>
+#include <linux/mtd/map.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/mtdram.h>
+#include <linux/mtd/partitions.h>
+
+#include <asm/axisflashmap.h>
+#include <asm/mmu.h>
+#include <arch/sv_addr_ag.h>
+
+#ifdef CONFIG_CRIS_LOW_MAP
+#define FLASH_UNCACHED_ADDR  KSEG_8
+#define FLASH_CACHED_ADDR    KSEG_5
+#else
+#define FLASH_UNCACHED_ADDR  KSEG_E
+#define FLASH_CACHED_ADDR    KSEG_F
+#endif
+
+#if CONFIG_ETRAX_FLASH_BUSWIDTH==1
+#define flash_data __u8
+#elif CONFIG_ETRAX_FLASH_BUSWIDTH==2
+#define flash_data __u16
+#elif CONFIG_ETRAX_FLASH_BUSWIDTH==4
+#define flash_data __u32
+#endif
+
+/* From head.S */
+extern unsigned long romfs_start, romfs_length, romfs_in_flash;
+
+/* The master mtd for the entire flash. */
+struct mtd_info* axisflash_mtd = NULL;
+
+/* Map driver functions. */
+
+static map_word flash_read(struct map_info *map, unsigned long ofs)
+{
+	map_word tmp;
+	tmp.x[0] = *(flash_data *)(map->map_priv_1 + ofs);
+	return tmp;
+}
+
+static void flash_copy_from(struct map_info *map, void *to,
+			    unsigned long from, ssize_t len)
+{
+	memcpy(to, (void *)(map->map_priv_1 + from), len);
+}
+
+static void flash_write(struct map_info *map, map_word d, unsigned long adr)
+{
+	*(flash_data *)(map->map_priv_1 + adr) = (flash_data)d.x[0];
+}
+
+/*
+ * The map for chip select e0.
+ *
+ * We run into tricky coherence situations if we mix cached with uncached
+ * accesses to we only use the uncached version here.
+ *
+ * The size field is the total size where the flash chips may be mapped on the
+ * chip select. MTD probes should find all devices there and it does not matter
+ * if there are unmapped gaps or aliases (mirrors of flash devices). The MTD
+ * probes will ignore them.
+ *
+ * The start address in map_priv_1 is in virtual memory so we cannot use
+ * MEM_CSE0_START but must rely on that FLASH_UNCACHED_ADDR is the start
+ * address of cse0.
+ */
+static struct map_info map_cse0 = {
+	.name = "cse0",
+	.size = MEM_CSE0_SIZE,
+	.bankwidth = CONFIG_ETRAX_FLASH_BUSWIDTH,
+	.read = flash_read,
+	.copy_from = flash_copy_from,
+	.write = flash_write,
+	.map_priv_1 = FLASH_UNCACHED_ADDR
+};
+
+/*
+ * The map for chip select e1.
+ *
+ * If there was a gap between cse0 and cse1, map_priv_1 would get the wrong
+ * address, but there isn't.
+ */
+static struct map_info map_cse1 = {
+	.name = "cse1",
+	.size = MEM_CSE1_SIZE,
+	.bankwidth = CONFIG_ETRAX_FLASH_BUSWIDTH,
+	.read = flash_read,
+	.copy_from = flash_copy_from,
+	.write = flash_write,
+	.map_priv_1 = FLASH_UNCACHED_ADDR + MEM_CSE0_SIZE
+};
+
+/* If no partition-table was found, we use this default-set. */
+#define MAX_PARTITIONS         7
+#define NUM_DEFAULT_PARTITIONS 3
+
+/*
+ * Default flash size is 2MB. CONFIG_ETRAX_PTABLE_SECTOR is most likely the
+ * size of one flash block and "filesystem"-partition needs 5 blocks to be able
+ * to use JFFS.
+ */
+static struct mtd_partition axis_default_partitions[NUM_DEFAULT_PARTITIONS] = {
+	{
+		.name = "boot firmware",
+		.size = CONFIG_ETRAX_PTABLE_SECTOR,
+		.offset = 0
+	},
+	{
+		.name = "kernel",
+		.size = 0x200000 - (6 * CONFIG_ETRAX_PTABLE_SECTOR),
+		.offset = CONFIG_ETRAX_PTABLE_SECTOR
+	},
+	{
+		.name = "filesystem",
+		.size = 5 * CONFIG_ETRAX_PTABLE_SECTOR,
+		.offset = 0x200000 - (5 * CONFIG_ETRAX_PTABLE_SECTOR)
+	}
+};
+
+/* Initialize the ones normally used. */
+static struct mtd_partition axis_partitions[MAX_PARTITIONS] = {
+	{
+		.name = "part0",
+		.size = CONFIG_ETRAX_PTABLE_SECTOR,
+		.offset = 0
+	},
+	{
+		.name = "part1",
+		.size = 0,
+		.offset = 0
+	},
+	{
+		.name = "part2",
+		.size = 0,
+		.offset = 0
+	},
+	{
+		.name = "part3",
+		.size = 0,
+		.offset = 0
+	},
+	{
+		.name = "part4",
+		.size = 0,
+		.offset = 0
+	},
+	{
+		.name = "part5",
+		.size = 0,
+		.offset = 0
+	},
+	{
+		.name = "part6",
+		.size = 0,
+		.offset = 0
+	},
+};
+
+#ifdef CONFIG_ETRAX_AXISFLASHMAP_MTD0WHOLE
+/* Main flash device */
+static struct mtd_partition main_partition = {
+	.name = "main",
+	.size = 0,
+	.offset = 0
+};
+#endif
+
+/*
+ * Probe a chip select for AMD-compatible (JEDEC) or CFI-compatible flash
+ * chips in that order (because the amd_flash-driver is faster).
+ */
+static struct mtd_info *probe_cs(struct map_info *map_cs)
+{
+	struct mtd_info *mtd_cs = NULL;
+
+	printk(KERN_INFO
+               "%s: Probing a 0x%08lx bytes large window at 0x%08lx.\n",
+	       map_cs->name, map_cs->size, map_cs->map_priv_1);
+
+#ifdef CONFIG_MTD_CFI
+	mtd_cs = do_map_probe("cfi_probe", map_cs);
+#endif
+#ifdef CONFIG_MTD_JEDECPROBE
+	if (!mtd_cs)
+		mtd_cs = do_map_probe("jedec_probe", map_cs);
+#endif
+
+	return mtd_cs;
+}
+
+/*
+ * Probe each chip select individually for flash chips. If there are chips on
+ * both cse0 and cse1, the mtd_info structs will be concatenated to one struct
+ * so that MTD partitions can cross chip boundries.
+ *
+ * The only known restriction to how you can mount your chips is that each
+ * chip select must hold similar flash chips. But you need external hardware
+ * to do that anyway and you can put totally different chips on cse0 and cse1
+ * so it isn't really much of a restriction.
+ */
+static struct mtd_info *flash_probe(void)
+{
+	struct mtd_info *mtd_cse0;
+	struct mtd_info *mtd_cse1;
+	struct mtd_info *mtd_cse;
+
+	mtd_cse0 = probe_cs(&map_cse0);
+	mtd_cse1 = probe_cs(&map_cse1);
+
+	if (!mtd_cse0 && !mtd_cse1) {
+		/* No chip found. */
+		return NULL;
+	}
+
+	if (mtd_cse0 && mtd_cse1) {
+		struct mtd_info *mtds[] = { mtd_cse0, mtd_cse1 };
+
+		/* Since the concatenation layer adds a small overhead we
+		 * could try to figure out if the chips in cse0 and cse1 are
+		 * identical and reprobe the whole cse0+cse1 window. But since
+		 * flash chips are slow, the overhead is relatively small.
+		 * So we use the MTD concatenation layer instead of further
+		 * complicating the probing procedure.
+		 */
+		mtd_cse = mtd_concat_create(mtds, ARRAY_SIZE(mtds),
+					    "cse0+cse1");
+		if (!mtd_cse) {
+			printk(KERN_ERR "%s and %s: Concatenation failed!\n",
+			       map_cse0.name, map_cse1.name);
+
+			/* The best we can do now is to only use what we found
+			 * at cse0.
+			 */
+			mtd_cse = mtd_cse0;
+			map_destroy(mtd_cse1);
+		}
+	} else {
+		mtd_cse = mtd_cse0? mtd_cse0 : mtd_cse1;
+	}
+
+	return mtd_cse;
+}
+
+/*
+ * Probe the flash chip(s) and, if it succeeds, read the partition-table
+ * and register the partitions with MTD.
+ */
+static int __init init_axis_flash(void)
+{
+	struct mtd_info *mymtd;
+	int err = 0;
+	int pidx = 0;
+	struct partitiontable_head *ptable_head = NULL;
+	struct partitiontable_entry *ptable;
+	int use_default_ptable = 1; /* Until proven otherwise. */
+	const char pmsg[] = "  /dev/flash%d at 0x%08x, size 0x%08x\n";
+
+	if (!(mymtd = flash_probe())) {
+		/* There's no reason to use this module if no flash chip can
+		 * be identified. Make sure that's understood.
+		 */
+		printk(KERN_INFO "axisflashmap: Found no flash chip.\n");
+	} else {
+		printk(KERN_INFO "%s: 0x%08x bytes of flash memory.\n",
+		       mymtd->name, mymtd->size);
+		axisflash_mtd = mymtd;
+	}
+
+	if (mymtd) {
+		mymtd->owner = THIS_MODULE;
+		ptable_head = (struct partitiontable_head *)(FLASH_CACHED_ADDR +
+			      CONFIG_ETRAX_PTABLE_SECTOR +
+			      PARTITION_TABLE_OFFSET);
+	}
+	pidx++;  /* First partition is always set to the default. */
+
+	if (ptable_head && (ptable_head->magic == PARTITION_TABLE_MAGIC)
+	    && (ptable_head->size <
+		(MAX_PARTITIONS * sizeof(struct partitiontable_entry) +
+		PARTITIONTABLE_END_MARKER_SIZE))
+	    && (*(unsigned long*)((void*)ptable_head + sizeof(*ptable_head) +
+				  ptable_head->size -
+				  PARTITIONTABLE_END_MARKER_SIZE)
+		== PARTITIONTABLE_END_MARKER)) {
+		/* Looks like a start, sane length and end of a
+		 * partition table, lets check csum etc.
+		 */
+		int ptable_ok = 0;
+		struct partitiontable_entry *max_addr =
+			(struct partitiontable_entry *)
+			((unsigned long)ptable_head + sizeof(*ptable_head) +
+			 ptable_head->size);
+		unsigned long offset = CONFIG_ETRAX_PTABLE_SECTOR;
+		unsigned char *p;
+		unsigned long csum = 0;
+
+		ptable = (struct partitiontable_entry *)
+			((unsigned long)ptable_head + sizeof(*ptable_head));
+
+		/* Lets be PARANOID, and check the checksum. */
+		p = (unsigned char*) ptable;
+
+		while (p <= (unsigned char*)max_addr) {
+			csum += *p++;
+			csum += *p++;
+			csum += *p++;
+			csum += *p++;
+		}
+		ptable_ok = (csum == ptable_head->checksum);
+
+		/* Read the entries and use/show the info.  */
+		printk(KERN_INFO " Found a%s partition table at 0x%p-0x%p.\n",
+		       (ptable_ok ? " valid" : "n invalid"), ptable_head,
+		       max_addr);
+
+		/* We have found a working bootblock.  Now read the
+		 * partition table.  Scan the table.  It ends when
+		 * there is 0xffffffff, that is, empty flash.
+		 */
+		while (ptable_ok
+		       && ptable->offset != 0xffffffff
+		       && ptable < max_addr
+		       && pidx < MAX_PARTITIONS) {
+
+			axis_partitions[pidx].offset = offset + ptable->offset;
+			axis_partitions[pidx].size = ptable->size;
+
+			printk(pmsg, pidx, axis_partitions[pidx].offset,
+			       axis_partitions[pidx].size);
+			pidx++;
+			ptable++;
+		}
+		use_default_ptable = !ptable_ok;
+	}
+
+	if (romfs_in_flash) {
+		/* Add an overlapping device for the root partition (romfs). */
+
+		axis_partitions[pidx].name = "romfs";
+		axis_partitions[pidx].size = romfs_length;
+		axis_partitions[pidx].offset = romfs_start - FLASH_CACHED_ADDR;
+		axis_partitions[pidx].mask_flags |= MTD_WRITEABLE;
+
+		printk(KERN_INFO
+                       " Adding readonly flash partition for romfs image:\n");
+		printk(pmsg, pidx, axis_partitions[pidx].offset,
+		       axis_partitions[pidx].size);
+		pidx++;
+	}
+
+#ifdef CONFIG_ETRAX_AXISFLASHMAP_MTD0WHOLE
+	if (mymtd) {
+		main_partition.size = mymtd->size;
+		err = add_mtd_partitions(mymtd, &main_partition, 1);
+		if (err)
+			panic("axisflashmap: Could not initialize "
+			      "partition for whole main mtd device!\n");
+	}
+#endif
+
+        if (mymtd) {
+		if (use_default_ptable) {
+			printk(KERN_INFO " Using default partition table.\n");
+			err = add_mtd_partitions(mymtd, axis_default_partitions,
+						 NUM_DEFAULT_PARTITIONS);
+		} else {
+			err = add_mtd_partitions(mymtd, axis_partitions, pidx);
+		}
+
+		if (err)
+			panic("axisflashmap could not add MTD partitions!\n");
+	}
+
+	if (!romfs_in_flash) {
+		/* Create an RAM device for the root partition (romfs). */
+
+#if !defined(CONFIG_MTD_MTDRAM) || (CONFIG_MTDRAM_TOTAL_SIZE != 0) || (CONFIG_MTDRAM_ABS_POS != 0)
+		/* No use trying to boot this kernel from RAM. Panic! */
+		printk(KERN_EMERG "axisflashmap: Cannot create an MTD RAM "
+		       "device due to kernel (mis)configuration!\n");
+		panic("This kernel cannot boot from RAM!\n");
+#else
+		struct mtd_info *mtd_ram;
+
+		mtd_ram = kmalloc(sizeof(struct mtd_info), GFP_KERNEL);
+		if (!mtd_ram)
+			panic("axisflashmap couldn't allocate memory for "
+			      "mtd_info!\n");
+
+		printk(KERN_INFO " Adding RAM partition for romfs image:\n");
+		printk(pmsg, pidx, (unsigned)romfs_start,
+			(unsigned)romfs_length);
+
+		err = mtdram_init_device(mtd_ram,
+			(void *)romfs_start,
+			romfs_length,
+			"romfs");
+		if (err)
+			panic("axisflashmap could not initialize MTD RAM "
+			      "device!\n");
+#endif
+	}
+	return err;
+}
+
+/* This adds the above to the kernels init-call chain. */
+module_init(init_axis_flash);
+
+EXPORT_SYMBOL(axisflash_mtd);
diff -Nur linux-2.6.39.orig/arch/cris/arch-v10/drivers/ds1302.c linux-2.6.39/arch/cris/arch-v10/drivers/ds1302.c
--- linux-2.6.39.orig/arch/cris/arch-v10/drivers/ds1302.c	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/arch-v10/drivers/ds1302.c	2011-07-28 16:16:35.863415658 +0200
@@ -22,6 +22,7 @@
 #include <linux/mutex.h>
 #include <linux/bcd.h>
 #include <linux/capability.h>
+#include <linux/device.h>
 
 #include <asm/uaccess.h>
 #include <asm/system.h>
@@ -501,6 +502,10 @@
 	return 0;
 }
 
+#ifdef CONFIG_SYSFS
+static struct class *rtc_class;
+#endif
+
 static int __init ds1302_register(void)
 {
 	ds1302_init();
@@ -509,6 +514,12 @@
 		       ds1302_name, RTC_MAJOR_NR);
 		return -1;
 	}
+	#ifdef CONFIG_SYSFS
+	rtc_class = class_create(THIS_MODULE, "rtc");
+	class_device_create(rtc_class, NULL, MKDEV(RTC_MAJOR_NR, 0),
+		NULL, "rtc");
+	#endif
+
         return 0;
 
 }
diff -Nur linux-2.6.39.orig/arch/cris/arch-v10/drivers/gpio.c linux-2.6.39/arch/cris/arch-v10/drivers/gpio.c
--- linux-2.6.39.orig/arch/cris/arch-v10/drivers/gpio.c	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/arch-v10/drivers/gpio.c	2011-07-28 16:16:36.023425394 +0200
@@ -20,6 +20,7 @@
 #include <linux/poll.h>
 #include <linux/init.h>
 #include <linux/interrupt.h>
+#include <linux/device.h>
 
 #include <asm/etraxgpio.h>
 #include <arch/svinto.h>
@@ -798,6 +799,10 @@
 
 /* main driver initialization routine, called from mem.c */
 
+#ifdef CONFIG_SYSFS
+static struct class *gpio_class;
+#endif
+
 static int __init gpio_init(void)
 {
 	int res;
@@ -811,6 +816,13 @@
 		return res;
 	}
 
+#ifdef CONFIG_SYSFS
+	gpio_class = class_create(THIS_MODULE, "gpio");
+	device_create(gpio_class, NULL, MKDEV(GPIO_MAJOR, 0), NULL, "gpioa");
+	device_create(gpio_class, NULL, MKDEV(GPIO_MAJOR, 1), NULL, "gpiob");
+	device_create(gpio_class, NULL, MKDEV(GPIO_MAJOR, 2), NULL, "leds");
+	device_create(gpio_class, NULL, MKDEV(GPIO_MAJOR, 3), NULL, "gpiog");
+#endif
 	/* Clear all leds */
 #if defined (CONFIG_ETRAX_CSP0_LEDS) ||  defined (CONFIG_ETRAX_PA_LEDS) || defined (CONFIG_ETRAX_PB_LEDS)
 	CRIS_LED_NETWORK_SET(0);
diff -Nur linux-2.6.39.orig/arch/cris/arch-v10/lib/hw_settings.S linux-2.6.39/arch/cris/arch-v10/lib/hw_settings.S
--- linux-2.6.39.orig/arch/cris/arch-v10/lib/hw_settings.S	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/arch-v10/lib/hw_settings.S	2011-07-28 16:16:36.163758404 +0200
@@ -58,3 +58,5 @@
 	.dword R_PORT_PB_SET
 	.dword PB_SET_VALUE
 	.dword 0 ; No more register values
+	.ascii "ACME_PART_MAGIC" 
+	.dword 0xdeadc0de
diff -Nur linux-2.6.39.orig/arch/cris/arch-v10/mm/init.c linux-2.6.39/arch/cris/arch-v10/mm/init.c
--- linux-2.6.39.orig/arch/cris/arch-v10/mm/init.c	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/arch-v10/mm/init.c	2011-07-28 16:16:36.313421347 +0200
@@ -184,6 +184,9 @@
 
 	free_area_init_node(0, zones_size, PAGE_OFFSET >> PAGE_SHIFT, 0);
 }
+void free_initrd_mem(unsigned long start, unsigned long end)
+{
+}
 
 /* Initialize remaps of some I/O-ports. It is important that this
  * is called before any driver is initialized.
diff -Nur linux-2.6.39.orig/arch/cris/boot/compressed/Makefile linux-2.6.39/arch/cris/boot/compressed/Makefile
--- linux-2.6.39.orig/arch/cris/boot/compressed/Makefile	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/boot/compressed/Makefile	2011-07-28 16:16:36.453421314 +0200
@@ -18,7 +18,7 @@
 OBJECTS-$(CONFIG_ETRAX_ARCH_V32) = $(obj)/head_v32.o
 OBJECTS-$(CONFIG_ETRAX_ARCH_V10) = $(obj)/head_v10.o
 OBJECTS= $(OBJECTS-y) $(obj)/misc.o
-OBJCOPYFLAGS = -O binary --remove-section=.bss
+#OBJCOPYFLAGS = -O binary --remove-section=.bss
 
 quiet_cmd_image = BUILD   $@
 cmd_image = cat $(obj)/decompress.bin $(obj)/piggy.gz > $@
diff -Nur linux-2.6.39.orig/arch/cris/boot/Makefile linux-2.6.39/arch/cris/boot/Makefile
--- linux-2.6.39.orig/arch/cris/boot/Makefile	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/boot/Makefile	2011-07-28 16:16:36.573671907 +0200
@@ -5,7 +5,7 @@
 objcopyflags-$(CONFIG_ETRAX_ARCH_V10) += -R .note -R .comment
 objcopyflags-$(CONFIG_ETRAX_ARCH_V32) += --remove-section=.bss --remove-section=.note.gnu.build-id
 
-OBJCOPYFLAGS = -O binary $(objcopyflags-y)
+#OBJCOPYFLAGS = -O binary $(objcopyflags-y)
 
 
 subdir- := compressed rescue
@@ -17,7 +17,6 @@
 
 $(obj)/compressed/vmlinux: $(obj)/Image FORCE
 	$(Q)$(MAKE) $(build)=$(obj)/compressed $@
-	$(Q)$(MAKE) $(build)=$(obj)/rescue $(obj)/rescue/rescue.bin
 
 $(obj)/zImage:  $(obj)/compressed/vmlinux
 	@cp $< $@
diff -Nur linux-2.6.39.orig/arch/cris/Kconfig linux-2.6.39/arch/cris/Kconfig
--- linux-2.6.39.orig/arch/cris/Kconfig	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/Kconfig	2011-07-28 16:16:36.713417234 +0200
@@ -168,6 +168,12 @@
 	help
 	  Size of DRAM (decimal in MB) typically 2, 8 or 16.
 
+config ETRAX_MTD_SIZE
+	hex "MTD size (hex)"
+	default "0x00800000"
+	help
+	  Size of MTD device typically 4 or 8 MB.
+
 config ETRAX_VMEM_SIZE
        int "Video memory size (dec, in MB)"
        depends on ETRAX_ARCH_V32 && !ETRAXFS
@@ -273,7 +279,7 @@
 	select MTD_CFI_AMDSTD
 	select MTD_JEDECPROBE if ETRAX_ARCH_V32
 	select MTD_CHAR
-	select MTD_BLOCK
+	select MTD_BLOCK_RO
 	select MTD_PARTITIONS
 	select MTD_COMPLEX_MAPPINGS
 	help
@@ -660,6 +666,11 @@
 
 source "drivers/ide/Kconfig"
 
+#mysteriously part of this standard linux driver was removed from cris build! - info@crisos.org  
+source "drivers/scsi/Kconfig"
+
+source "drivers/media/Kconfig"
+
 source "drivers/net/Kconfig"
 
 source "drivers/i2c/Kconfig"
@@ -675,6 +686,8 @@
 
 source "fs/Kconfig"
 
+source "sound/Kconfig"
+
 source "drivers/usb/Kconfig"
 
 source "drivers/uwb/Kconfig"
diff -Nur linux-2.6.39.orig/arch/cris/Kconfig.orig linux-2.6.39/arch/cris/Kconfig.orig
--- linux-2.6.39.orig/arch/cris/Kconfig.orig	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.39/arch/cris/Kconfig.orig	2011-05-19 06:06:34.000000000 +0200
@@ -0,0 +1,690 @@
+config MMU
+	bool
+	default y
+
+config ZONE_DMA
+	bool
+	default y
+
+config RWSEM_GENERIC_SPINLOCK
+	bool
+	default y
+
+config RWSEM_XCHGADD_ALGORITHM
+	bool
+
+config GENERIC_CMOS_UPDATE
+	def_bool y
+
+config ARCH_USES_GETTIMEOFFSET
+	def_bool n
+
+config GENERIC_IOMAP
+       bool
+       default y
+
+config ARCH_HAS_ILOG2_U32
+	bool
+	default n
+
+config ARCH_HAS_ILOG2_U64
+	bool
+	default n
+
+config GENERIC_FIND_NEXT_BIT
+	bool
+	default y
+
+config GENERIC_HWEIGHT
+	bool
+	default y
+
+config GENERIC_CALIBRATE_DELAY
+	bool
+	default y
+
+config NO_IOPORT
+	def_bool y
+
+config FORCE_MAX_ZONEORDER
+	int
+	default 6
+
+config CRIS
+	bool
+	default y
+	select HAVE_IDE
+	select HAVE_GENERIC_HARDIRQS
+	select GENERIC_IRQ_SHOW
+
+config HZ
+	int
+	default 100
+
+source "init/Kconfig"
+
+source "kernel/Kconfig.freezer"
+
+menu "General setup"
+
+source "fs/Kconfig.binfmt"
+
+config ETRAX_CMDLINE
+	string "Kernel command line"
+	default "root=/dev/mtdblock3"
+	help
+	  Pass additional commands to the kernel.
+
+config ETRAX_WATCHDOG
+	bool "Enable ETRAX watchdog"
+	help
+	  Enable the built-in watchdog timer support on ETRAX based embedded
+	  network computers.
+
+config ETRAX_WATCHDOG_NICE_DOGGY
+	bool "Disable watchdog during Oops printouts"
+	depends on ETRAX_WATCHDOG
+	help
+	  By enabling this you make sure that the watchdog does not bite while
+	  printing oopses. Recommended for development systems but not for
+	  production releases.
+
+config ETRAX_FAST_TIMER
+       bool "Enable ETRAX fast timer API"
+       help
+         This options enables the API to a fast timer implementation using
+	 timer1 to get sub jiffie resolution timers (primarily one-shot
+	 timers).
+	 This is needed if CONFIG_ETRAX_SERIAL_FAST_TIMER is enabled.
+
+config ETRAX_KMALLOCED_MODULES
+	bool "Enable module allocation with kmalloc"
+	help
+	  Enable module allocation with kmalloc instead of vmalloc.
+
+config OOM_REBOOT
+       bool "Enable reboot at out of memory"
+
+source "kernel/Kconfig.preempt"
+
+source mm/Kconfig
+
+endmenu
+
+menu "Hardware setup"
+
+choice
+	prompt "Processor type"
+	default ETRAX100LX
+
+config ETRAX100LX
+	bool "ETRAX-100LX-v1"
+	select ARCH_USES_GETTIMEOFFSET
+	help
+	  Support version 1 of the ETRAX 100LX.
+
+config ETRAX100LX_V2
+	bool "ETRAX-100LX-v2"
+	select ARCH_USES_GETTIMEOFFSET
+	help
+	  Support version 2 of the ETRAX 100LX.
+
+config SVINTO_SIM
+	bool "ETRAX-100LX-for-xsim-simulator"
+	select ARCH_USES_GETTIMEOFFSET
+	help
+	  Support the xsim ETRAX Simulator.
+
+config ETRAXFS
+	bool "ETRAX-FS-V32"
+	help
+	  Support CRIS V32.
+
+config CRIS_MACH_ARTPEC3
+        bool "ARTPEC-3"
+        help
+          Support Axis ARTPEC-3.
+
+endchoice
+
+config ETRAX_VCS_SIM
+	bool "VCS Simulator"
+	help
+	  Setup hardware to be run in the VCS simulator.
+
+config ETRAX_ARCH_V10
+       bool
+       default y if ETRAX100LX || ETRAX100LX_V2
+       default n if !(ETRAX100LX || ETRAX100LX_V2)
+
+config ETRAX_ARCH_V32
+       bool
+       default y if (ETRAXFS || CRIS_MACH_ARTPEC3)
+       default n if !(ETRAXFS || CRIS_MACH_ARTPEC3)
+
+config ETRAX_DRAM_SIZE
+	int "DRAM size (dec, in MB)"
+	default "8"
+	help
+	  Size of DRAM (decimal in MB) typically 2, 8 or 16.
+
+config ETRAX_VMEM_SIZE
+       int "Video memory size (dec, in MB)"
+       depends on ETRAX_ARCH_V32 && !ETRAXFS
+       default 8 if !ETRAXFS
+       help
+	Size of Video accessible memory (decimal, in MB).
+
+config ETRAX_FLASH_BUSWIDTH
+	int "Buswidth of NOR flash in bytes"
+	default "2"
+	help
+	  Width in bytes of the NOR Flash bus (1, 2 or 4). Is usually 2.
+
+config ETRAX_NANDFLASH_BUSWIDTH
+	int "Buswidth of NAND flash in bytes"
+	default "1"
+	help
+	  Width in bytes of the NAND flash (1 or 2).
+
+config ETRAX_FLASH1_SIZE
+       int "FLASH1 size (dec, in MB. 0 = Unknown)"
+       default "0"
+
+choice
+	prompt "Product debug-port"
+	default ETRAX_DEBUG_PORT0
+
+config ETRAX_DEBUG_PORT0
+	bool "Serial-0"
+	help
+	  Choose a serial port for the ETRAX debug console.  Default to
+	  port 0.
+
+config ETRAX_DEBUG_PORT1
+	bool "Serial-1"
+	help
+	  Use serial port 1 for the console.
+
+config ETRAX_DEBUG_PORT2
+	bool "Serial-2"
+	help
+	  Use serial port 2 for the console.
+
+config ETRAX_DEBUG_PORT3
+	bool "Serial-3"
+	help
+	  Use serial port 3 for the console.
+
+config ETRAX_DEBUG_PORT_NULL
+	bool "disabled"
+	help
+	  Disable serial-port debugging.
+
+endchoice
+
+choice
+	prompt "Kernel GDB port"
+	depends on ETRAX_KGDB
+	default ETRAX_KGDB_PORT0
+	help
+	  Choose a serial port for kernel debugging.  NOTE: This port should
+	  not be enabled under Drivers for built-in interfaces (as it has its
+	  own initialization code) and should not be the same as the debug port.
+
+config ETRAX_KGDB_PORT0
+	bool "Serial-0"
+	help
+	  Use serial port 0 for kernel debugging.
+
+config ETRAX_KGDB_PORT1
+	bool "Serial-1"
+	help
+	  Use serial port 1 for kernel debugging.
+
+config ETRAX_KGDB_PORT2
+	bool "Serial-2"
+	help
+	  Use serial port 2 for kernel debugging.
+
+config ETRAX_KGDB_PORT3
+	bool "Serial-3"
+	help
+	  Use serial port 3 for kernel debugging.
+
+endchoice
+
+source arch/cris/arch-v10/Kconfig
+source arch/cris/arch-v32/Kconfig
+
+endmenu
+
+source "net/Kconfig"
+
+# bring in ETRAX built-in drivers
+menu "Drivers for built-in interfaces"
+source arch/cris/arch-v10/drivers/Kconfig
+source arch/cris/arch-v32/drivers/Kconfig
+
+config ETRAX_AXISFLASHMAP
+	bool "Axis flash-map support"
+	select MTD
+	select MTD_CFI
+	select MTD_CFI_AMDSTD
+	select MTD_JEDECPROBE if ETRAX_ARCH_V32
+	select MTD_CHAR
+	select MTD_BLOCK
+	select MTD_PARTITIONS
+	select MTD_COMPLEX_MAPPINGS
+	help
+	  This option enables MTD mapping of flash devices.  Needed to use
+	  flash memories.  If unsure, say Y.
+
+config ETRAX_RTC
+	bool "Real Time Clock support"
+	depends on ETRAX_I2C
+	help
+	  Enables drivers for the Real-Time Clock battery-backed chips on
+	  some products. The kernel reads the time when booting, and
+	  the date can be set using ioctl(fd, RTC_SET_TIME, &rt) with rt a
+	  rtc_time struct (see <file:include/asm-cris/rtc.h>) on the /dev/rtc
+	  device.  You can check the time with cat /proc/rtc, but
+	  normal time reading should be done using libc function time and
+	  friends.
+
+choice
+	prompt "RTC chip"
+	depends on ETRAX_RTC
+	default ETRAX_DS1302
+
+config ETRAX_DS1302
+	depends on ETRAX_ARCH_V10
+	bool "DS1302"
+	help
+	  Enables the driver for the DS1302 Real-Time Clock battery-backed
+	  chip on some products.
+
+config ETRAX_PCF8563
+	bool "PCF8563"
+	help
+	  Enables the driver for the PCF8563 Real-Time Clock battery-backed
+	  chip on some products.
+
+endchoice
+
+config ETRAX_SYNCHRONOUS_SERIAL
+	bool "Synchronous serial-port support"
+	help
+	  Select this to enable the synchronous serial port driver.
+
+config ETRAX_SYNCHRONOUS_SERIAL_PORT0
+	bool "Synchronous serial port 0 enabled"
+	depends on ETRAX_SYNCHRONOUS_SERIAL
+	help
+	  Enabled synchronous serial port 0.
+
+config ETRAX_SYNCHRONOUS_SERIAL0_DMA
+	bool "Enable DMA on synchronous serial port 0."
+	depends on ETRAX_SYNCHRONOUS_SERIAL_PORT0
+	help
+	  A synchronous serial port can run in manual or DMA mode.
+	  Selecting this option will make it run in DMA mode.
+
+config ETRAX_SYNCHRONOUS_SERIAL_PORT1
+	bool "Synchronous serial port 1 enabled"
+	depends on ETRAX_SYNCHRONOUS_SERIAL && (ETRAXFS || ETRAX_ARCH_V10)
+	help
+	  Enabled synchronous serial port 1.
+
+config ETRAX_SYNCHRONOUS_SERIAL1_DMA
+	bool "Enable DMA on synchronous serial port 1."
+	depends on ETRAX_SYNCHRONOUS_SERIAL_PORT1
+	help
+	  A synchronous serial port can run in manual or DMA mode.
+	  Selecting this option will make it run in DMA mode.
+
+choice
+	prompt "Network LED behavior"
+	depends on ETRAX_ETHERNET
+	default ETRAX_NETWORK_LED_ON_WHEN_ACTIVITY
+
+config ETRAX_NETWORK_LED_ON_WHEN_LINK
+	bool "LED_on_when_link"
+	help
+	  Selecting LED_on_when_link will light the LED when there is a
+	  connection and will flash off when there is activity.
+
+	  Selecting LED_on_when_activity will light the LED only when
+	  there is activity.
+
+	  This setting will also affect the behaviour of other activity LEDs
+	  e.g. Bluetooth.
+
+config ETRAX_NETWORK_LED_ON_WHEN_ACTIVITY
+	bool "LED_on_when_activity"
+	help
+	  Selecting LED_on_when_link will light the LED when there is a
+	  connection and will flash off when there is activity.
+
+	  Selecting LED_on_when_activity will light the LED only when
+	  there is activity.
+
+	  This setting will also affect the behaviour of other activity LEDs
+	  e.g. Bluetooth.
+
+endchoice
+
+choice
+	prompt "Ser0 DMA out channel"
+	depends on ETRAX_SERIAL_PORT0
+	default ETRAX_SERIAL_PORT0_DMA6_OUT if ETRAX_ARCH_V32
+	default ETRAX_SERIAL_PORT0_NO_DMA_OUT if ETRAX_ARCH_V10
+
+config ETRAX_SERIAL_PORT0_NO_DMA_OUT
+	bool "Ser0 uses no DMA for output"
+	help
+	  Do not use DMA for ser0 output.
+
+config ETRAX_SERIAL_PORT0_DMA6_OUT
+	bool "Ser0 uses DMA6 for output"
+	depends on ETRAXFS
+	help
+	  Enables the DMA6 output channel for ser0 (ttyS0).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when transmitting data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+config ETRAX_SERIAL_PORT0_DMA0_OUT
+	bool "Ser0 uses DMA0 for output"
+	depends on CRIS_MACH_ARTPEC3
+	help
+	  Enables the DMA0 output channel for ser0 (ttyS0).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when transmitting data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+endchoice
+
+choice
+	prompt "Ser0 DMA in channel "
+	depends on ETRAX_SERIAL_PORT0
+	default ETRAX_SERIAL_PORT0_NO_DMA_IN if ETRAX_ARCH_V32
+	default ETRAX_SERIAL_PORT0_DMA7_IN if ETRAX_ARCH_V10
+	help
+	  What DMA channel to use for ser0.
+
+config ETRAX_SERIAL_PORT0_NO_DMA_IN
+	bool "Ser0 uses no DMA for input"
+	help
+	  Do not use DMA for ser0 input.
+
+config ETRAX_SERIAL_PORT0_DMA7_IN
+	bool "Ser0 uses DMA7 for input"
+	depends on ETRAXFS
+	help
+	  Enables the DMA7 input channel for ser0 (ttyS0).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when receiving data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+config ETRAX_SERIAL_PORT0_DMA1_IN
+	bool "Ser0 uses DMA1 for input"
+	depends on CRIS_MACH_ARTPEC3
+	help
+	  Enables the DMA1 input channel for ser0 (ttyS0).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when receiving data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+endchoice
+
+choice
+	prompt "Ser1 DMA in channel "
+	depends on ETRAX_SERIAL_PORT1
+	default ETRAX_SERIAL_PORT1_NO_DMA_IN if ETRAX_ARCH_V32
+	default ETRAX_SERIAL_PORT1_DMA9_IN if ETRAX_ARCH_V10
+	help
+	  What DMA channel to use for ser1.
+
+config ETRAX_SERIAL_PORT1_NO_DMA_IN
+	bool "Ser1 uses no DMA for input"
+	help
+	  Do not use DMA for ser1 input.
+
+config ETRAX_SERIAL_PORT1_DMA5_IN
+	bool "Ser1 uses DMA5 for input"
+	depends on ETRAX_ARCH_V32
+	help
+	  Enables the DMA5 input channel for ser1 (ttyS1).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when receiving data.
+	  Normally you want this on, unless you use the DMA channel for
+	  something else.
+
+config ETRAX_SERIAL_PORT1_DMA9_IN
+	depends on ETRAX_ARCH_V10
+	bool "Ser1 uses DMA9 for input"
+
+endchoice
+
+
+choice
+	prompt "Ser1 DMA out channel"
+	depends on ETRAX_SERIAL_PORT1
+	default ETRAX_SERIAL_PORT1_NO_DMA_OUT if ETRAX_ARCH_V32
+	default ETRAX_SERIAL_PORT1_DMA8_OUT if ETRAX_ARCH_V10
+	help
+	  What DMA channel to use for ser1.
+
+config ETRAX_SERIAL_PORT1_NO_DMA_OUT
+	bool "Ser1 uses no DMA for output"
+	help
+	  Do not use DMA for ser1 output.
+
+config ETRAX_SERIAL_PORT1_DMA8_OUT
+	depends on ETRAX_ARCH_V10
+	bool "Ser1 uses DMA8 for output"
+
+config ETRAX_SERIAL_PORT1_DMA4_OUT
+	depends on ETRAX_ARCH_V32
+	bool "Ser1 uses DMA4 for output"
+	help
+	  Enables the DMA4 output channel for ser1 (ttyS1).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when transmitting data.
+	  Normally you want this on, unless you use the DMA channel for
+	  something else.
+
+endchoice
+
+choice
+	prompt "Ser2 DMA out channel"
+	depends on ETRAX_SERIAL_PORT2
+	default ETRAX_SERIAL_PORT2_NO_DMA_OUT if ETRAX_ARCH_V32
+	default ETRAX_SERIAL_PORT2_DMA2_OUT if ETRAX_ARCH_V10
+
+config ETRAX_SERIAL_PORT2_NO_DMA_OUT
+	bool "Ser2 uses no DMA for output"
+	help
+	  Do not use DMA for ser2 output.
+
+config ETRAX_SERIAL_PORT2_DMA2_OUT
+	bool "Ser2 uses DMA2 for output"
+	depends on ETRAXFS || ETRAX_ARCH_V10
+	help
+	  Enables the DMA2 output channel for ser2 (ttyS2).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when transmitting data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+config ETRAX_SERIAL_PORT2_DMA6_OUT
+	bool "Ser2 uses DMA6 for output"
+	depends on CRIS_MACH_ARTPEC3
+	help
+	  Enables the DMA6 output channel for ser2 (ttyS2).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when transmitting data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+endchoice
+
+choice
+	prompt "Ser2 DMA in channel"
+	depends on ETRAX_SERIAL_PORT2
+	default ETRAX_SERIAL_PORT2_NO_DMA_IN if ETRAX_ARCH_V32
+	default ETRAX_SERIAL_PORT2_DMA3_IN if ETRAX_ARCH_V10
+	help
+	  What DMA channel to use for ser2.
+
+config ETRAX_SERIAL_PORT2_NO_DMA_IN
+	bool "Ser2 uses no DMA for input"
+	help
+	  Do not use DMA for ser2 input.
+
+config ETRAX_SERIAL_PORT2_DMA3_IN
+	bool "Ser2 uses DMA3 for input"
+	depends on ETRAXFS || ETRAX_ARCH_V10
+	help
+	  Enables the DMA3 input channel for ser2 (ttyS2).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when receiving data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+config ETRAX_SERIAL_PORT2_DMA7_IN
+	bool "Ser2 uses DMA7 for input"
+	depends on CRIS_MACH_ARTPEC3
+	help
+	  Enables the DMA7 input channel for ser2 (ttyS2).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when receiving data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+endchoice
+
+choice
+	prompt "Ser3 DMA in channel"
+	depends on ETRAX_SERIAL_PORT3
+	default ETRAX_SERIAL_PORT3_NO_DMA_IN if ETRAX_ARCH_V32
+	default ETRAX_SERIAL_PORT3_DMA5_IN if ETRAX_ARCH_V10
+	help
+	  What DMA channel to use for ser3.
+
+config ETRAX_SERIAL_PORT3_NO_DMA_IN
+	bool "Ser3 uses no DMA for input"
+	help
+	  Do not use DMA for ser3 input.
+
+config ETRAX_SERIAL_PORT3_DMA5_IN
+	depends on ETRAX_ARCH_V10
+	bool "DMA 5"
+
+config ETRAX_SERIAL_PORT3_DMA9_IN
+	bool "Ser3 uses DMA9 for input"
+	depends on ETRAXFS
+	help
+	  Enables the DMA9 input channel for ser3 (ttyS3).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when receiving data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+config ETRAX_SERIAL_PORT3_DMA3_IN
+	bool "Ser3 uses DMA3 for input"
+	depends on CRIS_MACH_ARTPEC3
+	help
+	  Enables the DMA3 input channel for ser3 (ttyS3).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when receiving data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+endchoice
+
+choice
+	prompt "Ser3 DMA out channel"
+	depends on ETRAX_SERIAL_PORT3
+	default ETRAX_SERIAL_PORT3_NO_DMA_OUT if ETRAX_ARCH_V32
+	default ETRAX_SERIAL_PORT3_DMA4_OUT if ETRAX_ARCH_V10
+
+config ETRAX_SERIAL_PORT3_NO_DMA_OUT
+	bool "Ser3 uses no DMA for output"
+	help
+	  Do not use DMA for ser3 output.
+
+config ETRAX_SERIAL_PORT3_DMA4_OUT
+	depends on ETRAX_ARCH_V10
+	bool "DMA 4"
+
+config ETRAX_SERIAL_PORT3_DMA8_OUT
+	bool "Ser3 uses DMA8 for output"
+	depends on ETRAXFS
+	help
+	  Enables the DMA8 output channel for ser3 (ttyS3).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when transmitting data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+config ETRAX_SERIAL_PORT3_DMA2_OUT
+	bool "Ser3 uses DMA2 for output"
+	depends on CRIS_MACH_ARTPEC3
+	help
+	  Enables the DMA2 output channel for ser3 (ttyS3).
+	  If you do not enable DMA, an interrupt for each character will be
+	  used when transmitting data.
+	  Normally you want to use DMA, unless you use the DMA channel for
+	  something else.
+
+endchoice
+
+endmenu
+
+source "drivers/base/Kconfig"
+
+# standard linux drivers
+source "drivers/mtd/Kconfig"
+
+source "drivers/parport/Kconfig"
+
+source "drivers/pnp/Kconfig"
+
+source "drivers/block/Kconfig"
+
+source "drivers/ide/Kconfig"
+
+source "drivers/net/Kconfig"
+
+source "drivers/i2c/Kconfig"
+
+source "drivers/rtc/Kconfig"
+
+#
+# input before char - char/joystick depends on it. As does USB.
+#
+source "drivers/input/Kconfig"
+
+source "drivers/char/Kconfig"
+
+source "fs/Kconfig"
+
+source "drivers/usb/Kconfig"
+
+source "drivers/uwb/Kconfig"
+
+source "drivers/staging/Kconfig"
+
+source "arch/cris/Kconfig.debug"
+
+source "security/Kconfig"
+
+source "crypto/Kconfig"
+
+source "lib/Kconfig"
diff -Nur linux-2.6.39.orig/arch/cris/Makefile linux-2.6.39/arch/cris/Makefile
--- linux-2.6.39.orig/arch/cris/Makefile	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/Makefile	2011-07-28 16:16:36.883415879 +0200
@@ -40,10 +40,10 @@
 
 LD = $(CROSS_COMPILE)ld -mcrislinux
 
-OBJCOPYFLAGS := -O binary -R .note -R .comment -S
+OBJCOPYFLAGS := -O binary -R .bss -R .note -R .note.gnu.build-id -R .comment -S
 
 KBUILD_AFLAGS += -mlinux -march=$(arch-y) $(inc)
-KBUILD_CFLAGS += -mlinux -march=$(arch-y) -pipe $(inc)
+KBUILD_CFLAGS += -mlinux -march=$(arch-y) -pipe -fno-peephole2 $(inc)
 KBUILD_CPPFLAGS += $(inc)
 
 ifdef CONFIG_FRAME_POINTER
diff -Nur linux-2.6.39.orig/arch/cris/mm/init.c linux-2.6.39/arch/cris/mm/init.c
--- linux-2.6.39.orig/arch/cris/mm/init.c	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/arch/cris/mm/init.c	2011-07-28 16:16:37.013424379 +0200
@@ -16,6 +16,7 @@
 DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
 
 unsigned long empty_zero_page;
+EXPORT_SYMBOL(empty_zero_page);
 
 extern char _stext, _edata, _etext; /* From linkerscript */
 extern char __init_begin, __init_end;
@@ -81,3 +82,10 @@
         printk (KERN_INFO "Freeing unused kernel memory: %luk freed\n",
 		(unsigned long)((&__init_end - &__init_begin) >> 10));
 }
+
+#ifdef CONFIG_BLK_DEV_INITRD
+void free_initrd_mem(unsigned long start, unsigned long end)
+{
+	return 0;
+}
+#endif
diff -Nur linux-2.6.39.orig/drivers/net/cris/eth_v10.c linux-2.6.39/drivers/net/cris/eth_v10.c
--- linux-2.6.39.orig/drivers/net/cris/eth_v10.c	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/drivers/net/cris/eth_v10.c	2011-07-28 16:16:37.184155914 +0200
@@ -1714,7 +1714,7 @@
 static void
 e100_netpoll(struct net_device* netdev)
 {
-	e100rxtx_interrupt(NETWORK_DMA_TX_IRQ_NBR, netdev, NULL);
+	e100rxtx_interrupt(NETWORK_DMA_TX_IRQ_NBR, netdev);
 }
 #endif
 
diff -Nur linux-2.6.39.orig/drivers/net/cris/eth_v10.c.orig linux-2.6.39/drivers/net/cris/eth_v10.c.orig
--- linux-2.6.39.orig/drivers/net/cris/eth_v10.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.39/drivers/net/cris/eth_v10.c.orig	2011-05-19 06:06:34.000000000 +0200
@@ -0,0 +1,1749 @@
+/*
+ * e100net.c: A network driver for the ETRAX 100LX network controller.
+ *
+ * Copyright (c) 1998-2002 Axis Communications AB.
+ *
+ * The outline of this driver comes from skeleton.c.
+ *
+ */
+
+
+#include <linux/module.h>
+
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/types.h>
+#include <linux/fcntl.h>
+#include <linux/interrupt.h>
+#include <linux/ptrace.h>
+#include <linux/ioport.h>
+#include <linux/in.h>
+#include <linux/string.h>
+#include <linux/spinlock.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/bitops.h>
+
+#include <linux/if.h>
+#include <linux/mii.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/ethtool.h>
+
+#include <arch/svinto.h>/* DMA and register descriptions */
+#include <asm/io.h>         /* CRIS_LED_* I/O functions */
+#include <asm/irq.h>
+#include <asm/dma.h>
+#include <asm/system.h>
+#include <asm/ethernet.h>
+#include <asm/cache.h>
+#include <arch/io_interface_mux.h>
+
+//#define ETHDEBUG
+#define D(x)
+
+/*
+ * The name of the card. Is used for messages and in the requests for
+ * io regions, irqs and dma channels
+ */
+
+static const char* cardname = "ETRAX 100LX built-in ethernet controller";
+
+/* A default ethernet address. Highlevel SW will set the real one later */
+
+static struct sockaddr default_mac = {
+	0,
+	{ 0x00, 0x40, 0x8C, 0xCD, 0x00, 0x00 }
+};
+
+/* Information that need to be kept for each board. */
+struct net_local {
+	struct mii_if_info mii_if;
+
+	/* Tx control lock.  This protects the transmit buffer ring
+	 * state along with the "tx full" state of the driver.  This
+	 * means all netif_queue flow control actions are protected
+	 * by this lock as well.
+	 */
+	spinlock_t lock;
+
+	spinlock_t led_lock; /* Protect LED state */
+	spinlock_t transceiver_lock; /* Protect transceiver state. */
+};
+
+typedef struct etrax_eth_descr
+{
+	etrax_dma_descr descr;
+	struct sk_buff* skb;
+} etrax_eth_descr;
+
+/* Some transceivers requires special handling */
+struct transceiver_ops
+{
+	unsigned int oui;
+	void (*check_speed)(struct net_device* dev);
+	void (*check_duplex)(struct net_device* dev);
+};
+
+/* Duplex settings */
+enum duplex
+{
+	half,
+	full,
+	autoneg
+};
+
+/* Dma descriptors etc. */
+
+#define MAX_MEDIA_DATA_SIZE 1522
+
+#define MIN_PACKET_LEN      46
+#define ETHER_HEAD_LEN      14
+
+/*
+** MDIO constants.
+*/
+#define MDIO_START                          0x1
+#define MDIO_READ                           0x2
+#define MDIO_WRITE                          0x1
+#define MDIO_PREAMBLE              0xfffffffful
+
+/* Broadcom specific */
+#define MDIO_AUX_CTRL_STATUS_REG           0x18
+#define MDIO_BC_FULL_DUPLEX_IND             0x1
+#define MDIO_BC_SPEED                       0x2
+
+/* TDK specific */
+#define MDIO_TDK_DIAGNOSTIC_REG              18
+#define MDIO_TDK_DIAGNOSTIC_RATE          0x400
+#define MDIO_TDK_DIAGNOSTIC_DPLX          0x800
+
+/*Intel LXT972A specific*/
+#define MDIO_INT_STATUS_REG_2			0x0011
+#define MDIO_INT_FULL_DUPLEX_IND       (1 << 9)
+#define MDIO_INT_SPEED                (1 << 14)
+
+/* Network flash constants */
+#define NET_FLASH_TIME                  (HZ/50) /* 20 ms */
+#define NET_FLASH_PAUSE                (HZ/100) /* 10 ms */
+#define NET_LINK_UP_CHECK_INTERVAL       (2*HZ) /* 2 s   */
+#define NET_DUPLEX_CHECK_INTERVAL        (2*HZ) /* 2 s   */
+
+#define NO_NETWORK_ACTIVITY 0
+#define NETWORK_ACTIVITY    1
+
+#define NBR_OF_RX_DESC     32
+#define NBR_OF_TX_DESC     16
+
+/* Large packets are sent directly to upper layers while small packets are */
+/* copied (to reduce memory waste). The following constant decides the breakpoint */
+#define RX_COPYBREAK 256
+
+/* Due to a chip bug we need to flush the cache when descriptors are returned */
+/* to the DMA. To decrease performance impact we return descriptors in chunks. */
+/* The following constant determines the number of descriptors to return. */
+#define RX_QUEUE_THRESHOLD  NBR_OF_RX_DESC/2
+
+#define GET_BIT(bit,val)   (((val) >> (bit)) & 0x01)
+
+/* Define some macros to access ETRAX 100 registers */
+#define SETF(var, reg, field, val) var = (var & ~IO_MASK_(reg##_, field##_)) | \
+					  IO_FIELD_(reg##_, field##_, val)
+#define SETS(var, reg, field, val) var = (var & ~IO_MASK_(reg##_, field##_)) | \
+					  IO_STATE_(reg##_, field##_, _##val)
+
+static etrax_eth_descr *myNextRxDesc;  /* Points to the next descriptor to
+                                          to be processed */
+static etrax_eth_descr *myLastRxDesc;  /* The last processed descriptor */
+
+static etrax_eth_descr RxDescList[NBR_OF_RX_DESC] __attribute__ ((aligned(32)));
+
+static etrax_eth_descr* myFirstTxDesc; /* First packet not yet sent */
+static etrax_eth_descr* myLastTxDesc;  /* End of send queue */
+static etrax_eth_descr* myNextTxDesc;  /* Next descriptor to use */
+static etrax_eth_descr TxDescList[NBR_OF_TX_DESC] __attribute__ ((aligned(32)));
+
+static unsigned int network_rec_config_shadow = 0;
+
+static unsigned int network_tr_ctrl_shadow = 0;
+
+/* Network speed indication. */
+static DEFINE_TIMER(speed_timer, NULL, 0, 0);
+static DEFINE_TIMER(clear_led_timer, NULL, 0, 0);
+static int current_speed; /* Speed read from transceiver */
+static int current_speed_selection; /* Speed selected by user */
+static unsigned long led_next_time;
+static int led_active;
+static int rx_queue_len;
+
+/* Duplex */
+static DEFINE_TIMER(duplex_timer, NULL, 0, 0);
+static int full_duplex;
+static enum duplex current_duplex;
+
+/* Index to functions, as function prototypes. */
+
+static int etrax_ethernet_init(void);
+
+static int e100_open(struct net_device *dev);
+static int e100_set_mac_address(struct net_device *dev, void *addr);
+static int e100_send_packet(struct sk_buff *skb, struct net_device *dev);
+static irqreturn_t e100rxtx_interrupt(int irq, void *dev_id);
+static irqreturn_t e100nw_interrupt(int irq, void *dev_id);
+static void e100_rx(struct net_device *dev);
+static int e100_close(struct net_device *dev);
+static int e100_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd);
+static int e100_set_config(struct net_device* dev, struct ifmap* map);
+static void e100_tx_timeout(struct net_device *dev);
+static struct net_device_stats *e100_get_stats(struct net_device *dev);
+static void set_multicast_list(struct net_device *dev);
+static void e100_hardware_send_packet(struct net_local* np, char *buf, int length);
+static void update_rx_stats(struct net_device_stats *);
+static void update_tx_stats(struct net_device_stats *);
+static int e100_probe_transceiver(struct net_device* dev);
+
+static void e100_check_speed(unsigned long priv);
+static void e100_set_speed(struct net_device* dev, unsigned long speed);
+static void e100_check_duplex(unsigned long priv);
+static void e100_set_duplex(struct net_device* dev, enum duplex);
+static void e100_negotiate(struct net_device* dev);
+
+static int e100_get_mdio_reg(struct net_device *dev, int phy_id, int location);
+static void e100_set_mdio_reg(struct net_device *dev, int phy_id, int location, int value);
+
+static void e100_send_mdio_cmd(unsigned short cmd, int write_cmd);
+static void e100_send_mdio_bit(unsigned char bit);
+static unsigned char e100_receive_mdio_bit(void);
+static void e100_reset_transceiver(struct net_device* net);
+
+static void e100_clear_network_leds(unsigned long dummy);
+static void e100_set_network_leds(int active);
+
+static const struct ethtool_ops e100_ethtool_ops;
+#if defined(CONFIG_ETRAX_NO_PHY)
+static void dummy_check_speed(struct net_device* dev);
+static void dummy_check_duplex(struct net_device* dev);
+#else
+static void broadcom_check_speed(struct net_device* dev);
+static void broadcom_check_duplex(struct net_device* dev);
+static void tdk_check_speed(struct net_device* dev);
+static void tdk_check_duplex(struct net_device* dev);
+static void intel_check_speed(struct net_device* dev);
+static void intel_check_duplex(struct net_device* dev);
+static void generic_check_speed(struct net_device* dev);
+static void generic_check_duplex(struct net_device* dev);
+#endif
+#ifdef CONFIG_NET_POLL_CONTROLLER
+static void e100_netpoll(struct net_device* dev);
+#endif
+
+static int autoneg_normal = 1;
+
+struct transceiver_ops transceivers[] =
+{
+#if defined(CONFIG_ETRAX_NO_PHY)
+	{0x0000, dummy_check_speed, dummy_check_duplex}        /* Dummy */
+#else
+	{0x1018, broadcom_check_speed, broadcom_check_duplex},  /* Broadcom */
+	{0xC039, tdk_check_speed, tdk_check_duplex},            /* TDK 2120 */
+	{0x039C, tdk_check_speed, tdk_check_duplex},            /* TDK 2120C */
+        {0x04de, intel_check_speed, intel_check_duplex},     	/* Intel LXT972A*/
+	{0x0000, generic_check_speed, generic_check_duplex}     /* Generic, must be last */
+#endif
+};
+
+struct transceiver_ops* transceiver = &transceivers[0];
+
+static const struct net_device_ops e100_netdev_ops = {
+	.ndo_open		= e100_open,
+	.ndo_stop		= e100_close,
+	.ndo_start_xmit		= e100_send_packet,
+	.ndo_tx_timeout		= e100_tx_timeout,
+	.ndo_get_stats		= e100_get_stats,
+	.ndo_set_multicast_list	= set_multicast_list,
+	.ndo_do_ioctl		= e100_ioctl,
+	.ndo_set_mac_address	= e100_set_mac_address,
+	.ndo_validate_addr	= eth_validate_addr,
+	.ndo_change_mtu		= eth_change_mtu,
+	.ndo_set_config		= e100_set_config,
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	.ndo_poll_controller	= e100_netpoll,
+#endif
+};
+
+#define tx_done(dev) (*R_DMA_CH0_CMD == 0)
+
+/*
+ * Check for a network adaptor of this type, and return '0' if one exists.
+ * If dev->base_addr == 0, probe all likely locations.
+ * If dev->base_addr == 1, always return failure.
+ * If dev->base_addr == 2, allocate space for the device and return success
+ * (detachable devices only).
+ */
+
+static int __init
+etrax_ethernet_init(void)
+{
+	struct net_device *dev;
+        struct net_local* np;
+	int i, err;
+
+	printk(KERN_INFO
+	       "ETRAX 100LX 10/100MBit ethernet v2.0 (c) 1998-2007 Axis Communications AB\n");
+
+	if (cris_request_io_interface(if_eth, cardname)) {
+		printk(KERN_CRIT "etrax_ethernet_init failed to get IO interface\n");
+		return -EBUSY;
+	}
+
+	dev = alloc_etherdev(sizeof(struct net_local));
+	if (!dev)
+		return -ENOMEM;
+
+	np = netdev_priv(dev);
+
+	/* we do our own locking */
+	dev->features |= NETIF_F_LLTX;
+
+	dev->base_addr = (unsigned int)R_NETWORK_SA_0; /* just to have something to show */
+
+	/* now setup our etrax specific stuff */
+
+	dev->irq = NETWORK_DMA_RX_IRQ_NBR; /* we really use DMATX as well... */
+	dev->dma = NETWORK_RX_DMA_NBR;
+
+	/* fill in our handlers so the network layer can talk to us in the future */
+
+	dev->ethtool_ops	= &e100_ethtool_ops;
+	dev->netdev_ops		= &e100_netdev_ops;
+
+	spin_lock_init(&np->lock);
+	spin_lock_init(&np->led_lock);
+	spin_lock_init(&np->transceiver_lock);
+
+	/* Initialise the list of Etrax DMA-descriptors */
+
+	/* Initialise receive descriptors */
+
+	for (i = 0; i < NBR_OF_RX_DESC; i++) {
+		/* Allocate two extra cachelines to make sure that buffer used
+		 * by DMA does not share cacheline with any other data (to
+		 * avoid cache bug)
+		 */
+		RxDescList[i].skb = dev_alloc_skb(MAX_MEDIA_DATA_SIZE + 2 * L1_CACHE_BYTES);
+		if (!RxDescList[i].skb)
+			return -ENOMEM;
+		RxDescList[i].descr.ctrl   = 0;
+		RxDescList[i].descr.sw_len = MAX_MEDIA_DATA_SIZE;
+		RxDescList[i].descr.next   = virt_to_phys(&RxDescList[i + 1]);
+		RxDescList[i].descr.buf    = L1_CACHE_ALIGN(virt_to_phys(RxDescList[i].skb->data));
+		RxDescList[i].descr.status = 0;
+		RxDescList[i].descr.hw_len = 0;
+		prepare_rx_descriptor(&RxDescList[i].descr);
+	}
+
+	RxDescList[NBR_OF_RX_DESC - 1].descr.ctrl   = d_eol;
+	RxDescList[NBR_OF_RX_DESC - 1].descr.next   = virt_to_phys(&RxDescList[0]);
+	rx_queue_len = 0;
+
+	/* Initialize transmit descriptors */
+	for (i = 0; i < NBR_OF_TX_DESC; i++) {
+		TxDescList[i].descr.ctrl   = 0;
+		TxDescList[i].descr.sw_len = 0;
+		TxDescList[i].descr.next   = virt_to_phys(&TxDescList[i + 1].descr);
+		TxDescList[i].descr.buf    = 0;
+		TxDescList[i].descr.status = 0;
+		TxDescList[i].descr.hw_len = 0;
+		TxDescList[i].skb = 0;
+	}
+
+	TxDescList[NBR_OF_TX_DESC - 1].descr.ctrl   = d_eol;
+	TxDescList[NBR_OF_TX_DESC - 1].descr.next   = virt_to_phys(&TxDescList[0].descr);
+
+	/* Initialise initial pointers */
+
+	myNextRxDesc  = &RxDescList[0];
+	myLastRxDesc  = &RxDescList[NBR_OF_RX_DESC - 1];
+	myFirstTxDesc = &TxDescList[0];
+	myNextTxDesc  = &TxDescList[0];
+	myLastTxDesc  = &TxDescList[NBR_OF_TX_DESC - 1];
+
+	/* Register device */
+	err = register_netdev(dev);
+	if (err) {
+		free_netdev(dev);
+		return err;
+	}
+
+	/* set the default MAC address */
+
+	e100_set_mac_address(dev, &default_mac);
+
+	/* Initialize speed indicator stuff. */
+
+	current_speed = 10;
+	current_speed_selection = 0; /* Auto */
+	speed_timer.expires = jiffies + NET_LINK_UP_CHECK_INTERVAL;
+	speed_timer.data = (unsigned long)dev;
+	speed_timer.function = e100_check_speed;
+
+	clear_led_timer.function = e100_clear_network_leds;
+	clear_led_timer.data = (unsigned long)dev;
+
+	full_duplex = 0;
+	current_duplex = autoneg;
+	duplex_timer.expires = jiffies + NET_DUPLEX_CHECK_INTERVAL;
+        duplex_timer.data = (unsigned long)dev;
+	duplex_timer.function = e100_check_duplex;
+
+        /* Initialize mii interface */
+	np->mii_if.phy_id_mask = 0x1f;
+	np->mii_if.reg_num_mask = 0x1f;
+	np->mii_if.dev = dev;
+	np->mii_if.mdio_read = e100_get_mdio_reg;
+	np->mii_if.mdio_write = e100_set_mdio_reg;
+
+	/* Initialize group address registers to make sure that no */
+	/* unwanted addresses are matched */
+	*R_NETWORK_GA_0 = 0x00000000;
+	*R_NETWORK_GA_1 = 0x00000000;
+
+	/* Initialize next time the led can flash */
+	led_next_time = jiffies;
+	return 0;
+}
+
+/* set MAC address of the interface. called from the core after a
+ * SIOCSIFADDR ioctl, and from the bootup above.
+ */
+
+static int
+e100_set_mac_address(struct net_device *dev, void *p)
+{
+	struct net_local *np = netdev_priv(dev);
+	struct sockaddr *addr = p;
+
+	spin_lock(&np->lock); /* preemption protection */
+
+	/* remember it */
+
+	memcpy(dev->dev_addr, addr->sa_data, dev->addr_len);
+
+	/* Write it to the hardware.
+	 * Note the way the address is wrapped:
+	 * *R_NETWORK_SA_0 = a0_0 | (a0_1 << 8) | (a0_2 << 16) | (a0_3 << 24);
+	 * *R_NETWORK_SA_1 = a0_4 | (a0_5 << 8);
+	 */
+
+	*R_NETWORK_SA_0 = dev->dev_addr[0] | (dev->dev_addr[1] << 8) |
+		(dev->dev_addr[2] << 16) | (dev->dev_addr[3] << 24);
+	*R_NETWORK_SA_1 = dev->dev_addr[4] | (dev->dev_addr[5] << 8);
+	*R_NETWORK_SA_2 = 0;
+
+	/* show it in the log as well */
+
+	printk(KERN_INFO "%s: changed MAC to %pM\n", dev->name, dev->dev_addr);
+
+	spin_unlock(&np->lock);
+
+	return 0;
+}
+
+/*
+ * Open/initialize the board. This is called (in the current kernel)
+ * sometime after booting when the 'ifconfig' program is run.
+ *
+ * This routine should set everything up anew at each open, even
+ * registers that "should" only need to be set once at boot, so that
+ * there is non-reboot way to recover if something goes wrong.
+ */
+
+static int
+e100_open(struct net_device *dev)
+{
+	unsigned long flags;
+
+	/* enable the MDIO output pin */
+
+	*R_NETWORK_MGM_CTRL = IO_STATE(R_NETWORK_MGM_CTRL, mdoe, enable);
+
+	*R_IRQ_MASK0_CLR =
+		IO_STATE(R_IRQ_MASK0_CLR, overrun, clr) |
+		IO_STATE(R_IRQ_MASK0_CLR, underrun, clr) |
+		IO_STATE(R_IRQ_MASK0_CLR, excessive_col, clr);
+
+	/* clear dma0 and 1 eop and descr irq masks */
+	*R_IRQ_MASK2_CLR =
+		IO_STATE(R_IRQ_MASK2_CLR, dma0_descr, clr) |
+		IO_STATE(R_IRQ_MASK2_CLR, dma0_eop, clr) |
+		IO_STATE(R_IRQ_MASK2_CLR, dma1_descr, clr) |
+		IO_STATE(R_IRQ_MASK2_CLR, dma1_eop, clr);
+
+	/* Reset and wait for the DMA channels */
+
+	RESET_DMA(NETWORK_TX_DMA_NBR);
+	RESET_DMA(NETWORK_RX_DMA_NBR);
+	WAIT_DMA(NETWORK_TX_DMA_NBR);
+	WAIT_DMA(NETWORK_RX_DMA_NBR);
+
+	/* Initialise the etrax network controller */
+
+	/* allocate the irq corresponding to the receiving DMA */
+
+	if (request_irq(NETWORK_DMA_RX_IRQ_NBR, e100rxtx_interrupt,
+			IRQF_SAMPLE_RANDOM, cardname, (void *)dev)) {
+		goto grace_exit0;
+	}
+
+	/* allocate the irq corresponding to the transmitting DMA */
+
+	if (request_irq(NETWORK_DMA_TX_IRQ_NBR, e100rxtx_interrupt, 0,
+			cardname, (void *)dev)) {
+		goto grace_exit1;
+	}
+
+	/* allocate the irq corresponding to the network errors etc */
+
+	if (request_irq(NETWORK_STATUS_IRQ_NBR, e100nw_interrupt, 0,
+			cardname, (void *)dev)) {
+		goto grace_exit2;
+	}
+
+	/*
+	 * Always allocate the DMA channels after the IRQ,
+	 * and clean up on failure.
+	 */
+
+	if (cris_request_dma(NETWORK_TX_DMA_NBR,
+	                     cardname,
+	                     DMA_VERBOSE_ON_ERROR,
+	                     dma_eth)) {
+		goto grace_exit3;
+        }
+
+	if (cris_request_dma(NETWORK_RX_DMA_NBR,
+	                     cardname,
+	                     DMA_VERBOSE_ON_ERROR,
+	                     dma_eth)) {
+		goto grace_exit4;
+        }
+
+	/* give the HW an idea of what MAC address we want */
+
+	*R_NETWORK_SA_0 = dev->dev_addr[0] | (dev->dev_addr[1] << 8) |
+		(dev->dev_addr[2] << 16) | (dev->dev_addr[3] << 24);
+	*R_NETWORK_SA_1 = dev->dev_addr[4] | (dev->dev_addr[5] << 8);
+	*R_NETWORK_SA_2 = 0;
+
+#if 0
+	/* use promiscuous mode for testing */
+	*R_NETWORK_GA_0 = 0xffffffff;
+	*R_NETWORK_GA_1 = 0xffffffff;
+
+	*R_NETWORK_REC_CONFIG = 0xd; /* broadcast rec, individ. rec, ma0 enabled */
+#else
+	SETS(network_rec_config_shadow, R_NETWORK_REC_CONFIG, max_size, size1522);
+	SETS(network_rec_config_shadow, R_NETWORK_REC_CONFIG, broadcast, receive);
+	SETS(network_rec_config_shadow, R_NETWORK_REC_CONFIG, ma0, enable);
+	SETF(network_rec_config_shadow, R_NETWORK_REC_CONFIG, duplex, full_duplex);
+	*R_NETWORK_REC_CONFIG = network_rec_config_shadow;
+#endif
+
+	*R_NETWORK_GEN_CONFIG =
+		IO_STATE(R_NETWORK_GEN_CONFIG, phy,    mii_clk) |
+		IO_STATE(R_NETWORK_GEN_CONFIG, enable, on);
+
+	SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, clr_error, clr);
+	SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, delay, none);
+	SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, cancel, dont);
+	SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, cd, enable);
+	SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, retry, enable);
+	SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, pad, enable);
+	SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, crc, enable);
+	*R_NETWORK_TR_CTRL = network_tr_ctrl_shadow;
+
+	local_irq_save(flags);
+
+	/* enable the irq's for ethernet DMA */
+
+	*R_IRQ_MASK2_SET =
+		IO_STATE(R_IRQ_MASK2_SET, dma0_eop, set) |
+		IO_STATE(R_IRQ_MASK2_SET, dma1_eop, set);
+
+	*R_IRQ_MASK0_SET =
+		IO_STATE(R_IRQ_MASK0_SET, overrun,       set) |
+		IO_STATE(R_IRQ_MASK0_SET, underrun,      set) |
+		IO_STATE(R_IRQ_MASK0_SET, excessive_col, set);
+
+	/* make sure the irqs are cleared */
+
+	*R_DMA_CH0_CLR_INTR = IO_STATE(R_DMA_CH0_CLR_INTR, clr_eop, do);
+	*R_DMA_CH1_CLR_INTR = IO_STATE(R_DMA_CH1_CLR_INTR, clr_eop, do);
+
+	/* make sure the rec and transmit error counters are cleared */
+
+	(void)*R_REC_COUNTERS;  /* dummy read */
+	(void)*R_TR_COUNTERS;   /* dummy read */
+
+	/* start the receiving DMA channel so we can receive packets from now on */
+
+	*R_DMA_CH1_FIRST = virt_to_phys(myNextRxDesc);
+	*R_DMA_CH1_CMD = IO_STATE(R_DMA_CH1_CMD, cmd, start);
+
+	/* Set up transmit DMA channel so it can be restarted later */
+
+	*R_DMA_CH0_FIRST = 0;
+	*R_DMA_CH0_DESCR = virt_to_phys(myLastTxDesc);
+	netif_start_queue(dev);
+
+	local_irq_restore(flags);
+
+	/* Probe for transceiver */
+	if (e100_probe_transceiver(dev))
+		goto grace_exit5;
+
+	/* Start duplex/speed timers */
+	add_timer(&speed_timer);
+	add_timer(&duplex_timer);
+
+	/* We are now ready to accept transmit requeusts from
+	 * the queueing layer of the networking.
+	 */
+	netif_carrier_on(dev);
+
+	return 0;
+
+grace_exit5:
+	cris_free_dma(NETWORK_RX_DMA_NBR, cardname);
+grace_exit4:
+	cris_free_dma(NETWORK_TX_DMA_NBR, cardname);
+grace_exit3:
+	free_irq(NETWORK_STATUS_IRQ_NBR, (void *)dev);
+grace_exit2:
+	free_irq(NETWORK_DMA_TX_IRQ_NBR, (void *)dev);
+grace_exit1:
+	free_irq(NETWORK_DMA_RX_IRQ_NBR, (void *)dev);
+grace_exit0:
+	return -EAGAIN;
+}
+
+#if defined(CONFIG_ETRAX_NO_PHY)
+static void
+dummy_check_speed(struct net_device* dev)
+{
+	current_speed = 100;
+}
+#else
+static void
+generic_check_speed(struct net_device* dev)
+{
+	unsigned long data;
+	struct net_local *np = netdev_priv(dev);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id, MII_ADVERTISE);
+	if ((data & ADVERTISE_100FULL) ||
+	    (data & ADVERTISE_100HALF))
+		current_speed = 100;
+	else
+		current_speed = 10;
+}
+
+static void
+tdk_check_speed(struct net_device* dev)
+{
+	unsigned long data;
+	struct net_local *np = netdev_priv(dev);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id,
+				 MDIO_TDK_DIAGNOSTIC_REG);
+	current_speed = (data & MDIO_TDK_DIAGNOSTIC_RATE ? 100 : 10);
+}
+
+static void
+broadcom_check_speed(struct net_device* dev)
+{
+	unsigned long data;
+	struct net_local *np = netdev_priv(dev);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id,
+				 MDIO_AUX_CTRL_STATUS_REG);
+	current_speed = (data & MDIO_BC_SPEED ? 100 : 10);
+}
+
+static void
+intel_check_speed(struct net_device* dev)
+{
+	unsigned long data;
+	struct net_local *np = netdev_priv(dev);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id,
+				 MDIO_INT_STATUS_REG_2);
+	current_speed = (data & MDIO_INT_SPEED ? 100 : 10);
+}
+#endif
+static void
+e100_check_speed(unsigned long priv)
+{
+	struct net_device* dev = (struct net_device*)priv;
+	struct net_local *np = netdev_priv(dev);
+	static int led_initiated = 0;
+	unsigned long data;
+	int old_speed = current_speed;
+
+	spin_lock(&np->transceiver_lock);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id, MII_BMSR);
+	if (!(data & BMSR_LSTATUS)) {
+		current_speed = 0;
+	} else {
+		transceiver->check_speed(dev);
+	}
+
+	spin_lock(&np->led_lock);
+	if ((old_speed != current_speed) || !led_initiated) {
+		led_initiated = 1;
+		e100_set_network_leds(NO_NETWORK_ACTIVITY);
+		if (current_speed)
+			netif_carrier_on(dev);
+		else
+			netif_carrier_off(dev);
+	}
+	spin_unlock(&np->led_lock);
+
+	/* Reinitialize the timer. */
+	speed_timer.expires = jiffies + NET_LINK_UP_CHECK_INTERVAL;
+	add_timer(&speed_timer);
+
+	spin_unlock(&np->transceiver_lock);
+}
+
+static void
+e100_negotiate(struct net_device* dev)
+{
+	struct net_local *np = netdev_priv(dev);
+	unsigned short data = e100_get_mdio_reg(dev, np->mii_if.phy_id,
+						MII_ADVERTISE);
+
+	/* Discard old speed and duplex settings */
+	data &= ~(ADVERTISE_100HALF | ADVERTISE_100FULL |
+	          ADVERTISE_10HALF | ADVERTISE_10FULL);
+
+	switch (current_speed_selection) {
+		case 10:
+			if (current_duplex == full)
+				data |= ADVERTISE_10FULL;
+			else if (current_duplex == half)
+				data |= ADVERTISE_10HALF;
+			else
+				data |= ADVERTISE_10HALF | ADVERTISE_10FULL;
+			break;
+
+		case 100:
+			 if (current_duplex == full)
+				data |= ADVERTISE_100FULL;
+			else if (current_duplex == half)
+				data |= ADVERTISE_100HALF;
+			else
+				data |= ADVERTISE_100HALF | ADVERTISE_100FULL;
+			break;
+
+		case 0: /* Auto */
+			 if (current_duplex == full)
+				data |= ADVERTISE_100FULL | ADVERTISE_10FULL;
+			else if (current_duplex == half)
+				data |= ADVERTISE_100HALF | ADVERTISE_10HALF;
+			else
+				data |= ADVERTISE_10HALF | ADVERTISE_10FULL |
+				  ADVERTISE_100HALF | ADVERTISE_100FULL;
+			break;
+
+		default: /* assume autoneg speed and duplex */
+			data |= ADVERTISE_10HALF | ADVERTISE_10FULL |
+				  ADVERTISE_100HALF | ADVERTISE_100FULL;
+			break;
+	}
+
+	e100_set_mdio_reg(dev, np->mii_if.phy_id, MII_ADVERTISE, data);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id, MII_BMCR);
+	if (autoneg_normal) {
+		/* Renegotiate with link partner */
+		data |= BMCR_ANENABLE | BMCR_ANRESTART;
+	} else {
+		/* Don't negotiate speed or duplex */
+		data &= ~(BMCR_ANENABLE | BMCR_ANRESTART);
+
+		/* Set speed and duplex static */
+		if (current_speed_selection == 10)
+			data &= ~BMCR_SPEED100;
+		else
+			data |= BMCR_SPEED100;
+
+		if (current_duplex != full)
+			data &= ~BMCR_FULLDPLX;
+		else
+			data |= BMCR_FULLDPLX;
+	}
+	e100_set_mdio_reg(dev, np->mii_if.phy_id, MII_BMCR, data);
+}
+
+static void
+e100_set_speed(struct net_device* dev, unsigned long speed)
+{
+	struct net_local *np = netdev_priv(dev);
+
+	spin_lock(&np->transceiver_lock);
+	if (speed != current_speed_selection) {
+		current_speed_selection = speed;
+		e100_negotiate(dev);
+	}
+	spin_unlock(&np->transceiver_lock);
+}
+
+static void
+e100_check_duplex(unsigned long priv)
+{
+	struct net_device *dev = (struct net_device *)priv;
+	struct net_local *np = netdev_priv(dev);
+	int old_duplex;
+
+	spin_lock(&np->transceiver_lock);
+	old_duplex = full_duplex;
+	transceiver->check_duplex(dev);
+	if (old_duplex != full_duplex) {
+		/* Duplex changed */
+		SETF(network_rec_config_shadow, R_NETWORK_REC_CONFIG, duplex, full_duplex);
+		*R_NETWORK_REC_CONFIG = network_rec_config_shadow;
+	}
+
+	/* Reinitialize the timer. */
+	duplex_timer.expires = jiffies + NET_DUPLEX_CHECK_INTERVAL;
+	add_timer(&duplex_timer);
+	np->mii_if.full_duplex = full_duplex;
+	spin_unlock(&np->transceiver_lock);
+}
+#if defined(CONFIG_ETRAX_NO_PHY)
+static void
+dummy_check_duplex(struct net_device* dev)
+{
+	full_duplex = 1;
+}
+#else
+static void
+generic_check_duplex(struct net_device* dev)
+{
+	unsigned long data;
+	struct net_local *np = netdev_priv(dev);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id, MII_ADVERTISE);
+	if ((data & ADVERTISE_10FULL) ||
+	    (data & ADVERTISE_100FULL))
+		full_duplex = 1;
+	else
+		full_duplex = 0;
+}
+
+static void
+tdk_check_duplex(struct net_device* dev)
+{
+	unsigned long data;
+	struct net_local *np = netdev_priv(dev);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id,
+				 MDIO_TDK_DIAGNOSTIC_REG);
+	full_duplex = (data & MDIO_TDK_DIAGNOSTIC_DPLX) ? 1 : 0;
+}
+
+static void
+broadcom_check_duplex(struct net_device* dev)
+{
+	unsigned long data;
+	struct net_local *np = netdev_priv(dev);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id,
+				 MDIO_AUX_CTRL_STATUS_REG);
+	full_duplex = (data & MDIO_BC_FULL_DUPLEX_IND) ? 1 : 0;
+}
+
+static void
+intel_check_duplex(struct net_device* dev)
+{
+	unsigned long data;
+	struct net_local *np = netdev_priv(dev);
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id,
+				 MDIO_INT_STATUS_REG_2);
+	full_duplex = (data & MDIO_INT_FULL_DUPLEX_IND) ? 1 : 0;
+}
+#endif
+static void
+e100_set_duplex(struct net_device* dev, enum duplex new_duplex)
+{
+	struct net_local *np = netdev_priv(dev);
+
+	spin_lock(&np->transceiver_lock);
+	if (new_duplex != current_duplex) {
+		current_duplex = new_duplex;
+		e100_negotiate(dev);
+	}
+	spin_unlock(&np->transceiver_lock);
+}
+
+static int
+e100_probe_transceiver(struct net_device* dev)
+{
+	int ret = 0;
+
+#if !defined(CONFIG_ETRAX_NO_PHY)
+	unsigned int phyid_high;
+	unsigned int phyid_low;
+	unsigned int oui;
+	struct transceiver_ops* ops = NULL;
+	struct net_local *np = netdev_priv(dev);
+
+	spin_lock(&np->transceiver_lock);
+
+	/* Probe MDIO physical address */
+	for (np->mii_if.phy_id = 0; np->mii_if.phy_id <= 31;
+	     np->mii_if.phy_id++) {
+		if (e100_get_mdio_reg(dev,
+				      np->mii_if.phy_id, MII_BMSR) != 0xffff)
+			break;
+	}
+	if (np->mii_if.phy_id == 32) {
+		ret = -ENODEV;
+		goto out;
+	}
+
+	/* Get manufacturer */
+	phyid_high = e100_get_mdio_reg(dev, np->mii_if.phy_id, MII_PHYSID1);
+	phyid_low = e100_get_mdio_reg(dev, np->mii_if.phy_id, MII_PHYSID2);
+	oui = (phyid_high << 6) | (phyid_low >> 10);
+
+	for (ops = &transceivers[0]; ops->oui; ops++) {
+		if (ops->oui == oui)
+			break;
+	}
+	transceiver = ops;
+out:
+	spin_unlock(&np->transceiver_lock);
+#endif
+	return ret;
+}
+
+static int
+e100_get_mdio_reg(struct net_device *dev, int phy_id, int location)
+{
+	unsigned short cmd;    /* Data to be sent on MDIO port */
+	int data;   /* Data read from MDIO */
+	int bitCounter;
+
+	/* Start of frame, OP Code, Physical Address, Register Address */
+	cmd = (MDIO_START << 14) | (MDIO_READ << 12) | (phy_id << 7) |
+		(location << 2);
+
+	e100_send_mdio_cmd(cmd, 0);
+
+	data = 0;
+
+	/* Data... */
+	for (bitCounter=15; bitCounter>=0 ; bitCounter--) {
+		data |= (e100_receive_mdio_bit() << bitCounter);
+	}
+
+	return data;
+}
+
+static void
+e100_set_mdio_reg(struct net_device *dev, int phy_id, int location, int value)
+{
+	int bitCounter;
+	unsigned short cmd;
+
+	cmd = (MDIO_START << 14) | (MDIO_WRITE << 12) | (phy_id << 7) |
+	      (location << 2);
+
+	e100_send_mdio_cmd(cmd, 1);
+
+	/* Data... */
+	for (bitCounter=15; bitCounter>=0 ; bitCounter--) {
+		e100_send_mdio_bit(GET_BIT(bitCounter, value));
+	}
+
+}
+
+static void
+e100_send_mdio_cmd(unsigned short cmd, int write_cmd)
+{
+	int bitCounter;
+	unsigned char data = 0x2;
+
+	/* Preamble */
+	for (bitCounter = 31; bitCounter>= 0; bitCounter--)
+		e100_send_mdio_bit(GET_BIT(bitCounter, MDIO_PREAMBLE));
+
+	for (bitCounter = 15; bitCounter >= 2; bitCounter--)
+		e100_send_mdio_bit(GET_BIT(bitCounter, cmd));
+
+	/* Turnaround */
+	for (bitCounter = 1; bitCounter >= 0 ; bitCounter--)
+		if (write_cmd)
+			e100_send_mdio_bit(GET_BIT(bitCounter, data));
+		else
+			e100_receive_mdio_bit();
+}
+
+static void
+e100_send_mdio_bit(unsigned char bit)
+{
+	*R_NETWORK_MGM_CTRL =
+		IO_STATE(R_NETWORK_MGM_CTRL, mdoe, enable) |
+		IO_FIELD(R_NETWORK_MGM_CTRL, mdio, bit);
+	udelay(1);
+	*R_NETWORK_MGM_CTRL =
+		IO_STATE(R_NETWORK_MGM_CTRL, mdoe, enable) |
+		IO_MASK(R_NETWORK_MGM_CTRL, mdck) |
+		IO_FIELD(R_NETWORK_MGM_CTRL, mdio, bit);
+	udelay(1);
+}
+
+static unsigned char
+e100_receive_mdio_bit()
+{
+	unsigned char bit;
+	*R_NETWORK_MGM_CTRL = 0;
+	bit = IO_EXTRACT(R_NETWORK_STAT, mdio, *R_NETWORK_STAT);
+	udelay(1);
+	*R_NETWORK_MGM_CTRL = IO_MASK(R_NETWORK_MGM_CTRL, mdck);
+	udelay(1);
+	return bit;
+}
+
+static void
+e100_reset_transceiver(struct net_device* dev)
+{
+	struct net_local *np = netdev_priv(dev);
+	unsigned short cmd;
+	unsigned short data;
+	int bitCounter;
+
+	data = e100_get_mdio_reg(dev, np->mii_if.phy_id, MII_BMCR);
+
+	cmd = (MDIO_START << 14) | (MDIO_WRITE << 12) | (np->mii_if.phy_id << 7) | (MII_BMCR << 2);
+
+	e100_send_mdio_cmd(cmd, 1);
+
+	data |= 0x8000;
+
+	for (bitCounter = 15; bitCounter >= 0 ; bitCounter--) {
+		e100_send_mdio_bit(GET_BIT(bitCounter, data));
+	}
+}
+
+/* Called by upper layers if they decide it took too long to complete
+ * sending a packet - we need to reset and stuff.
+ */
+
+static void
+e100_tx_timeout(struct net_device *dev)
+{
+	struct net_local *np = netdev_priv(dev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&np->lock, flags);
+
+	printk(KERN_WARNING "%s: transmit timed out, %s?\n", dev->name,
+	       tx_done(dev) ? "IRQ problem" : "network cable problem");
+
+	/* remember we got an error */
+
+	dev->stats.tx_errors++;
+
+	/* reset the TX DMA in case it has hung on something */
+
+	RESET_DMA(NETWORK_TX_DMA_NBR);
+	WAIT_DMA(NETWORK_TX_DMA_NBR);
+
+	/* Reset the transceiver. */
+
+	e100_reset_transceiver(dev);
+
+	/* and get rid of the packets that never got an interrupt */
+	while (myFirstTxDesc != myNextTxDesc) {
+		dev_kfree_skb(myFirstTxDesc->skb);
+		myFirstTxDesc->skb = 0;
+		myFirstTxDesc = phys_to_virt(myFirstTxDesc->descr.next);
+	}
+
+	/* Set up transmit DMA channel so it can be restarted later */
+	*R_DMA_CH0_FIRST = 0;
+	*R_DMA_CH0_DESCR = virt_to_phys(myLastTxDesc);
+
+	/* tell the upper layers we're ok again */
+
+	netif_wake_queue(dev);
+	spin_unlock_irqrestore(&np->lock, flags);
+}
+
+
+/* This will only be invoked if the driver is _not_ in XOFF state.
+ * What this means is that we need not check it, and that this
+ * invariant will hold if we make sure that the netif_*_queue()
+ * calls are done at the proper times.
+ */
+
+static int
+e100_send_packet(struct sk_buff *skb, struct net_device *dev)
+{
+	struct net_local *np = netdev_priv(dev);
+	unsigned char *buf = skb->data;
+	unsigned long flags;
+
+#ifdef ETHDEBUG
+	printk("send packet len %d\n", length);
+#endif
+	spin_lock_irqsave(&np->lock, flags);  /* protect from tx_interrupt and ourself */
+
+	myNextTxDesc->skb = skb;
+
+	dev->trans_start = jiffies; /* NETIF_F_LLTX driver :( */
+
+	e100_hardware_send_packet(np, buf, skb->len);
+
+	myNextTxDesc = phys_to_virt(myNextTxDesc->descr.next);
+
+	/* Stop queue if full */
+	if (myNextTxDesc == myFirstTxDesc) {
+		netif_stop_queue(dev);
+	}
+
+	spin_unlock_irqrestore(&np->lock, flags);
+
+	return NETDEV_TX_OK;
+}
+
+/*
+ * The typical workload of the driver:
+ *   Handle the network interface interrupts.
+ */
+
+static irqreturn_t
+e100rxtx_interrupt(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *)dev_id;
+	struct net_local *np = netdev_priv(dev);
+	unsigned long irqbits;
+
+	/*
+	 * Note that both rx and tx interrupts are blocked at this point,
+	 * regardless of which got us here.
+	 */
+
+	irqbits = *R_IRQ_MASK2_RD;
+
+	/* Handle received packets */
+	if (irqbits & IO_STATE(R_IRQ_MASK2_RD, dma1_eop, active)) {
+		/* acknowledge the eop interrupt */
+
+		*R_DMA_CH1_CLR_INTR = IO_STATE(R_DMA_CH1_CLR_INTR, clr_eop, do);
+
+		/* check if one or more complete packets were indeed received */
+
+		while ((*R_DMA_CH1_FIRST != virt_to_phys(myNextRxDesc)) &&
+		       (myNextRxDesc != myLastRxDesc)) {
+			/* Take out the buffer and give it to the OS, then
+			 * allocate a new buffer to put a packet in.
+			 */
+			e100_rx(dev);
+			dev->stats.rx_packets++;
+			/* restart/continue on the channel, for safety */
+			*R_DMA_CH1_CMD = IO_STATE(R_DMA_CH1_CMD, cmd, restart);
+			/* clear dma channel 1 eop/descr irq bits */
+			*R_DMA_CH1_CLR_INTR =
+				IO_STATE(R_DMA_CH1_CLR_INTR, clr_eop, do) |
+				IO_STATE(R_DMA_CH1_CLR_INTR, clr_descr, do);
+
+			/* now, we might have gotten another packet
+			   so we have to loop back and check if so */
+		}
+	}
+
+	/* Report any packets that have been sent */
+	while (virt_to_phys(myFirstTxDesc) != *R_DMA_CH0_FIRST &&
+	       (netif_queue_stopped(dev) || myFirstTxDesc != myNextTxDesc)) {
+		dev->stats.tx_bytes += myFirstTxDesc->skb->len;
+		dev->stats.tx_packets++;
+
+		/* dma is ready with the transmission of the data in tx_skb, so now
+		   we can release the skb memory */
+		dev_kfree_skb_irq(myFirstTxDesc->skb);
+		myFirstTxDesc->skb = 0;
+		myFirstTxDesc = phys_to_virt(myFirstTxDesc->descr.next);
+                /* Wake up queue. */
+		netif_wake_queue(dev);
+	}
+
+	if (irqbits & IO_STATE(R_IRQ_MASK2_RD, dma0_eop, active)) {
+		/* acknowledge the eop interrupt. */
+		*R_DMA_CH0_CLR_INTR = IO_STATE(R_DMA_CH0_CLR_INTR, clr_eop, do);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t
+e100nw_interrupt(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *)dev_id;
+	unsigned long irqbits = *R_IRQ_MASK0_RD;
+
+	/* check for underrun irq */
+	if (irqbits & IO_STATE(R_IRQ_MASK0_RD, underrun, active)) {
+		SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, clr_error, clr);
+		*R_NETWORK_TR_CTRL = network_tr_ctrl_shadow;
+		SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, clr_error, nop);
+		dev->stats.tx_errors++;
+		D(printk("ethernet receiver underrun!\n"));
+	}
+
+	/* check for overrun irq */
+	if (irqbits & IO_STATE(R_IRQ_MASK0_RD, overrun, active)) {
+		update_rx_stats(&dev->stats); /* this will ack the irq */
+		D(printk("ethernet receiver overrun!\n"));
+	}
+	/* check for excessive collision irq */
+	if (irqbits & IO_STATE(R_IRQ_MASK0_RD, excessive_col, active)) {
+		SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, clr_error, clr);
+		*R_NETWORK_TR_CTRL = network_tr_ctrl_shadow;
+		SETS(network_tr_ctrl_shadow, R_NETWORK_TR_CTRL, clr_error, nop);
+		dev->stats.tx_errors++;
+		D(printk("ethernet excessive collisions!\n"));
+	}
+	return IRQ_HANDLED;
+}
+
+/* We have a good packet(s), get it/them out of the buffers. */
+static void
+e100_rx(struct net_device *dev)
+{
+	struct sk_buff *skb;
+	int length = 0;
+	struct net_local *np = netdev_priv(dev);
+	unsigned char *skb_data_ptr;
+#ifdef ETHDEBUG
+	int i;
+#endif
+	etrax_eth_descr *prevRxDesc;  /* The descriptor right before myNextRxDesc */
+	spin_lock(&np->led_lock);
+	if (!led_active && time_after(jiffies, led_next_time)) {
+		/* light the network leds depending on the current speed. */
+		e100_set_network_leds(NETWORK_ACTIVITY);
+
+		/* Set the earliest time we may clear the LED */
+		led_next_time = jiffies + NET_FLASH_TIME;
+		led_active = 1;
+		mod_timer(&clear_led_timer, jiffies + HZ/10);
+	}
+	spin_unlock(&np->led_lock);
+
+	length = myNextRxDesc->descr.hw_len - 4;
+	dev->stats.rx_bytes += length;
+
+#ifdef ETHDEBUG
+	printk("Got a packet of length %d:\n", length);
+	/* dump the first bytes in the packet */
+	skb_data_ptr = (unsigned char *)phys_to_virt(myNextRxDesc->descr.buf);
+	for (i = 0; i < 8; i++) {
+		printk("%d: %.2x %.2x %.2x %.2x %.2x %.2x %.2x %.2x\n", i * 8,
+		       skb_data_ptr[0],skb_data_ptr[1],skb_data_ptr[2],skb_data_ptr[3],
+		       skb_data_ptr[4],skb_data_ptr[5],skb_data_ptr[6],skb_data_ptr[7]);
+		skb_data_ptr += 8;
+	}
+#endif
+
+	if (length < RX_COPYBREAK) {
+		/* Small packet, copy data */
+		skb = dev_alloc_skb(length - ETHER_HEAD_LEN);
+		if (!skb) {
+			dev->stats.rx_errors++;
+			printk(KERN_NOTICE "%s: Memory squeeze, dropping packet.\n", dev->name);
+			goto update_nextrxdesc;
+		}
+
+		skb_put(skb, length - ETHER_HEAD_LEN);        /* allocate room for the packet body */
+		skb_data_ptr = skb_push(skb, ETHER_HEAD_LEN); /* allocate room for the header */
+
+#ifdef ETHDEBUG
+		printk("head = 0x%x, data = 0x%x, tail = 0x%x, end = 0x%x\n",
+		       skb->head, skb->data, skb_tail_pointer(skb),
+		       skb_end_pointer(skb));
+		printk("copying packet to 0x%x.\n", skb_data_ptr);
+#endif
+
+		memcpy(skb_data_ptr, phys_to_virt(myNextRxDesc->descr.buf), length);
+	}
+	else {
+		/* Large packet, send directly to upper layers and allocate new
+		 * memory (aligned to cache line boundary to avoid bug).
+		 * Before sending the skb to upper layers we must make sure
+		 * that skb->data points to the aligned start of the packet.
+		 */
+		int align;
+		struct sk_buff *new_skb = dev_alloc_skb(MAX_MEDIA_DATA_SIZE + 2 * L1_CACHE_BYTES);
+		if (!new_skb) {
+			dev->stats.rx_errors++;
+			printk(KERN_NOTICE "%s: Memory squeeze, dropping packet.\n", dev->name);
+			goto update_nextrxdesc;
+		}
+		skb = myNextRxDesc->skb;
+		align = (int)phys_to_virt(myNextRxDesc->descr.buf) - (int)skb->data;
+		skb_put(skb, length + align);
+		skb_pull(skb, align); /* Remove alignment bytes */
+		myNextRxDesc->skb = new_skb;
+		myNextRxDesc->descr.buf = L1_CACHE_ALIGN(virt_to_phys(myNextRxDesc->skb->data));
+	}
+
+	skb->protocol = eth_type_trans(skb, dev);
+
+	/* Send the packet to the upper layers */
+	netif_rx(skb);
+
+  update_nextrxdesc:
+	/* Prepare for next packet */
+	myNextRxDesc->descr.status = 0;
+	prevRxDesc = myNextRxDesc;
+	myNextRxDesc = phys_to_virt(myNextRxDesc->descr.next);
+
+	rx_queue_len++;
+
+	/* Check if descriptors should be returned */
+	if (rx_queue_len == RX_QUEUE_THRESHOLD) {
+		flush_etrax_cache();
+		prevRxDesc->descr.ctrl |= d_eol;
+		myLastRxDesc->descr.ctrl &= ~d_eol;
+		myLastRxDesc = prevRxDesc;
+		rx_queue_len = 0;
+	}
+}
+
+/* The inverse routine to net_open(). */
+static int
+e100_close(struct net_device *dev)
+{
+	printk(KERN_INFO "Closing %s.\n", dev->name);
+
+	netif_stop_queue(dev);
+
+	*R_IRQ_MASK0_CLR =
+		IO_STATE(R_IRQ_MASK0_CLR, overrun, clr) |
+		IO_STATE(R_IRQ_MASK0_CLR, underrun, clr) |
+		IO_STATE(R_IRQ_MASK0_CLR, excessive_col, clr);
+
+	*R_IRQ_MASK2_CLR =
+		IO_STATE(R_IRQ_MASK2_CLR, dma0_descr, clr) |
+		IO_STATE(R_IRQ_MASK2_CLR, dma0_eop, clr) |
+		IO_STATE(R_IRQ_MASK2_CLR, dma1_descr, clr) |
+		IO_STATE(R_IRQ_MASK2_CLR, dma1_eop, clr);
+
+	/* Stop the receiver and the transmitter */
+
+	RESET_DMA(NETWORK_TX_DMA_NBR);
+	RESET_DMA(NETWORK_RX_DMA_NBR);
+
+	/* Flush the Tx and disable Rx here. */
+
+	free_irq(NETWORK_DMA_RX_IRQ_NBR, (void *)dev);
+	free_irq(NETWORK_DMA_TX_IRQ_NBR, (void *)dev);
+	free_irq(NETWORK_STATUS_IRQ_NBR, (void *)dev);
+
+	cris_free_dma(NETWORK_TX_DMA_NBR, cardname);
+	cris_free_dma(NETWORK_RX_DMA_NBR, cardname);
+
+	/* Update the statistics here. */
+
+	update_rx_stats(&dev->stats);
+	update_tx_stats(&dev->stats);
+
+	/* Stop speed/duplex timers */
+	del_timer(&speed_timer);
+	del_timer(&duplex_timer);
+
+	return 0;
+}
+
+static int
+e100_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+	struct mii_ioctl_data *data = if_mii(ifr);
+	struct net_local *np = netdev_priv(dev);
+	int rc = 0;
+        int old_autoneg;
+
+	spin_lock(&np->lock); /* Preempt protection */
+	switch (cmd) {
+		/* The ioctls below should be considered obsolete but are */
+		/* still present for compatibility with old scripts/apps  */
+		case SET_ETH_SPEED_10:                  /* 10 Mbps */
+			e100_set_speed(dev, 10);
+			break;
+		case SET_ETH_SPEED_100:                /* 100 Mbps */
+			e100_set_speed(dev, 100);
+			break;
+		case SET_ETH_SPEED_AUTO:        /* Auto-negotiate speed */
+			e100_set_speed(dev, 0);
+			break;
+		case SET_ETH_DUPLEX_HALF:       /* Half duplex */
+			e100_set_duplex(dev, half);
+			break;
+		case SET_ETH_DUPLEX_FULL:       /* Full duplex */
+			e100_set_duplex(dev, full);
+			break;
+		case SET_ETH_DUPLEX_AUTO:       /* Auto-negotiate duplex */
+			e100_set_duplex(dev, autoneg);
+			break;
+	        case SET_ETH_AUTONEG:
+			old_autoneg = autoneg_normal;
+		        autoneg_normal = *(int*)data;
+			if (autoneg_normal != old_autoneg)
+				e100_negotiate(dev);
+			break;
+		default:
+			rc = generic_mii_ioctl(&np->mii_if, if_mii(ifr),
+						cmd, NULL);
+			break;
+	}
+	spin_unlock(&np->lock);
+	return rc;
+}
+
+static int e100_get_settings(struct net_device *dev,
+			     struct ethtool_cmd *cmd)
+{
+	struct net_local *np = netdev_priv(dev);
+	int err;
+
+	spin_lock_irq(&np->lock);
+	err = mii_ethtool_gset(&np->mii_if, cmd);
+	spin_unlock_irq(&np->lock);
+
+	/* The PHY may support 1000baseT, but the Etrax100 does not.  */
+	cmd->supported &= ~(SUPPORTED_1000baseT_Half
+			    | SUPPORTED_1000baseT_Full);
+	return err;
+}
+
+static int e100_set_settings(struct net_device *dev,
+			     struct ethtool_cmd *ecmd)
+{
+	if (ecmd->autoneg == AUTONEG_ENABLE) {
+		e100_set_duplex(dev, autoneg);
+		e100_set_speed(dev, 0);
+	} else {
+		e100_set_duplex(dev, ecmd->duplex == DUPLEX_HALF ? half : full);
+		e100_set_speed(dev, ecmd->speed == SPEED_10 ? 10: 100);
+	}
+
+	return 0;
+}
+
+static void e100_get_drvinfo(struct net_device *dev,
+			     struct ethtool_drvinfo *info)
+{
+	strncpy(info->driver, "ETRAX 100LX", sizeof(info->driver) - 1);
+	strncpy(info->version, "$Revision: 1.31 $", sizeof(info->version) - 1);
+	strncpy(info->fw_version, "N/A", sizeof(info->fw_version) - 1);
+	strncpy(info->bus_info, "N/A", sizeof(info->bus_info) - 1);
+}
+
+static int e100_nway_reset(struct net_device *dev)
+{
+	if (current_duplex == autoneg && current_speed_selection == 0)
+		e100_negotiate(dev);
+	return 0;
+}
+
+static const struct ethtool_ops e100_ethtool_ops = {
+	.get_settings	= e100_get_settings,
+	.set_settings	= e100_set_settings,
+	.get_drvinfo	= e100_get_drvinfo,
+	.nway_reset	= e100_nway_reset,
+	.get_link	= ethtool_op_get_link,
+};
+
+static int
+e100_set_config(struct net_device *dev, struct ifmap *map)
+{
+	struct net_local *np = netdev_priv(dev);
+
+	spin_lock(&np->lock); /* Preempt protection */
+
+	switch(map->port) {
+		case IF_PORT_UNKNOWN:
+			/* Use autoneg */
+			e100_set_speed(dev, 0);
+			e100_set_duplex(dev, autoneg);
+			break;
+		case IF_PORT_10BASET:
+			e100_set_speed(dev, 10);
+			e100_set_duplex(dev, autoneg);
+			break;
+		case IF_PORT_100BASET:
+		case IF_PORT_100BASETX:
+			e100_set_speed(dev, 100);
+			e100_set_duplex(dev, autoneg);
+			break;
+		case IF_PORT_100BASEFX:
+		case IF_PORT_10BASE2:
+		case IF_PORT_AUI:
+			spin_unlock(&np->lock);
+			return -EOPNOTSUPP;
+			break;
+		default:
+			printk(KERN_ERR "%s: Invalid media selected", dev->name);
+			spin_unlock(&np->lock);
+			return -EINVAL;
+	}
+	spin_unlock(&np->lock);
+	return 0;
+}
+
+static void
+update_rx_stats(struct net_device_stats *es)
+{
+	unsigned long r = *R_REC_COUNTERS;
+	/* update stats relevant to reception errors */
+	es->rx_fifo_errors += IO_EXTRACT(R_REC_COUNTERS, congestion, r);
+	es->rx_crc_errors += IO_EXTRACT(R_REC_COUNTERS, crc_error, r);
+	es->rx_frame_errors += IO_EXTRACT(R_REC_COUNTERS, alignment_error, r);
+	es->rx_length_errors += IO_EXTRACT(R_REC_COUNTERS, oversize, r);
+}
+
+static void
+update_tx_stats(struct net_device_stats *es)
+{
+	unsigned long r = *R_TR_COUNTERS;
+	/* update stats relevant to transmission errors */
+	es->collisions +=
+		IO_EXTRACT(R_TR_COUNTERS, single_col, r) +
+		IO_EXTRACT(R_TR_COUNTERS, multiple_col, r);
+}
+
+/*
+ * Get the current statistics.
+ * This may be called with the card open or closed.
+ */
+static struct net_device_stats *
+e100_get_stats(struct net_device *dev)
+{
+	struct net_local *lp = netdev_priv(dev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&lp->lock, flags);
+
+	update_rx_stats(&dev->stats);
+	update_tx_stats(&dev->stats);
+
+	spin_unlock_irqrestore(&lp->lock, flags);
+	return &dev->stats;
+}
+
+/*
+ * Set or clear the multicast filter for this adaptor.
+ * num_addrs == -1	Promiscuous mode, receive all packets
+ * num_addrs == 0	Normal mode, clear multicast list
+ * num_addrs > 0	Multicast mode, receive normal and MC packets,
+ *			and do best-effort filtering.
+ */
+static void
+set_multicast_list(struct net_device *dev)
+{
+	struct net_local *lp = netdev_priv(dev);
+	int num_addr = netdev_mc_count(dev);
+	unsigned long int lo_bits;
+	unsigned long int hi_bits;
+
+	spin_lock(&lp->lock);
+	if (dev->flags & IFF_PROMISC) {
+		/* promiscuous mode */
+		lo_bits = 0xfffffffful;
+		hi_bits = 0xfffffffful;
+
+		/* Enable individual receive */
+		SETS(network_rec_config_shadow, R_NETWORK_REC_CONFIG, individual, receive);
+		*R_NETWORK_REC_CONFIG = network_rec_config_shadow;
+	} else if (dev->flags & IFF_ALLMULTI) {
+		/* enable all multicasts */
+		lo_bits = 0xfffffffful;
+		hi_bits = 0xfffffffful;
+
+		/* Disable individual receive */
+		SETS(network_rec_config_shadow, R_NETWORK_REC_CONFIG, individual, discard);
+		*R_NETWORK_REC_CONFIG =  network_rec_config_shadow;
+	} else if (num_addr == 0) {
+		/* Normal, clear the mc list */
+		lo_bits = 0x00000000ul;
+		hi_bits = 0x00000000ul;
+
+		/* Disable individual receive */
+		SETS(network_rec_config_shadow, R_NETWORK_REC_CONFIG, individual, discard);
+		*R_NETWORK_REC_CONFIG =  network_rec_config_shadow;
+	} else {
+		/* MC mode, receive normal and MC packets */
+		char hash_ix;
+		struct netdev_hw_addr *ha;
+		char *baddr;
+
+		lo_bits = 0x00000000ul;
+		hi_bits = 0x00000000ul;
+		netdev_for_each_mc_addr(ha, dev) {
+			/* Calculate the hash index for the GA registers */
+
+			hash_ix = 0;
+			baddr = ha->addr;
+			hash_ix ^= (*baddr) & 0x3f;
+			hash_ix ^= ((*baddr) >> 6) & 0x03;
+			++baddr;
+			hash_ix ^= ((*baddr) << 2) & 0x03c;
+			hash_ix ^= ((*baddr) >> 4) & 0xf;
+			++baddr;
+			hash_ix ^= ((*baddr) << 4) & 0x30;
+			hash_ix ^= ((*baddr) >> 2) & 0x3f;
+			++baddr;
+			hash_ix ^= (*baddr) & 0x3f;
+			hash_ix ^= ((*baddr) >> 6) & 0x03;
+			++baddr;
+			hash_ix ^= ((*baddr) << 2) & 0x03c;
+			hash_ix ^= ((*baddr) >> 4) & 0xf;
+			++baddr;
+			hash_ix ^= ((*baddr) << 4) & 0x30;
+			hash_ix ^= ((*baddr) >> 2) & 0x3f;
+
+			hash_ix &= 0x3f;
+
+			if (hash_ix >= 32) {
+				hi_bits |= (1 << (hash_ix-32));
+			} else {
+				lo_bits |= (1 << hash_ix);
+			}
+		}
+		/* Disable individual receive */
+		SETS(network_rec_config_shadow, R_NETWORK_REC_CONFIG, individual, discard);
+		*R_NETWORK_REC_CONFIG = network_rec_config_shadow;
+	}
+	*R_NETWORK_GA_0 = lo_bits;
+	*R_NETWORK_GA_1 = hi_bits;
+	spin_unlock(&lp->lock);
+}
+
+void
+e100_hardware_send_packet(struct net_local *np, char *buf, int length)
+{
+	D(printk("e100 send pack, buf 0x%x len %d\n", buf, length));
+
+	spin_lock(&np->led_lock);
+	if (!led_active && time_after(jiffies, led_next_time)) {
+		/* light the network leds depending on the current speed. */
+		e100_set_network_leds(NETWORK_ACTIVITY);
+
+		/* Set the earliest time we may clear the LED */
+		led_next_time = jiffies + NET_FLASH_TIME;
+		led_active = 1;
+		mod_timer(&clear_led_timer, jiffies + HZ/10);
+	}
+	spin_unlock(&np->led_lock);
+
+	/* configure the tx dma descriptor */
+	myNextTxDesc->descr.sw_len = length;
+	myNextTxDesc->descr.ctrl = d_eop | d_eol | d_wait;
+	myNextTxDesc->descr.buf = virt_to_phys(buf);
+
+        /* Move end of list */
+        myLastTxDesc->descr.ctrl &= ~d_eol;
+        myLastTxDesc = myNextTxDesc;
+
+	/* Restart DMA channel */
+	*R_DMA_CH0_CMD = IO_STATE(R_DMA_CH0_CMD, cmd, restart);
+}
+
+static void
+e100_clear_network_leds(unsigned long dummy)
+{
+	struct net_device *dev = (struct net_device *)dummy;
+	struct net_local *np = netdev_priv(dev);
+
+	spin_lock(&np->led_lock);
+
+	if (led_active && time_after(jiffies, led_next_time)) {
+		e100_set_network_leds(NO_NETWORK_ACTIVITY);
+
+		/* Set the earliest time we may set the LED */
+		led_next_time = jiffies + NET_FLASH_PAUSE;
+		led_active = 0;
+	}
+
+	spin_unlock(&np->led_lock);
+}
+
+static void
+e100_set_network_leds(int active)
+{
+#if defined(CONFIG_ETRAX_NETWORK_LED_ON_WHEN_LINK)
+	int light_leds = (active == NO_NETWORK_ACTIVITY);
+#elif defined(CONFIG_ETRAX_NETWORK_LED_ON_WHEN_ACTIVITY)
+	int light_leds = (active == NETWORK_ACTIVITY);
+#else
+#error "Define either CONFIG_ETRAX_NETWORK_LED_ON_WHEN_LINK or CONFIG_ETRAX_NETWORK_LED_ON_WHEN_ACTIVITY"
+#endif
+
+	if (!current_speed) {
+		/* Make LED red, link is down */
+		CRIS_LED_NETWORK_SET(CRIS_LED_OFF);
+	} else if (light_leds) {
+		if (current_speed == 10) {
+			CRIS_LED_NETWORK_SET(CRIS_LED_ORANGE);
+		} else {
+			CRIS_LED_NETWORK_SET(CRIS_LED_GREEN);
+		}
+	} else {
+		CRIS_LED_NETWORK_SET(CRIS_LED_OFF);
+	}
+}
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+static void
+e100_netpoll(struct net_device* netdev)
+{
+	e100rxtx_interrupt(NETWORK_DMA_TX_IRQ_NBR, netdev, NULL);
+}
+#endif
+
+static int
+etrax_init_module(void)
+{
+	return etrax_ethernet_init();
+}
+
+static int __init
+e100_boot_setup(char* str)
+{
+	struct sockaddr sa = {0};
+	int i;
+
+	/* Parse the colon separated Ethernet station address */
+	for (i = 0; i <  ETH_ALEN; i++) {
+		unsigned int tmp;
+		if (sscanf(str + 3*i, "%2x", &tmp) != 1) {
+			printk(KERN_WARNING "Malformed station address");
+			return 0;
+		}
+		sa.sa_data[i] = (char)tmp;
+	}
+
+	default_mac = sa;
+	return 1;
+}
+
+__setup("etrax100_eth=", e100_boot_setup);
+
+module_init(etrax_init_module);
diff -Nur linux-2.6.39.orig/drivers/tty/serial/crisv10.c linux-2.6.39/drivers/tty/serial/crisv10.c
--- linux-2.6.39.orig/drivers/tty/serial/crisv10.c	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/drivers/tty/serial/crisv10.c	2011-07-28 16:27:57.623883501 +0200
@@ -26,6 +26,7 @@
 #include <linux/kernel.h>
 #include <linux/mutex.h>
 #include <linux/bitops.h>
+#include <linux/device.h>
 #include <linux/seq_file.h>
 #include <linux/delay.h>
 #include <linux/module.h>
@@ -4430,6 +4431,7 @@
 #endif
 };
 
+static struct class *rs_class;
 static int __init rs_init(void)
 {
 	int i;
@@ -4564,6 +4566,24 @@
 #endif
 #endif /* CONFIG_SVINTO_SIM */
 
+	rs_class = class_create(THIS_MODULE, "rs_tty");
+#ifdef CONFIG_ETRAX_SERIAL_PORT0 
+	device_create(rs_class, NULL,
+		MKDEV(TTY_MAJOR, 64), NULL, "ttyS0");
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT1 
+	device_create(rs_class, NULL,
+		MKDEV(TTY_MAJOR, 65), NULL, "ttyS1");
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT2 
+	device_create(rs_class, NULL,
+		MKDEV(TTY_MAJOR, 66), NULL, "ttyS2");
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT3 
+	device_create(rs_class, NULL,
+		MKDEV(TTY_MAJOR, 67), NULL, "ttyS3");
+#endif
+
 	return 0;
 }
 
diff -Nur linux-2.6.39.orig/drivers/tty/serial/crisv10.c.orig linux-2.6.39/drivers/tty/serial/crisv10.c.orig
--- linux-2.6.39.orig/drivers/tty/serial/crisv10.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.39/drivers/tty/serial/crisv10.c.orig	2011-05-19 06:06:34.000000000 +0200
@@ -0,0 +1,4572 @@
+/*
+ * Serial port driver for the ETRAX 100LX chip
+ *
+ *    Copyright (C) 1998-2007  Axis Communications AB
+ *
+ *    Many, many authors. Based once upon a time on serial.c for 16x50.
+ *
+ */
+
+static char *serial_version = "$Revision: 1.25 $";
+
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/timer.h>
+#include <linux/interrupt.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/major.h>
+#include <linux/string.h>
+#include <linux/fcntl.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/mutex.h>
+#include <linux/bitops.h>
+#include <linux/seq_file.h>
+#include <linux/delay.h>
+#include <linux/module.h>
+#include <linux/uaccess.h>
+#include <linux/io.h>
+
+#include <asm/irq.h>
+#include <asm/dma.h>
+#include <asm/system.h>
+
+#include <arch/svinto.h>
+
+/* non-arch dependent serial structures are in linux/serial.h */
+#include <linux/serial.h>
+/* while we keep our own stuff (struct e100_serial) in a local .h file */
+#include "crisv10.h"
+#include <asm/fasttimer.h>
+#include <arch/io_interface_mux.h>
+
+#ifdef CONFIG_ETRAX_SERIAL_FAST_TIMER
+#ifndef CONFIG_ETRAX_FAST_TIMER
+#error "Enable FAST_TIMER to use SERIAL_FAST_TIMER"
+#endif
+#endif
+
+#if defined(CONFIG_ETRAX_SERIAL_RX_TIMEOUT_TICKS) && \
+           (CONFIG_ETRAX_SERIAL_RX_TIMEOUT_TICKS == 0)
+#error "RX_TIMEOUT_TICKS == 0 not allowed, use 1"
+#endif
+
+#if defined(CONFIG_ETRAX_RS485_ON_PA) && defined(CONFIG_ETRAX_RS485_ON_PORT_G)
+#error "Disable either CONFIG_ETRAX_RS485_ON_PA or CONFIG_ETRAX_RS485_ON_PORT_G"
+#endif
+
+/*
+ * All of the compatibilty code so we can compile serial.c against
+ * older kernels is hidden in serial_compat.h
+ */
+#if defined(LOCAL_HEADERS)
+#include "serial_compat.h"
+#endif
+
+struct tty_driver *serial_driver;
+
+/* number of characters left in xmit buffer before we ask for more */
+#define WAKEUP_CHARS 256
+
+//#define SERIAL_DEBUG_INTR
+//#define SERIAL_DEBUG_OPEN
+//#define SERIAL_DEBUG_FLOW
+//#define SERIAL_DEBUG_DATA
+//#define SERIAL_DEBUG_THROTTLE
+//#define SERIAL_DEBUG_IO  /* Debug for Extra control and status pins */
+//#define SERIAL_DEBUG_LINE 0 /* What serport we want to debug */
+
+/* Enable this to use serial interrupts to handle when you
+   expect the first received event on the serial port to
+   be an error, break or similar. Used to be able to flash IRMA
+   from eLinux */
+#define SERIAL_HANDLE_EARLY_ERRORS
+
+/* Currently 16 descriptors x 128 bytes = 2048 bytes */
+#define SERIAL_DESCR_BUF_SIZE 256
+
+#define SERIAL_PRESCALE_BASE 3125000 /* 3.125MHz */
+#define DEF_BAUD_BASE SERIAL_PRESCALE_BASE
+
+/* We don't want to load the system with massive fast timer interrupt
+ * on high baudrates so limit it to 250 us (4kHz) */
+#define MIN_FLUSH_TIME_USEC 250
+
+/* Add an x here to log a lot of timer stuff */
+#define TIMERD(x)
+/* Debug details of interrupt handling */
+#define DINTR1(x)  /* irq on/off, errors */
+#define DINTR2(x)    /* tx and rx */
+/* Debug flip buffer stuff */
+#define DFLIP(x)
+/* Debug flow control and overview of data flow */
+#define DFLOW(x)
+#define DBAUD(x)
+#define DLOG_INT_TRIG(x)
+
+//#define DEBUG_LOG_INCLUDED
+#ifndef DEBUG_LOG_INCLUDED
+#define DEBUG_LOG(line, string, value)
+#else
+struct debug_log_info
+{
+	unsigned long time;
+	unsigned long timer_data;
+//  int line;
+	const char *string;
+	int value;
+};
+#define DEBUG_LOG_SIZE 4096
+
+struct debug_log_info debug_log[DEBUG_LOG_SIZE];
+int debug_log_pos = 0;
+
+#define DEBUG_LOG(_line, _string, _value) do { \
+  if ((_line) == SERIAL_DEBUG_LINE) {\
+    debug_log_func(_line, _string, _value); \
+  }\
+}while(0)
+
+void debug_log_func(int line, const char *string, int value)
+{
+	if (debug_log_pos < DEBUG_LOG_SIZE) {
+		debug_log[debug_log_pos].time = jiffies;
+		debug_log[debug_log_pos].timer_data = *R_TIMER_DATA;
+//    debug_log[debug_log_pos].line = line;
+		debug_log[debug_log_pos].string = string;
+		debug_log[debug_log_pos].value = value;
+		debug_log_pos++;
+	}
+	/*printk(string, value);*/
+}
+#endif
+
+#ifndef CONFIG_ETRAX_SERIAL_RX_TIMEOUT_TICKS
+/* Default number of timer ticks before flushing rx fifo
+ * When using "little data, low latency applications: use 0
+ * When using "much data applications (PPP)" use ~5
+ */
+#define CONFIG_ETRAX_SERIAL_RX_TIMEOUT_TICKS 5
+#endif
+
+unsigned long timer_data_to_ns(unsigned long timer_data);
+
+static void change_speed(struct e100_serial *info);
+static void rs_throttle(struct tty_struct * tty);
+static void rs_wait_until_sent(struct tty_struct *tty, int timeout);
+static int rs_write(struct tty_struct *tty,
+		const unsigned char *buf, int count);
+#ifdef CONFIG_ETRAX_RS485
+static int e100_write_rs485(struct tty_struct *tty,
+		const unsigned char *buf, int count);
+#endif
+static int get_lsr_info(struct e100_serial *info, unsigned int *value);
+
+
+#define DEF_BAUD 115200   /* 115.2 kbit/s */
+#define STD_FLAGS (ASYNC_BOOT_AUTOCONF | ASYNC_SKIP_TEST)
+#define DEF_RX 0x20  /* or SERIAL_CTRL_W >> 8 */
+/* Default value of tx_ctrl register: has txd(bit 7)=1 (idle) as default */
+#define DEF_TX 0x80  /* or SERIAL_CTRL_B */
+
+/* offsets from R_SERIALx_CTRL */
+
+#define REG_DATA 0
+#define REG_DATA_STATUS32 0 /* this is the 32 bit register R_SERIALx_READ */
+#define REG_TR_DATA 0
+#define REG_STATUS 1
+#define REG_TR_CTRL 1
+#define REG_REC_CTRL 2
+#define REG_BAUD 3
+#define REG_XOFF 4  /* this is a 32 bit register */
+
+/* The bitfields are the same for all serial ports */
+#define SER_RXD_MASK         IO_MASK(R_SERIAL0_STATUS, rxd)
+#define SER_DATA_AVAIL_MASK  IO_MASK(R_SERIAL0_STATUS, data_avail)
+#define SER_FRAMING_ERR_MASK IO_MASK(R_SERIAL0_STATUS, framing_err)
+#define SER_PAR_ERR_MASK     IO_MASK(R_SERIAL0_STATUS, par_err)
+#define SER_OVERRUN_MASK     IO_MASK(R_SERIAL0_STATUS, overrun)
+
+#define SER_ERROR_MASK (SER_OVERRUN_MASK | SER_PAR_ERR_MASK | SER_FRAMING_ERR_MASK)
+
+/* Values for info->errorcode */
+#define ERRCODE_SET_BREAK    (TTY_BREAK)
+#define ERRCODE_INSERT        0x100
+#define ERRCODE_INSERT_BREAK (ERRCODE_INSERT | TTY_BREAK)
+
+#define FORCE_EOP(info)  *R_SET_EOP = 1U << info->iseteop;
+
+/*
+ * General note regarding the use of IO_* macros in this file:
+ *
+ * We will use the bits defined for DMA channel 6 when using various
+ * IO_* macros (e.g. IO_STATE, IO_MASK, IO_EXTRACT) and _assume_ they are
+ * the same for all channels (which of course they are).
+ *
+ * We will also use the bits defined for serial port 0 when writing commands
+ * to the different ports, as these bits too are the same for all ports.
+ */
+
+
+/* Mask for the irqs possibly enabled in R_IRQ_MASK1_RD etc. */
+static const unsigned long e100_ser_int_mask = 0
+#ifdef CONFIG_ETRAX_SERIAL_PORT0
+| IO_MASK(R_IRQ_MASK1_RD, ser0_data) | IO_MASK(R_IRQ_MASK1_RD, ser0_ready)
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT1
+| IO_MASK(R_IRQ_MASK1_RD, ser1_data) | IO_MASK(R_IRQ_MASK1_RD, ser1_ready)
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT2
+| IO_MASK(R_IRQ_MASK1_RD, ser2_data) | IO_MASK(R_IRQ_MASK1_RD, ser2_ready)
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT3
+| IO_MASK(R_IRQ_MASK1_RD, ser3_data) | IO_MASK(R_IRQ_MASK1_RD, ser3_ready)
+#endif
+;
+unsigned long r_alt_ser_baudrate_shadow = 0;
+
+/* this is the data for the four serial ports in the etrax100 */
+/*  DMA2(ser2), DMA4(ser3), DMA6(ser0) or DMA8(ser1) */
+/* R_DMA_CHx_CLR_INTR, R_DMA_CHx_FIRST, R_DMA_CHx_CMD */
+
+static struct e100_serial rs_table[] = {
+	{ .baud        = DEF_BAUD,
+	  .ioport        = (unsigned char *)R_SERIAL0_CTRL,
+	  .irq         = 1U << 12, /* uses DMA 6 and 7 */
+	  .oclrintradr = R_DMA_CH6_CLR_INTR,
+	  .ofirstadr   = R_DMA_CH6_FIRST,
+	  .ocmdadr     = R_DMA_CH6_CMD,
+	  .ostatusadr  = R_DMA_CH6_STATUS,
+	  .iclrintradr = R_DMA_CH7_CLR_INTR,
+	  .ifirstadr   = R_DMA_CH7_FIRST,
+	  .icmdadr     = R_DMA_CH7_CMD,
+	  .idescradr   = R_DMA_CH7_DESCR,
+	  .flags       = STD_FLAGS,
+	  .rx_ctrl     = DEF_RX,
+	  .tx_ctrl     = DEF_TX,
+	  .iseteop     = 2,
+	  .dma_owner   = dma_ser0,
+	  .io_if       = if_serial_0,
+#ifdef CONFIG_ETRAX_SERIAL_PORT0
+          .enabled  = 1,
+#ifdef CONFIG_ETRAX_SERIAL_PORT0_DMA6_OUT
+	  .dma_out_enabled = 1,
+	  .dma_out_nbr = SER0_TX_DMA_NBR,
+	  .dma_out_irq_nbr = SER0_DMA_TX_IRQ_NBR,
+	  .dma_out_irq_flags = IRQF_DISABLED,
+	  .dma_out_irq_description = "serial 0 dma tr",
+#else
+	  .dma_out_enabled = 0,
+	  .dma_out_nbr = UINT_MAX,
+	  .dma_out_irq_nbr = 0,
+	  .dma_out_irq_flags = 0,
+	  .dma_out_irq_description = NULL,
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT0_DMA7_IN
+	  .dma_in_enabled = 1,
+	  .dma_in_nbr = SER0_RX_DMA_NBR,
+	  .dma_in_irq_nbr = SER0_DMA_RX_IRQ_NBR,
+	  .dma_in_irq_flags = IRQF_DISABLED,
+	  .dma_in_irq_description = "serial 0 dma rec",
+#else
+	  .dma_in_enabled = 0,
+	  .dma_in_nbr = UINT_MAX,
+	  .dma_in_irq_nbr = 0,
+	  .dma_in_irq_flags = 0,
+	  .dma_in_irq_description = NULL,
+#endif
+#else
+          .enabled  = 0,
+	  .io_if_description = NULL,
+	  .dma_out_enabled = 0,
+	  .dma_in_enabled = 0
+#endif
+
+},  /* ttyS0 */
+#ifndef CONFIG_SVINTO_SIM
+	{ .baud        = DEF_BAUD,
+	  .ioport        = (unsigned char *)R_SERIAL1_CTRL,
+	  .irq         = 1U << 16, /* uses DMA 8 and 9 */
+	  .oclrintradr = R_DMA_CH8_CLR_INTR,
+	  .ofirstadr   = R_DMA_CH8_FIRST,
+	  .ocmdadr     = R_DMA_CH8_CMD,
+	  .ostatusadr  = R_DMA_CH8_STATUS,
+	  .iclrintradr = R_DMA_CH9_CLR_INTR,
+	  .ifirstadr   = R_DMA_CH9_FIRST,
+	  .icmdadr     = R_DMA_CH9_CMD,
+	  .idescradr   = R_DMA_CH9_DESCR,
+	  .flags       = STD_FLAGS,
+	  .rx_ctrl     = DEF_RX,
+	  .tx_ctrl     = DEF_TX,
+	  .iseteop     = 3,
+	  .dma_owner   = dma_ser1,
+	  .io_if       = if_serial_1,
+#ifdef CONFIG_ETRAX_SERIAL_PORT1
+          .enabled  = 1,
+	  .io_if_description = "ser1",
+#ifdef CONFIG_ETRAX_SERIAL_PORT1_DMA8_OUT
+	  .dma_out_enabled = 1,
+	  .dma_out_nbr = SER1_TX_DMA_NBR,
+	  .dma_out_irq_nbr = SER1_DMA_TX_IRQ_NBR,
+	  .dma_out_irq_flags = IRQF_DISABLED,
+	  .dma_out_irq_description = "serial 1 dma tr",
+#else
+	  .dma_out_enabled = 0,
+	  .dma_out_nbr = UINT_MAX,
+	  .dma_out_irq_nbr = 0,
+	  .dma_out_irq_flags = 0,
+	  .dma_out_irq_description = NULL,
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT1_DMA9_IN
+	  .dma_in_enabled = 1,
+	  .dma_in_nbr = SER1_RX_DMA_NBR,
+	  .dma_in_irq_nbr = SER1_DMA_RX_IRQ_NBR,
+	  .dma_in_irq_flags = IRQF_DISABLED,
+	  .dma_in_irq_description = "serial 1 dma rec",
+#else
+	  .dma_in_enabled = 0,
+	  .dma_in_enabled = 0,
+	  .dma_in_nbr = UINT_MAX,
+	  .dma_in_irq_nbr = 0,
+	  .dma_in_irq_flags = 0,
+	  .dma_in_irq_description = NULL,
+#endif
+#else
+          .enabled  = 0,
+	  .io_if_description = NULL,
+	  .dma_in_irq_nbr = 0,
+	  .dma_out_enabled = 0,
+	  .dma_in_enabled = 0
+#endif
+},  /* ttyS1 */
+
+	{ .baud        = DEF_BAUD,
+	  .ioport        = (unsigned char *)R_SERIAL2_CTRL,
+	  .irq         = 1U << 4,  /* uses DMA 2 and 3 */
+	  .oclrintradr = R_DMA_CH2_CLR_INTR,
+	  .ofirstadr   = R_DMA_CH2_FIRST,
+	  .ocmdadr     = R_DMA_CH2_CMD,
+	  .ostatusadr  = R_DMA_CH2_STATUS,
+	  .iclrintradr = R_DMA_CH3_CLR_INTR,
+	  .ifirstadr   = R_DMA_CH3_FIRST,
+	  .icmdadr     = R_DMA_CH3_CMD,
+	  .idescradr   = R_DMA_CH3_DESCR,
+	  .flags       = STD_FLAGS,
+	  .rx_ctrl     = DEF_RX,
+	  .tx_ctrl     = DEF_TX,
+	  .iseteop     = 0,
+	  .dma_owner   = dma_ser2,
+	  .io_if       = if_serial_2,
+#ifdef CONFIG_ETRAX_SERIAL_PORT2
+          .enabled  = 1,
+	  .io_if_description = "ser2",
+#ifdef CONFIG_ETRAX_SERIAL_PORT2_DMA2_OUT
+	  .dma_out_enabled = 1,
+	  .dma_out_nbr = SER2_TX_DMA_NBR,
+	  .dma_out_irq_nbr = SER2_DMA_TX_IRQ_NBR,
+	  .dma_out_irq_flags = IRQF_DISABLED,
+	  .dma_out_irq_description = "serial 2 dma tr",
+#else
+	  .dma_out_enabled = 0,
+	  .dma_out_nbr = UINT_MAX,
+	  .dma_out_irq_nbr = 0,
+	  .dma_out_irq_flags = 0,
+	  .dma_out_irq_description = NULL,
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT2_DMA3_IN
+	  .dma_in_enabled = 1,
+	  .dma_in_nbr = SER2_RX_DMA_NBR,
+	  .dma_in_irq_nbr = SER2_DMA_RX_IRQ_NBR,
+	  .dma_in_irq_flags = IRQF_DISABLED,
+	  .dma_in_irq_description = "serial 2 dma rec",
+#else
+	  .dma_in_enabled = 0,
+	  .dma_in_nbr = UINT_MAX,
+	  .dma_in_irq_nbr = 0,
+	  .dma_in_irq_flags = 0,
+	  .dma_in_irq_description = NULL,
+#endif
+#else
+          .enabled  = 0,
+	  .io_if_description = NULL,
+	  .dma_out_enabled = 0,
+	  .dma_in_enabled = 0
+#endif
+ },  /* ttyS2 */
+
+	{ .baud        = DEF_BAUD,
+	  .ioport        = (unsigned char *)R_SERIAL3_CTRL,
+	  .irq         = 1U << 8,  /* uses DMA 4 and 5 */
+	  .oclrintradr = R_DMA_CH4_CLR_INTR,
+	  .ofirstadr   = R_DMA_CH4_FIRST,
+	  .ocmdadr     = R_DMA_CH4_CMD,
+	  .ostatusadr  = R_DMA_CH4_STATUS,
+	  .iclrintradr = R_DMA_CH5_CLR_INTR,
+	  .ifirstadr   = R_DMA_CH5_FIRST,
+	  .icmdadr     = R_DMA_CH5_CMD,
+	  .idescradr   = R_DMA_CH5_DESCR,
+	  .flags       = STD_FLAGS,
+	  .rx_ctrl     = DEF_RX,
+	  .tx_ctrl     = DEF_TX,
+	  .iseteop     = 1,
+	  .dma_owner   = dma_ser3,
+	  .io_if       = if_serial_3,
+#ifdef CONFIG_ETRAX_SERIAL_PORT3
+          .enabled  = 1,
+	  .io_if_description = "ser3",
+#ifdef CONFIG_ETRAX_SERIAL_PORT3_DMA4_OUT
+	  .dma_out_enabled = 1,
+	  .dma_out_nbr = SER3_TX_DMA_NBR,
+	  .dma_out_irq_nbr = SER3_DMA_TX_IRQ_NBR,
+	  .dma_out_irq_flags = IRQF_DISABLED,
+	  .dma_out_irq_description = "serial 3 dma tr",
+#else
+	  .dma_out_enabled = 0,
+	  .dma_out_nbr = UINT_MAX,
+	  .dma_out_irq_nbr = 0,
+	  .dma_out_irq_flags = 0,
+	  .dma_out_irq_description = NULL,
+#endif
+#ifdef CONFIG_ETRAX_SERIAL_PORT3_DMA5_IN
+	  .dma_in_enabled = 1,
+	  .dma_in_nbr = SER3_RX_DMA_NBR,
+	  .dma_in_irq_nbr = SER3_DMA_RX_IRQ_NBR,
+	  .dma_in_irq_flags = IRQF_DISABLED,
+	  .dma_in_irq_description = "serial 3 dma rec",
+#else
+	  .dma_in_enabled = 0,
+	  .dma_in_nbr = UINT_MAX,
+	  .dma_in_irq_nbr = 0,
+	  .dma_in_irq_flags = 0,
+	  .dma_in_irq_description = NULL
+#endif
+#else
+          .enabled  = 0,
+	  .io_if_description = NULL,
+	  .dma_out_enabled = 0,
+	  .dma_in_enabled = 0
+#endif
+ }   /* ttyS3 */
+#endif
+};
+
+
+#define NR_PORTS (sizeof(rs_table)/sizeof(struct e100_serial))
+
+#ifdef CONFIG_ETRAX_SERIAL_FAST_TIMER
+static struct fast_timer fast_timers[NR_PORTS];
+#endif
+
+#ifdef CONFIG_ETRAX_SERIAL_PROC_ENTRY
+#define PROCSTAT(x) x
+struct ser_statistics_type {
+	int overrun_cnt;
+	int early_errors_cnt;
+	int ser_ints_ok_cnt;
+	int errors_cnt;
+	unsigned long int processing_flip;
+	unsigned long processing_flip_still_room;
+	unsigned long int timeout_flush_cnt;
+	int rx_dma_ints;
+	int tx_dma_ints;
+	int rx_tot;
+	int tx_tot;
+};
+
+static struct ser_statistics_type ser_stat[NR_PORTS];
+
+#else
+
+#define PROCSTAT(x)
+
+#endif /* CONFIG_ETRAX_SERIAL_PROC_ENTRY */
+
+/* RS-485 */
+#if defined(CONFIG_ETRAX_RS485)
+#ifdef CONFIG_ETRAX_FAST_TIMER
+static struct fast_timer fast_timers_rs485[NR_PORTS];
+#endif
+#if defined(CONFIG_ETRAX_RS485_ON_PA)
+static int rs485_pa_bit = CONFIG_ETRAX_RS485_ON_PA_BIT;
+#endif
+#if defined(CONFIG_ETRAX_RS485_ON_PORT_G)
+static int rs485_port_g_bit = CONFIG_ETRAX_RS485_ON_PORT_G_BIT;
+#endif
+#endif
+
+/* Info and macros needed for each ports extra control/status signals. */
+#define E100_STRUCT_PORT(line, pinname) \
+ ((CONFIG_ETRAX_SER##line##_##pinname##_ON_PA_BIT >= 0)? \
+		(R_PORT_PA_DATA): ( \
+ (CONFIG_ETRAX_SER##line##_##pinname##_ON_PB_BIT >= 0)? \
+		(R_PORT_PB_DATA):&dummy_ser[line]))
+
+#define E100_STRUCT_SHADOW(line, pinname) \
+ ((CONFIG_ETRAX_SER##line##_##pinname##_ON_PA_BIT >= 0)? \
+		(&port_pa_data_shadow): ( \
+ (CONFIG_ETRAX_SER##line##_##pinname##_ON_PB_BIT >= 0)? \
+		(&port_pb_data_shadow):&dummy_ser[line]))
+#define E100_STRUCT_MASK(line, pinname) \
+ ((CONFIG_ETRAX_SER##line##_##pinname##_ON_PA_BIT >= 0)? \
+		(1<<CONFIG_ETRAX_SER##line##_##pinname##_ON_PA_BIT): ( \
+ (CONFIG_ETRAX_SER##line##_##pinname##_ON_PB_BIT >= 0)? \
+		(1<<CONFIG_ETRAX_SER##line##_##pinname##_ON_PB_BIT):DUMMY_##pinname##_MASK))
+
+#define DUMMY_DTR_MASK 1
+#define DUMMY_RI_MASK  2
+#define DUMMY_DSR_MASK 4
+#define DUMMY_CD_MASK  8
+static unsigned char dummy_ser[NR_PORTS] = {0xFF, 0xFF, 0xFF,0xFF};
+
+/* If not all status pins are used or disabled, use mixed mode */
+#ifdef CONFIG_ETRAX_SERIAL_PORT0
+
+#define SER0_PA_BITSUM (CONFIG_ETRAX_SER0_DTR_ON_PA_BIT+CONFIG_ETRAX_SER0_RI_ON_PA_BIT+CONFIG_ETRAX_SER0_DSR_ON_PA_BIT+CONFIG_ETRAX_SER0_CD_ON_PA_BIT)
+
+#if SER0_PA_BITSUM != -4
+#  if CONFIG_ETRAX_SER0_DTR_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#   endif
+# if CONFIG_ETRAX_SER0_RI_ON_PA_BIT == -1
+#   ifndef CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED
+#     define CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED 1
+#   endif
+#  endif
+#  if CONFIG_ETRAX_SER0_DSR_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#  if CONFIG_ETRAX_SER0_CD_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#endif
+
+#define SER0_PB_BITSUM (CONFIG_ETRAX_SER0_DTR_ON_PB_BIT+CONFIG_ETRAX_SER0_RI_ON_PB_BIT+CONFIG_ETRAX_SER0_DSR_ON_PB_BIT+CONFIG_ETRAX_SER0_CD_ON_PB_BIT)
+
+#if SER0_PB_BITSUM != -4
+#  if CONFIG_ETRAX_SER0_DTR_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#   endif
+# if CONFIG_ETRAX_SER0_RI_ON_PB_BIT == -1
+#   ifndef CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED
+#     define CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED 1
+#   endif
+#  endif
+#  if CONFIG_ETRAX_SER0_DSR_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#  if CONFIG_ETRAX_SER0_CD_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#endif
+
+#endif /* PORT0 */
+
+
+#ifdef CONFIG_ETRAX_SERIAL_PORT1
+
+#define SER1_PA_BITSUM (CONFIG_ETRAX_SER1_DTR_ON_PA_BIT+CONFIG_ETRAX_SER1_RI_ON_PA_BIT+CONFIG_ETRAX_SER1_DSR_ON_PA_BIT+CONFIG_ETRAX_SER1_CD_ON_PA_BIT)
+
+#if SER1_PA_BITSUM != -4
+#  if CONFIG_ETRAX_SER1_DTR_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#   endif
+# if CONFIG_ETRAX_SER1_RI_ON_PA_BIT == -1
+#   ifndef CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED
+#     define CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED 1
+#   endif
+#  endif
+#  if CONFIG_ETRAX_SER1_DSR_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#  if CONFIG_ETRAX_SER1_CD_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#endif
+
+#define SER1_PB_BITSUM (CONFIG_ETRAX_SER1_DTR_ON_PB_BIT+CONFIG_ETRAX_SER1_RI_ON_PB_BIT+CONFIG_ETRAX_SER1_DSR_ON_PB_BIT+CONFIG_ETRAX_SER1_CD_ON_PB_BIT)
+
+#if SER1_PB_BITSUM != -4
+#  if CONFIG_ETRAX_SER1_DTR_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#   endif
+# if CONFIG_ETRAX_SER1_RI_ON_PB_BIT == -1
+#   ifndef CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED
+#     define CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED 1
+#   endif
+#  endif
+#  if CONFIG_ETRAX_SER1_DSR_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#  if CONFIG_ETRAX_SER1_CD_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#endif
+
+#endif /* PORT1 */
+
+#ifdef CONFIG_ETRAX_SERIAL_PORT2
+
+#define SER2_PA_BITSUM (CONFIG_ETRAX_SER2_DTR_ON_PA_BIT+CONFIG_ETRAX_SER2_RI_ON_PA_BIT+CONFIG_ETRAX_SER2_DSR_ON_PA_BIT+CONFIG_ETRAX_SER2_CD_ON_PA_BIT)
+
+#if SER2_PA_BITSUM != -4
+#  if CONFIG_ETRAX_SER2_DTR_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#   endif
+# if CONFIG_ETRAX_SER2_RI_ON_PA_BIT == -1
+#   ifndef CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED
+#     define CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED 1
+#   endif
+#  endif
+#  if CONFIG_ETRAX_SER2_DSR_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#  if CONFIG_ETRAX_SER2_CD_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#endif
+
+#define SER2_PB_BITSUM (CONFIG_ETRAX_SER2_DTR_ON_PB_BIT+CONFIG_ETRAX_SER2_RI_ON_PB_BIT+CONFIG_ETRAX_SER2_DSR_ON_PB_BIT+CONFIG_ETRAX_SER2_CD_ON_PB_BIT)
+
+#if SER2_PB_BITSUM != -4
+#  if CONFIG_ETRAX_SER2_DTR_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#   endif
+# if CONFIG_ETRAX_SER2_RI_ON_PB_BIT == -1
+#   ifndef CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED
+#     define CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED 1
+#   endif
+#  endif
+#  if CONFIG_ETRAX_SER2_DSR_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#  if CONFIG_ETRAX_SER2_CD_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#endif
+
+#endif /* PORT2 */
+
+#ifdef CONFIG_ETRAX_SERIAL_PORT3
+
+#define SER3_PA_BITSUM (CONFIG_ETRAX_SER3_DTR_ON_PA_BIT+CONFIG_ETRAX_SER3_RI_ON_PA_BIT+CONFIG_ETRAX_SER3_DSR_ON_PA_BIT+CONFIG_ETRAX_SER3_CD_ON_PA_BIT)
+
+#if SER3_PA_BITSUM != -4
+#  if CONFIG_ETRAX_SER3_DTR_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#   endif
+# if CONFIG_ETRAX_SER3_RI_ON_PA_BIT == -1
+#   ifndef CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED
+#     define CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED 1
+#   endif
+#  endif
+#  if CONFIG_ETRAX_SER3_DSR_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#  if CONFIG_ETRAX_SER3_CD_ON_PA_BIT == -1
+#    ifndef CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#endif
+
+#define SER3_PB_BITSUM (CONFIG_ETRAX_SER3_DTR_ON_PB_BIT+CONFIG_ETRAX_SER3_RI_ON_PB_BIT+CONFIG_ETRAX_SER3_DSR_ON_PB_BIT+CONFIG_ETRAX_SER3_CD_ON_PB_BIT)
+
+#if SER3_PB_BITSUM != -4
+#  if CONFIG_ETRAX_SER3_DTR_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#   endif
+# if CONFIG_ETRAX_SER3_RI_ON_PB_BIT == -1
+#   ifndef CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED
+#     define CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED 1
+#   endif
+#  endif
+#  if CONFIG_ETRAX_SER3_DSR_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#  if CONFIG_ETRAX_SER3_CD_ON_PB_BIT == -1
+#    ifndef CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED
+#      define CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED 1
+#    endif
+#  endif
+#endif
+
+#endif /* PORT3 */
+
+
+#if defined(CONFIG_ETRAX_SER0_DTR_RI_DSR_CD_MIXED) || \
+    defined(CONFIG_ETRAX_SER1_DTR_RI_DSR_CD_MIXED) || \
+    defined(CONFIG_ETRAX_SER2_DTR_RI_DSR_CD_MIXED) || \
+    defined(CONFIG_ETRAX_SER3_DTR_RI_DSR_CD_MIXED)
+#define CONFIG_ETRAX_SERX_DTR_RI_DSR_CD_MIXED
+#endif
+
+#ifdef CONFIG_ETRAX_SERX_DTR_RI_DSR_CD_MIXED
+/* The pins can be mixed on PA and PB */
+#define CONTROL_PINS_PORT_NOT_USED(line) \
+  &dummy_ser[line], &dummy_ser[line], \
+  &dummy_ser[line], &dummy_ser[line], \
+  &dummy_ser[line], &dummy_ser[line], \
+  &dummy_ser[line], &dummy_ser[line], \
+  DUMMY_DTR_MASK, DUMMY_RI_MASK, DUMMY_DSR_MASK, DUMMY_CD_MASK
+
+
+struct control_pins
+{
+	volatile unsigned char *dtr_port;
+	unsigned char          *dtr_shadow;
+	volatile unsigned char *ri_port;
+	unsigned char          *ri_shadow;
+	volatile unsigned char *dsr_port;
+	unsigned char          *dsr_shadow;
+	volatile unsigned char *cd_port;
+	unsigned char          *cd_shadow;
+
+	unsigned char dtr_mask;
+	unsigned char ri_mask;
+	unsigned char dsr_mask;
+	unsigned char cd_mask;
+};
+
+static const struct control_pins e100_modem_pins[NR_PORTS] =
+{
+	/* Ser 0 */
+	{
+#ifdef CONFIG_ETRAX_SERIAL_PORT0
+	E100_STRUCT_PORT(0,DTR), E100_STRUCT_SHADOW(0,DTR),
+	E100_STRUCT_PORT(0,RI),  E100_STRUCT_SHADOW(0,RI),
+	E100_STRUCT_PORT(0,DSR), E100_STRUCT_SHADOW(0,DSR),
+	E100_STRUCT_PORT(0,CD),  E100_STRUCT_SHADOW(0,CD),
+	E100_STRUCT_MASK(0,DTR),
+	E100_STRUCT_MASK(0,RI),
+	E100_STRUCT_MASK(0,DSR),
+	E100_STRUCT_MASK(0,CD)
+#else
+	CONTROL_PINS_PORT_NOT_USED(0)
+#endif
+	},
+
+	/* Ser 1 */
+	{
+#ifdef CONFIG_ETRAX_SERIAL_PORT1
+	E100_STRUCT_PORT(1,DTR), E100_STRUCT_SHADOW(1,DTR),
+	E100_STRUCT_PORT(1,RI),  E100_STRUCT_SHADOW(1,RI),
+	E100_STRUCT_PORT(1,DSR), E100_STRUCT_SHADOW(1,DSR),
+	E100_STRUCT_PORT(1,CD),  E100_STRUCT_SHADOW(1,CD),
+	E100_STRUCT_MASK(1,DTR),
+	E100_STRUCT_MASK(1,RI),
+	E100_STRUCT_MASK(1,DSR),
+	E100_STRUCT_MASK(1,CD)
+#else
+	CONTROL_PINS_PORT_NOT_USED(1)
+#endif
+	},
+
+	/* Ser 2 */
+	{
+#ifdef CONFIG_ETRAX_SERIAL_PORT2
+	E100_STRUCT_PORT(2,DTR), E100_STRUCT_SHADOW(2,DTR),
+	E100_STRUCT_PORT(2,RI),  E100_STRUCT_SHADOW(2,RI),
+	E100_STRUCT_PORT(2,DSR), E100_STRUCT_SHADOW(2,DSR),
+	E100_STRUCT_PORT(2,CD),  E100_STRUCT_SHADOW(2,CD),
+	E100_STRUCT_MASK(2,DTR),
+	E100_STRUCT_MASK(2,RI),
+	E100_STRUCT_MASK(2,DSR),
+	E100_STRUCT_MASK(2,CD)
+#else
+	CONTROL_PINS_PORT_NOT_USED(2)
+#endif
+	},
+
+	/* Ser 3 */
+	{
+#ifdef CONFIG_ETRAX_SERIAL_PORT3
+	E100_STRUCT_PORT(3,DTR), E100_STRUCT_SHADOW(3,DTR),
+	E100_STRUCT_PORT(3,RI),  E100_STRUCT_SHADOW(3,RI),
+	E100_STRUCT_PORT(3,DSR), E100_STRUCT_SHADOW(3,DSR),
+	E100_STRUCT_PORT(3,CD),  E100_STRUCT_SHADOW(3,CD),
+	E100_STRUCT_MASK(3,DTR),
+	E100_STRUCT_MASK(3,RI),
+	E100_STRUCT_MASK(3,DSR),
+	E100_STRUCT_MASK(3,CD)
+#else
+	CONTROL_PINS_PORT_NOT_USED(3)
+#endif
+	}
+};
+#else  /* CONFIG_ETRAX_SERX_DTR_RI_DSR_CD_MIXED */
+
+/* All pins are on either PA or PB for each serial port */
+#define CONTROL_PINS_PORT_NOT_USED(line) \
+  &dummy_ser[line], &dummy_ser[line], \
+  DUMMY_DTR_MASK, DUMMY_RI_MASK, DUMMY_DSR_MASK, DUMMY_CD_MASK
+
+
+struct control_pins
+{
+	volatile unsigned char *port;
+	unsigned char          *shadow;
+
+	unsigned char dtr_mask;
+	unsigned char ri_mask;
+	unsigned char dsr_mask;
+	unsigned char cd_mask;
+};
+
+#define dtr_port port
+#define dtr_shadow shadow
+#define ri_port port
+#define ri_shadow shadow
+#define dsr_port port
+#define dsr_shadow shadow
+#define cd_port port
+#define cd_shadow shadow
+
+static const struct control_pins e100_modem_pins[NR_PORTS] =
+{
+	/* Ser 0 */
+	{
+#ifdef CONFIG_ETRAX_SERIAL_PORT0
+	E100_STRUCT_PORT(0,DTR), E100_STRUCT_SHADOW(0,DTR),
+	E100_STRUCT_MASK(0,DTR),
+	E100_STRUCT_MASK(0,RI),
+	E100_STRUCT_MASK(0,DSR),
+	E100_STRUCT_MASK(0,CD)
+#else
+	CONTROL_PINS_PORT_NOT_USED(0)
+#endif
+	},
+
+	/* Ser 1 */
+	{
+#ifdef CONFIG_ETRAX_SERIAL_PORT1
+	E100_STRUCT_PORT(1,DTR), E100_STRUCT_SHADOW(1,DTR),
+	E100_STRUCT_MASK(1,DTR),
+	E100_STRUCT_MASK(1,RI),
+	E100_STRUCT_MASK(1,DSR),
+	E100_STRUCT_MASK(1,CD)
+#else
+	CONTROL_PINS_PORT_NOT_USED(1)
+#endif
+	},
+
+	/* Ser 2 */
+	{
+#ifdef CONFIG_ETRAX_SERIAL_PORT2
+	E100_STRUCT_PORT(2,DTR), E100_STRUCT_SHADOW(2,DTR),
+	E100_STRUCT_MASK(2,DTR),
+	E100_STRUCT_MASK(2,RI),
+	E100_STRUCT_MASK(2,DSR),
+	E100_STRUCT_MASK(2,CD)
+#else
+	CONTROL_PINS_PORT_NOT_USED(2)
+#endif
+	},
+
+	/* Ser 3 */
+	{
+#ifdef CONFIG_ETRAX_SERIAL_PORT3
+	E100_STRUCT_PORT(3,DTR), E100_STRUCT_SHADOW(3,DTR),
+	E100_STRUCT_MASK(3,DTR),
+	E100_STRUCT_MASK(3,RI),
+	E100_STRUCT_MASK(3,DSR),
+	E100_STRUCT_MASK(3,CD)
+#else
+	CONTROL_PINS_PORT_NOT_USED(3)
+#endif
+	}
+};
+#endif /* !CONFIG_ETRAX_SERX_DTR_RI_DSR_CD_MIXED */
+
+#define E100_RTS_MASK 0x20
+#define E100_CTS_MASK 0x40
+
+/* All serial port signals are active low:
+ * active   = 0 -> 3.3V to RS-232 driver -> -12V on RS-232 level
+ * inactive = 1 -> 0V   to RS-232 driver -> +12V on RS-232 level
+ *
+ * These macros returns the pin value: 0=0V, >=1 = 3.3V on ETRAX chip
+ */
+
+/* Output */
+#define E100_RTS_GET(info) ((info)->rx_ctrl & E100_RTS_MASK)
+/* Input */
+#define E100_CTS_GET(info) ((info)->ioport[REG_STATUS] & E100_CTS_MASK)
+
+/* These are typically PA or PB and 0 means 0V, 1 means 3.3V */
+/* Is an output */
+#define E100_DTR_GET(info) ((*e100_modem_pins[(info)->line].dtr_shadow) & e100_modem_pins[(info)->line].dtr_mask)
+
+/* Normally inputs */
+#define E100_RI_GET(info) ((*e100_modem_pins[(info)->line].ri_port) & e100_modem_pins[(info)->line].ri_mask)
+#define E100_CD_GET(info) ((*e100_modem_pins[(info)->line].cd_port) & e100_modem_pins[(info)->line].cd_mask)
+
+/* Input */
+#define E100_DSR_GET(info) ((*e100_modem_pins[(info)->line].dsr_port) & e100_modem_pins[(info)->line].dsr_mask)
+
+
+/*
+ * tmp_buf is used as a temporary buffer by serial_write.  We need to
+ * lock it in case the memcpy_fromfs blocks while swapping in a page,
+ * and some other program tries to do a serial write at the same time.
+ * Since the lock will only come under contention when the system is
+ * swapping and available memory is low, it makes sense to share one
+ * buffer across all the serial ports, since it significantly saves
+ * memory if large numbers of serial ports are open.
+ */
+static unsigned char *tmp_buf;
+static DEFINE_MUTEX(tmp_buf_mutex);
+
+/* Calculate the chartime depending on baudrate, numbor of bits etc. */
+static void update_char_time(struct e100_serial * info)
+{
+	tcflag_t cflags = info->port.tty->termios->c_cflag;
+	int bits;
+
+	/* calc. number of bits / data byte */
+	/* databits + startbit and 1 stopbit */
+	if ((cflags & CSIZE) == CS7)
+		bits = 9;
+	else
+		bits = 10;
+
+	if (cflags & CSTOPB)     /* 2 stopbits ? */
+		bits++;
+
+	if (cflags & PARENB)     /* parity bit ? */
+		bits++;
+
+	/* calc timeout */
+	info->char_time_usec = ((bits * 1000000) / info->baud) + 1;
+	info->flush_time_usec = 4*info->char_time_usec;
+	if (info->flush_time_usec < MIN_FLUSH_TIME_USEC)
+		info->flush_time_usec = MIN_FLUSH_TIME_USEC;
+
+}
+
+/*
+ * This function maps from the Bxxxx defines in asm/termbits.h into real
+ * baud rates.
+ */
+
+static int
+cflag_to_baud(unsigned int cflag)
+{
+	static int baud_table[] = {
+		0, 50, 75, 110, 134, 150, 200, 300, 600, 1200, 1800, 2400,
+		4800, 9600, 19200, 38400 };
+
+	static int ext_baud_table[] = {
+		0, 57600, 115200, 230400, 460800, 921600, 1843200, 6250000,
+                0, 0, 0, 0, 0, 0, 0, 0 };
+
+	if (cflag & CBAUDEX)
+		return ext_baud_table[(cflag & CBAUD) & ~CBAUDEX];
+	else
+		return baud_table[cflag & CBAUD];
+}
+
+/* and this maps to an etrax100 hardware baud constant */
+
+static unsigned char
+cflag_to_etrax_baud(unsigned int cflag)
+{
+	char retval;
+
+	static char baud_table[] = {
+		-1, -1, -1, -1, -1, -1, -1, 0, 1, 2, -1, 3, 4, 5, 6, 7 };
+
+	static char ext_baud_table[] = {
+		-1, 8, 9, 10, 11, 12, 13, 14, -1, -1, -1, -1, -1, -1, -1, -1 };
+
+	if (cflag & CBAUDEX)
+		retval = ext_baud_table[(cflag & CBAUD) & ~CBAUDEX];
+	else
+		retval = baud_table[cflag & CBAUD];
+
+	if (retval < 0) {
+		printk(KERN_WARNING "serdriver tried setting invalid baud rate, flags %x.\n", cflag);
+		retval = 5; /* choose default 9600 instead */
+	}
+
+	return retval | (retval << 4); /* choose same for both TX and RX */
+}
+
+
+/* Various static support functions */
+
+/* Functions to set or clear DTR/RTS on the requested line */
+/* It is complicated by the fact that RTS is a serial port register, while
+ * DTR might not be implemented in the HW at all, and if it is, it can be on
+ * any general port.
+ */
+
+
+static inline void
+e100_dtr(struct e100_serial *info, int set)
+{
+#ifndef CONFIG_SVINTO_SIM
+	unsigned char mask = e100_modem_pins[info->line].dtr_mask;
+
+#ifdef SERIAL_DEBUG_IO
+	printk("ser%i dtr %i mask: 0x%02X\n", info->line, set, mask);
+	printk("ser%i shadow before 0x%02X get: %i\n",
+	       info->line, *e100_modem_pins[info->line].dtr_shadow,
+	       E100_DTR_GET(info));
+#endif
+	/* DTR is active low */
+	{
+		unsigned long flags;
+
+		local_irq_save(flags);
+		*e100_modem_pins[info->line].dtr_shadow &= ~mask;
+		*e100_modem_pins[info->line].dtr_shadow |= (set ? 0 : mask);
+		*e100_modem_pins[info->line].dtr_port = *e100_modem_pins[info->line].dtr_shadow;
+		local_irq_restore(flags);
+	}
+
+#ifdef SERIAL_DEBUG_IO
+	printk("ser%i shadow after 0x%02X get: %i\n",
+	       info->line, *e100_modem_pins[info->line].dtr_shadow,
+	       E100_DTR_GET(info));
+#endif
+#endif
+}
+
+/* set = 0 means 3.3V on the pin, bitvalue: 0=active, 1=inactive
+ *                                          0=0V    , 1=3.3V
+ */
+static inline void
+e100_rts(struct e100_serial *info, int set)
+{
+#ifndef CONFIG_SVINTO_SIM
+	unsigned long flags;
+	local_irq_save(flags);
+	info->rx_ctrl &= ~E100_RTS_MASK;
+	info->rx_ctrl |= (set ? 0 : E100_RTS_MASK);  /* RTS is active low */
+	info->ioport[REG_REC_CTRL] = info->rx_ctrl;
+	local_irq_restore(flags);
+#ifdef SERIAL_DEBUG_IO
+	printk("ser%i rts %i\n", info->line, set);
+#endif
+#endif
+}
+
+
+/* If this behaves as a modem, RI and CD is an output */
+static inline void
+e100_ri_out(struct e100_serial *info, int set)
+{
+#ifndef CONFIG_SVINTO_SIM
+	/* RI is active low */
+	{
+		unsigned char mask = e100_modem_pins[info->line].ri_mask;
+		unsigned long flags;
+
+		local_irq_save(flags);
+		*e100_modem_pins[info->line].ri_shadow &= ~mask;
+		*e100_modem_pins[info->line].ri_shadow |= (set ? 0 : mask);
+		*e100_modem_pins[info->line].ri_port = *e100_modem_pins[info->line].ri_shadow;
+		local_irq_restore(flags);
+	}
+#endif
+}
+static inline void
+e100_cd_out(struct e100_serial *info, int set)
+{
+#ifndef CONFIG_SVINTO_SIM
+	/* CD is active low */
+	{
+		unsigned char mask = e100_modem_pins[info->line].cd_mask;
+		unsigned long flags;
+
+		local_irq_save(flags);
+		*e100_modem_pins[info->line].cd_shadow &= ~mask;
+		*e100_modem_pins[info->line].cd_shadow |= (set ? 0 : mask);
+		*e100_modem_pins[info->line].cd_port = *e100_modem_pins[info->line].cd_shadow;
+		local_irq_restore(flags);
+	}
+#endif
+}
+
+static inline void
+e100_disable_rx(struct e100_serial *info)
+{
+#ifndef CONFIG_SVINTO_SIM
+	/* disable the receiver */
+	info->ioport[REG_REC_CTRL] =
+		(info->rx_ctrl &= ~IO_MASK(R_SERIAL0_REC_CTRL, rec_enable));
+#endif
+}
+
+static inline void
+e100_enable_rx(struct e100_serial *info)
+{
+#ifndef CONFIG_SVINTO_SIM
+	/* enable the receiver */
+	info->ioport[REG_REC_CTRL] =
+		(info->rx_ctrl |= IO_MASK(R_SERIAL0_REC_CTRL, rec_enable));
+#endif
+}
+
+/* the rx DMA uses both the dma_descr and the dma_eop interrupts */
+
+static inline void
+e100_disable_rxdma_irq(struct e100_serial *info)
+{
+#ifdef SERIAL_DEBUG_INTR
+	printk("rxdma_irq(%d): 0\n",info->line);
+#endif
+	DINTR1(DEBUG_LOG(info->line,"IRQ disable_rxdma_irq %i\n", info->line));
+	*R_IRQ_MASK2_CLR = (info->irq << 2) | (info->irq << 3);
+}
+
+static inline void
+e100_enable_rxdma_irq(struct e100_serial *info)
+{
+#ifdef SERIAL_DEBUG_INTR
+	printk("rxdma_irq(%d): 1\n",info->line);
+#endif
+	DINTR1(DEBUG_LOG(info->line,"IRQ enable_rxdma_irq %i\n", info->line));
+	*R_IRQ_MASK2_SET = (info->irq << 2) | (info->irq << 3);
+}
+
+/* the tx DMA uses only dma_descr interrupt */
+
+static void e100_disable_txdma_irq(struct e100_serial *info)
+{
+#ifdef SERIAL_DEBUG_INTR
+	printk("txdma_irq(%d): 0\n",info->line);
+#endif
+	DINTR1(DEBUG_LOG(info->line,"IRQ disable_txdma_irq %i\n", info->line));
+	*R_IRQ_MASK2_CLR = info->irq;
+}
+
+static void e100_enable_txdma_irq(struct e100_serial *info)
+{
+#ifdef SERIAL_DEBUG_INTR
+	printk("txdma_irq(%d): 1\n",info->line);
+#endif
+	DINTR1(DEBUG_LOG(info->line,"IRQ enable_txdma_irq %i\n", info->line));
+	*R_IRQ_MASK2_SET = info->irq;
+}
+
+static void e100_disable_txdma_channel(struct e100_serial *info)
+{
+	unsigned long flags;
+
+	/* Disable output DMA channel for the serial port in question
+	 * ( set to something other than serialX)
+	 */
+	local_irq_save(flags);
+	DFLOW(DEBUG_LOG(info->line, "disable_txdma_channel %i\n", info->line));
+	if (info->line == 0) {
+		if ((genconfig_shadow & IO_MASK(R_GEN_CONFIG, dma6)) ==
+		    IO_STATE(R_GEN_CONFIG, dma6, serial0)) {
+			genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma6);
+			genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma6, unused);
+		}
+	} else if (info->line == 1) {
+		if ((genconfig_shadow & IO_MASK(R_GEN_CONFIG, dma8)) ==
+		    IO_STATE(R_GEN_CONFIG, dma8, serial1)) {
+			genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma8);
+			genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma8, usb);
+		}
+	} else if (info->line == 2) {
+		if ((genconfig_shadow & IO_MASK(R_GEN_CONFIG, dma2)) ==
+		    IO_STATE(R_GEN_CONFIG, dma2, serial2)) {
+			genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma2);
+			genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma2, par0);
+		}
+	} else if (info->line == 3) {
+		if ((genconfig_shadow & IO_MASK(R_GEN_CONFIG, dma4)) ==
+		    IO_STATE(R_GEN_CONFIG, dma4, serial3)) {
+			genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma4);
+			genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma4, par1);
+		}
+	}
+	*R_GEN_CONFIG = genconfig_shadow;
+	local_irq_restore(flags);
+}
+
+
+static void e100_enable_txdma_channel(struct e100_serial *info)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	DFLOW(DEBUG_LOG(info->line, "enable_txdma_channel %i\n", info->line));
+	/* Enable output DMA channel for the serial port in question */
+	if (info->line == 0) {
+		genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma6);
+		genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma6, serial0);
+	} else if (info->line == 1) {
+		genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma8);
+		genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma8, serial1);
+	} else if (info->line == 2) {
+		genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma2);
+		genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma2, serial2);
+	} else if (info->line == 3) {
+		genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma4);
+		genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma4, serial3);
+	}
+	*R_GEN_CONFIG = genconfig_shadow;
+	local_irq_restore(flags);
+}
+
+static void e100_disable_rxdma_channel(struct e100_serial *info)
+{
+	unsigned long flags;
+
+	/* Disable input DMA channel for the serial port in question
+	 * ( set to something other than serialX)
+	 */
+	local_irq_save(flags);
+	if (info->line == 0) {
+		if ((genconfig_shadow & IO_MASK(R_GEN_CONFIG, dma7)) ==
+		    IO_STATE(R_GEN_CONFIG, dma7, serial0)) {
+			genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma7);
+			genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma7, unused);
+		}
+	} else if (info->line == 1) {
+		if ((genconfig_shadow & IO_MASK(R_GEN_CONFIG, dma9)) ==
+		    IO_STATE(R_GEN_CONFIG, dma9, serial1)) {
+			genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma9);
+			genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma9, usb);
+		}
+	} else if (info->line == 2) {
+		if ((genconfig_shadow & IO_MASK(R_GEN_CONFIG, dma3)) ==
+		    IO_STATE(R_GEN_CONFIG, dma3, serial2)) {
+			genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma3);
+			genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma3, par0);
+		}
+	} else if (info->line == 3) {
+		if ((genconfig_shadow & IO_MASK(R_GEN_CONFIG, dma5)) ==
+		    IO_STATE(R_GEN_CONFIG, dma5, serial3)) {
+			genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma5);
+			genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma5, par1);
+		}
+	}
+	*R_GEN_CONFIG = genconfig_shadow;
+	local_irq_restore(flags);
+}
+
+
+static void e100_enable_rxdma_channel(struct e100_serial *info)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	/* Enable input DMA channel for the serial port in question */
+	if (info->line == 0) {
+		genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma7);
+		genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma7, serial0);
+	} else if (info->line == 1) {
+		genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma9);
+		genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma9, serial1);
+	} else if (info->line == 2) {
+		genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma3);
+		genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma3, serial2);
+	} else if (info->line == 3) {
+		genconfig_shadow &=  ~IO_MASK(R_GEN_CONFIG, dma5);
+		genconfig_shadow |= IO_STATE(R_GEN_CONFIG, dma5, serial3);
+	}
+	*R_GEN_CONFIG = genconfig_shadow;
+	local_irq_restore(flags);
+}
+
+#ifdef SERIAL_HANDLE_EARLY_ERRORS
+/* in order to detect and fix errors on the first byte
+   we have to use the serial interrupts as well. */
+
+static inline void
+e100_disable_serial_data_irq(struct e100_serial *info)
+{
+#ifdef SERIAL_DEBUG_INTR
+	printk("ser_irq(%d): 0\n",info->line);
+#endif
+	DINTR1(DEBUG_LOG(info->line,"IRQ disable data_irq %i\n", info->line));
+	*R_IRQ_MASK1_CLR = (1U << (8+2*info->line));
+}
+
+static inline void
+e100_enable_serial_data_irq(struct e100_serial *info)
+{
+#ifdef SERIAL_DEBUG_INTR
+	printk("ser_irq(%d): 1\n",info->line);
+	printk("**** %d = %d\n",
+	       (8+2*info->line),
+	       (1U << (8+2*info->line)));
+#endif
+	DINTR1(DEBUG_LOG(info->line,"IRQ enable data_irq %i\n", info->line));
+	*R_IRQ_MASK1_SET = (1U << (8+2*info->line));
+}
+#endif
+
+static inline void
+e100_disable_serial_tx_ready_irq(struct e100_serial *info)
+{
+#ifdef SERIAL_DEBUG_INTR
+	printk("ser_tx_irq(%d): 0\n",info->line);
+#endif
+	DINTR1(DEBUG_LOG(info->line,"IRQ disable ready_irq %i\n", info->line));
+	*R_IRQ_MASK1_CLR = (1U << (8+1+2*info->line));
+}
+
+static inline void
+e100_enable_serial_tx_ready_irq(struct e100_serial *info)
+{
+#ifdef SERIAL_DEBUG_INTR
+	printk("ser_tx_irq(%d): 1\n",info->line);
+	printk("**** %d = %d\n",
+	       (8+1+2*info->line),
+	       (1U << (8+1+2*info->line)));
+#endif
+	DINTR2(DEBUG_LOG(info->line,"IRQ enable ready_irq %i\n", info->line));
+	*R_IRQ_MASK1_SET = (1U << (8+1+2*info->line));
+}
+
+static inline void e100_enable_rx_irq(struct e100_serial *info)
+{
+	if (info->uses_dma_in)
+		e100_enable_rxdma_irq(info);
+	else
+		e100_enable_serial_data_irq(info);
+}
+static inline void e100_disable_rx_irq(struct e100_serial *info)
+{
+	if (info->uses_dma_in)
+		e100_disable_rxdma_irq(info);
+	else
+		e100_disable_serial_data_irq(info);
+}
+
+#if defined(CONFIG_ETRAX_RS485)
+/* Enable RS-485 mode on selected port. This is UGLY. */
+static int
+e100_enable_rs485(struct tty_struct *tty, struct serial_rs485 *r)
+{
+	struct e100_serial * info = (struct e100_serial *)tty->driver_data;
+
+#if defined(CONFIG_ETRAX_RS485_ON_PA)
+	*R_PORT_PA_DATA = port_pa_data_shadow |= (1 << rs485_pa_bit);
+#endif
+#if defined(CONFIG_ETRAX_RS485_ON_PORT_G)
+	REG_SHADOW_SET(R_PORT_G_DATA,  port_g_data_shadow,
+		       rs485_port_g_bit, 1);
+#endif
+#if defined(CONFIG_ETRAX_RS485_LTC1387)
+	REG_SHADOW_SET(R_PORT_G_DATA, port_g_data_shadow,
+		       CONFIG_ETRAX_RS485_LTC1387_DXEN_PORT_G_BIT, 1);
+	REG_SHADOW_SET(R_PORT_G_DATA, port_g_data_shadow,
+		       CONFIG_ETRAX_RS485_LTC1387_RXEN_PORT_G_BIT, 1);
+#endif
+
+	info->rs485 = *r;
+
+	/* Maximum delay before RTS equal to 1000 */
+	if (info->rs485.delay_rts_before_send >= 1000)
+		info->rs485.delay_rts_before_send = 1000;
+
+/*	printk("rts: on send = %i, after = %i, enabled = %i",
+		    info->rs485.rts_on_send,
+		    info->rs485.rts_after_sent,
+		    info->rs485.enabled
+	);
+*/
+	return 0;
+}
+
+static int
+e100_write_rs485(struct tty_struct *tty,
+                 const unsigned char *buf, int count)
+{
+	struct e100_serial * info = (struct e100_serial *)tty->driver_data;
+	int old_value = (info->rs485.flags) & SER_RS485_ENABLED;
+
+	/* rs485 is always implicitly enabled if we're using the ioctl()
+	 * but it doesn't have to be set in the serial_rs485
+	 * (to be backward compatible with old apps)
+	 * So we store, set and restore it.
+	 */
+	info->rs485.flags |= SER_RS485_ENABLED;
+	/* rs_write now deals with RS485 if enabled */
+	count = rs_write(tty, buf, count);
+	if (!old_value)
+		info->rs485.flags &= ~(SER_RS485_ENABLED);
+	return count;
+}
+
+#ifdef CONFIG_ETRAX_FAST_TIMER
+/* Timer function to toggle RTS when using FAST_TIMER */
+static void rs485_toggle_rts_timer_function(unsigned long data)
+{
+	struct e100_serial *info = (struct e100_serial *)data;
+
+	fast_timers_rs485[info->line].function = NULL;
+	e100_rts(info, (info->rs485.flags & SER_RS485_RTS_AFTER_SEND));
+#if defined(CONFIG_ETRAX_RS485_DISABLE_RECEIVER)
+	e100_enable_rx(info);
+	e100_enable_rx_irq(info);
+#endif
+}
+#endif
+#endif /* CONFIG_ETRAX_RS485 */
+
+/*
+ * ------------------------------------------------------------
+ * rs_stop() and rs_start()
+ *
+ * This routines are called before setting or resetting tty->stopped.
+ * They enable or disable transmitter using the XOFF registers, as necessary.
+ * ------------------------------------------------------------
+ */
+
+static void
+rs_stop(struct tty_struct *tty)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	if (info) {
+		unsigned long flags;
+		unsigned long xoff;
+
+		local_irq_save(flags);
+		DFLOW(DEBUG_LOG(info->line, "XOFF rs_stop xmit %i\n",
+				CIRC_CNT(info->xmit.head,
+					 info->xmit.tail,SERIAL_XMIT_SIZE)));
+
+		xoff = IO_FIELD(R_SERIAL0_XOFF, xoff_char,
+				STOP_CHAR(info->port.tty));
+		xoff |= IO_STATE(R_SERIAL0_XOFF, tx_stop, stop);
+		if (tty->termios->c_iflag & IXON ) {
+			xoff |= IO_STATE(R_SERIAL0_XOFF, auto_xoff, enable);
+		}
+
+		*((unsigned long *)&info->ioport[REG_XOFF]) = xoff;
+		local_irq_restore(flags);
+	}
+}
+
+static void
+rs_start(struct tty_struct *tty)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	if (info) {
+		unsigned long flags;
+		unsigned long xoff;
+
+		local_irq_save(flags);
+		DFLOW(DEBUG_LOG(info->line, "XOFF rs_start xmit %i\n",
+				CIRC_CNT(info->xmit.head,
+					 info->xmit.tail,SERIAL_XMIT_SIZE)));
+		xoff = IO_FIELD(R_SERIAL0_XOFF, xoff_char, STOP_CHAR(tty));
+		xoff |= IO_STATE(R_SERIAL0_XOFF, tx_stop, enable);
+		if (tty->termios->c_iflag & IXON ) {
+			xoff |= IO_STATE(R_SERIAL0_XOFF, auto_xoff, enable);
+		}
+
+		*((unsigned long *)&info->ioport[REG_XOFF]) = xoff;
+		if (!info->uses_dma_out &&
+		    info->xmit.head != info->xmit.tail && info->xmit.buf)
+			e100_enable_serial_tx_ready_irq(info);
+
+		local_irq_restore(flags);
+	}
+}
+
+/*
+ * ----------------------------------------------------------------------
+ *
+ * Here starts the interrupt handling routines.  All of the following
+ * subroutines are declared as inline and are folded into
+ * rs_interrupt().  They were separated out for readability's sake.
+ *
+ * Note: rs_interrupt() is a "fast" interrupt, which means that it
+ * runs with interrupts turned off.  People who may want to modify
+ * rs_interrupt() should try to keep the interrupt handler as fast as
+ * possible.  After you are done making modifications, it is not a bad
+ * idea to do:
+ *
+ * gcc -S -DKERNEL -Wall -Wstrict-prototypes -O6 -fomit-frame-pointer serial.c
+ *
+ * and look at the resulting assemble code in serial.s.
+ *
+ * 				- Ted Ts'o (tytso@mit.edu), 7-Mar-93
+ * -----------------------------------------------------------------------
+ */
+
+/*
+ * This routine is used by the interrupt handler to schedule
+ * processing in the software interrupt portion of the driver.
+ */
+static void rs_sched_event(struct e100_serial *info, int event)
+{
+	if (info->event & (1 << event))
+		return;
+	info->event |= 1 << event;
+	schedule_work(&info->work);
+}
+
+/* The output DMA channel is free - use it to send as many chars as possible
+ * NOTES:
+ *   We don't pay attention to info->x_char, which means if the TTY wants to
+ *   use XON/XOFF it will set info->x_char but we won't send any X char!
+ *
+ *   To implement this, we'd just start a DMA send of 1 byte pointing at a
+ *   buffer containing the X char, and skip updating xmit. We'd also have to
+ *   check if the last sent char was the X char when we enter this function
+ *   the next time, to avoid updating xmit with the sent X value.
+ */
+
+static void
+transmit_chars_dma(struct e100_serial *info)
+{
+	unsigned int c, sentl;
+	struct etrax_dma_descr *descr;
+
+#ifdef CONFIG_SVINTO_SIM
+	/* This will output too little if tail is not 0 always since
+	 * we don't reloop to send the other part. Anyway this SHOULD be a
+	 * no-op - transmit_chars_dma would never really be called during sim
+	 * since rs_write does not write into the xmit buffer then.
+	 */
+	if (info->xmit.tail)
+		printk("Error in serial.c:transmit_chars-dma(), tail!=0\n");
+	if (info->xmit.head != info->xmit.tail) {
+		SIMCOUT(info->xmit.buf + info->xmit.tail,
+			CIRC_CNT(info->xmit.head,
+				 info->xmit.tail,
+				 SERIAL_XMIT_SIZE));
+		info->xmit.head = info->xmit.tail;  /* move back head */
+		info->tr_running = 0;
+	}
+	return;
+#endif
+	/* acknowledge both dma_descr and dma_eop irq in R_DMA_CHx_CLR_INTR */
+	*info->oclrintradr =
+		IO_STATE(R_DMA_CH6_CLR_INTR, clr_descr, do) |
+		IO_STATE(R_DMA_CH6_CLR_INTR, clr_eop, do);
+
+#ifdef SERIAL_DEBUG_INTR
+	if (info->line == SERIAL_DEBUG_LINE)
+		printk("tc\n");
+#endif
+	if (!info->tr_running) {
+		/* weirdo... we shouldn't get here! */
+		printk(KERN_WARNING "Achtung: transmit_chars_dma with !tr_running\n");
+		return;
+	}
+
+	descr = &info->tr_descr;
+
+	/* first get the amount of bytes sent during the last DMA transfer,
+	   and update xmit accordingly */
+
+	/* if the stop bit was not set, all data has been sent */
+	if (!(descr->status & d_stop)) {
+		sentl = descr->sw_len;
+	} else
+		/* otherwise we find the amount of data sent here */
+		sentl = descr->hw_len;
+
+	DFLOW(DEBUG_LOG(info->line, "TX %i done\n", sentl));
+
+	/* update stats */
+	info->icount.tx += sentl;
+
+	/* update xmit buffer */
+	info->xmit.tail = (info->xmit.tail + sentl) & (SERIAL_XMIT_SIZE - 1);
+
+	/* if there is only a few chars left in the buf, wake up the blocked
+	   write if any */
+	if (CIRC_CNT(info->xmit.head,
+		     info->xmit.tail,
+		     SERIAL_XMIT_SIZE) < WAKEUP_CHARS)
+		rs_sched_event(info, RS_EVENT_WRITE_WAKEUP);
+
+	/* find out the largest amount of consecutive bytes we want to send now */
+
+	c = CIRC_CNT_TO_END(info->xmit.head, info->xmit.tail, SERIAL_XMIT_SIZE);
+
+	/* Don't send all in one DMA transfer - divide it so we wake up
+	 * application before all is sent
+	 */
+
+	if (c >= 4*WAKEUP_CHARS)
+		c = c/2;
+
+	if (c <= 0) {
+		/* our job here is done, don't schedule any new DMA transfer */
+		info->tr_running = 0;
+
+#if defined(CONFIG_ETRAX_RS485) && defined(CONFIG_ETRAX_FAST_TIMER)
+		if (info->rs485.flags & SER_RS485_ENABLED) {
+			/* Set a short timer to toggle RTS */
+			start_one_shot_timer(&fast_timers_rs485[info->line],
+			                     rs485_toggle_rts_timer_function,
+			                     (unsigned long)info,
+			                     info->char_time_usec*2,
+			                     "RS-485");
+		}
+#endif /* RS485 */
+		return;
+	}
+
+	/* ok we can schedule a dma send of c chars starting at info->xmit.tail */
+	/* set up the descriptor correctly for output */
+	DFLOW(DEBUG_LOG(info->line, "TX %i\n", c));
+	descr->ctrl = d_int | d_eol | d_wait; /* Wait needed for tty_wait_until_sent() */
+	descr->sw_len = c;
+	descr->buf = virt_to_phys(info->xmit.buf + info->xmit.tail);
+	descr->status = 0;
+
+	*info->ofirstadr = virt_to_phys(descr); /* write to R_DMAx_FIRST */
+	*info->ocmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, start);
+
+	/* DMA is now running (hopefully) */
+} /* transmit_chars_dma */
+
+static void
+start_transmit(struct e100_serial *info)
+{
+#if 0
+	if (info->line == SERIAL_DEBUG_LINE)
+		printk("x\n");
+#endif
+
+	info->tr_descr.sw_len = 0;
+	info->tr_descr.hw_len = 0;
+	info->tr_descr.status = 0;
+	info->tr_running = 1;
+	if (info->uses_dma_out)
+		transmit_chars_dma(info);
+	else
+		e100_enable_serial_tx_ready_irq(info);
+} /* start_transmit */
+
+#ifdef CONFIG_ETRAX_SERIAL_FAST_TIMER
+static int serial_fast_timer_started = 0;
+static int serial_fast_timer_expired = 0;
+static void flush_timeout_function(unsigned long data);
+#define START_FLUSH_FAST_TIMER_TIME(info, string, usec) {\
+  unsigned long timer_flags; \
+  local_irq_save(timer_flags); \
+  if (fast_timers[info->line].function == NULL) { \
+    serial_fast_timer_started++; \
+    TIMERD(DEBUG_LOG(info->line, "start_timer %i ", info->line)); \
+    TIMERD(DEBUG_LOG(info->line, "num started: %i\n", serial_fast_timer_started)); \
+    start_one_shot_timer(&fast_timers[info->line], \
+                         flush_timeout_function, \
+                         (unsigned long)info, \
+                         (usec), \
+                         string); \
+  } \
+  else { \
+    TIMERD(DEBUG_LOG(info->line, "timer %i already running\n", info->line)); \
+  } \
+  local_irq_restore(timer_flags); \
+}
+#define START_FLUSH_FAST_TIMER(info, string) START_FLUSH_FAST_TIMER_TIME(info, string, info->flush_time_usec)
+
+#else
+#define START_FLUSH_FAST_TIMER_TIME(info, string, usec)
+#define START_FLUSH_FAST_TIMER(info, string)
+#endif
+
+static struct etrax_recv_buffer *
+alloc_recv_buffer(unsigned int size)
+{
+	struct etrax_recv_buffer *buffer;
+
+	if (!(buffer = kmalloc(sizeof *buffer + size, GFP_ATOMIC)))
+		return NULL;
+
+	buffer->next = NULL;
+	buffer->length = 0;
+	buffer->error = TTY_NORMAL;
+
+	return buffer;
+}
+
+static void
+append_recv_buffer(struct e100_serial *info, struct etrax_recv_buffer *buffer)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	if (!info->first_recv_buffer)
+		info->first_recv_buffer = buffer;
+	else
+		info->last_recv_buffer->next = buffer;
+
+	info->last_recv_buffer = buffer;
+
+	info->recv_cnt += buffer->length;
+	if (info->recv_cnt > info->max_recv_cnt)
+		info->max_recv_cnt = info->recv_cnt;
+
+	local_irq_restore(flags);
+}
+
+static int
+add_char_and_flag(struct e100_serial *info, unsigned char data, unsigned char flag)
+{
+	struct etrax_recv_buffer *buffer;
+	if (info->uses_dma_in) {
+		if (!(buffer = alloc_recv_buffer(4)))
+			return 0;
+
+		buffer->length = 1;
+		buffer->error = flag;
+		buffer->buffer[0] = data;
+
+		append_recv_buffer(info, buffer);
+
+		info->icount.rx++;
+	} else {
+		struct tty_struct *tty = info->port.tty;
+		tty_insert_flip_char(tty, data, flag);
+		info->icount.rx++;
+	}
+
+	return 1;
+}
+
+static unsigned int handle_descr_data(struct e100_serial *info,
+				      struct etrax_dma_descr *descr,
+				      unsigned int recvl)
+{
+	struct etrax_recv_buffer *buffer = phys_to_virt(descr->buf) - sizeof *buffer;
+
+	if (info->recv_cnt + recvl > 65536) {
+		printk(KERN_CRIT
+		       "%s: Too much pending incoming serial data! Dropping %u bytes.\n", __func__, recvl);
+		return 0;
+	}
+
+	buffer->length = recvl;
+
+	if (info->errorcode == ERRCODE_SET_BREAK)
+		buffer->error = TTY_BREAK;
+	info->errorcode = 0;
+
+	append_recv_buffer(info, buffer);
+
+	if (!(buffer = alloc_recv_buffer(SERIAL_DESCR_BUF_SIZE)))
+		panic("%s: Failed to allocate memory for receive buffer!\n", __func__);
+
+	descr->buf = virt_to_phys(buffer->buffer);
+
+	return recvl;
+}
+
+static unsigned int handle_all_descr_data(struct e100_serial *info)
+{
+	struct etrax_dma_descr *descr;
+	unsigned int recvl;
+	unsigned int ret = 0;
+
+	while (1)
+	{
+		descr = &info->rec_descr[info->cur_rec_descr];
+
+		if (descr == phys_to_virt(*info->idescradr))
+			break;
+
+		if (++info->cur_rec_descr == SERIAL_RECV_DESCRIPTORS)
+			info->cur_rec_descr = 0;
+
+		/* find out how many bytes were read */
+
+		/* if the eop bit was not set, all data has been received */
+		if (!(descr->status & d_eop)) {
+			recvl = descr->sw_len;
+		} else {
+			/* otherwise we find the amount of data received here */
+			recvl = descr->hw_len;
+		}
+
+		/* Reset the status information */
+		descr->status = 0;
+
+		DFLOW(  DEBUG_LOG(info->line, "RX %lu\n", recvl);
+			if (info->port.tty->stopped) {
+				unsigned char *buf = phys_to_virt(descr->buf);
+				DEBUG_LOG(info->line, "rx 0x%02X\n", buf[0]);
+				DEBUG_LOG(info->line, "rx 0x%02X\n", buf[1]);
+				DEBUG_LOG(info->line, "rx 0x%02X\n", buf[2]);
+			}
+			);
+
+		/* update stats */
+		info->icount.rx += recvl;
+
+		ret += handle_descr_data(info, descr, recvl);
+	}
+
+	return ret;
+}
+
+static void receive_chars_dma(struct e100_serial *info)
+{
+	struct tty_struct *tty;
+	unsigned char rstat;
+
+#ifdef CONFIG_SVINTO_SIM
+	/* No receive in the simulator.  Will probably be when the rest of
+	 * the serial interface works, and this piece will just be removed.
+	 */
+	return;
+#endif
+
+	/* Acknowledge both dma_descr and dma_eop irq in R_DMA_CHx_CLR_INTR */
+	*info->iclrintradr =
+		IO_STATE(R_DMA_CH6_CLR_INTR, clr_descr, do) |
+		IO_STATE(R_DMA_CH6_CLR_INTR, clr_eop, do);
+
+	tty = info->port.tty;
+	if (!tty) /* Something wrong... */
+		return;
+
+#ifdef SERIAL_HANDLE_EARLY_ERRORS
+	if (info->uses_dma_in)
+		e100_enable_serial_data_irq(info);
+#endif
+
+	if (info->errorcode == ERRCODE_INSERT_BREAK)
+		add_char_and_flag(info, '\0', TTY_BREAK);
+
+	handle_all_descr_data(info);
+
+	/* Read the status register to detect errors */
+	rstat = info->ioport[REG_STATUS];
+	if (rstat & IO_MASK(R_SERIAL0_STATUS, xoff_detect) ) {
+		DFLOW(DEBUG_LOG(info->line, "XOFF detect stat %x\n", rstat));
+	}
+
+	if (rstat & SER_ERROR_MASK) {
+		/* If we got an error, we must reset it by reading the
+		 * data_in field
+		 */
+		unsigned char data = info->ioport[REG_DATA];
+
+		PROCSTAT(ser_stat[info->line].errors_cnt++);
+		DEBUG_LOG(info->line, "#dERR: s d 0x%04X\n",
+			  ((rstat & SER_ERROR_MASK) << 8) | data);
+
+		if (rstat & SER_PAR_ERR_MASK)
+			add_char_and_flag(info, data, TTY_PARITY);
+		else if (rstat & SER_OVERRUN_MASK)
+			add_char_and_flag(info, data, TTY_OVERRUN);
+		else if (rstat & SER_FRAMING_ERR_MASK)
+			add_char_and_flag(info, data, TTY_FRAME);
+	}
+
+	START_FLUSH_FAST_TIMER(info, "receive_chars");
+
+	/* Restart the receiving DMA */
+	*info->icmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, restart);
+}
+
+static int start_recv_dma(struct e100_serial *info)
+{
+	struct etrax_dma_descr *descr = info->rec_descr;
+	struct etrax_recv_buffer *buffer;
+        int i;
+
+	/* Set up the receiving descriptors */
+	for (i = 0; i < SERIAL_RECV_DESCRIPTORS; i++) {
+		if (!(buffer = alloc_recv_buffer(SERIAL_DESCR_BUF_SIZE)))
+			panic("%s: Failed to allocate memory for receive buffer!\n", __func__);
+
+		descr[i].ctrl = d_int;
+		descr[i].buf = virt_to_phys(buffer->buffer);
+		descr[i].sw_len = SERIAL_DESCR_BUF_SIZE;
+		descr[i].hw_len = 0;
+		descr[i].status = 0;
+		descr[i].next = virt_to_phys(&descr[i+1]);
+	}
+
+	/* Link the last descriptor to the first */
+	descr[i-1].next = virt_to_phys(&descr[0]);
+
+	/* Start with the first descriptor in the list */
+	info->cur_rec_descr = 0;
+
+	/* Start the DMA */
+	*info->ifirstadr = virt_to_phys(&descr[info->cur_rec_descr]);
+	*info->icmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, start);
+
+	/* Input DMA should be running now */
+	return 1;
+}
+
+static void
+start_receive(struct e100_serial *info)
+{
+#ifdef CONFIG_SVINTO_SIM
+	/* No receive in the simulator.  Will probably be when the rest of
+	 * the serial interface works, and this piece will just be removed.
+	 */
+	return;
+#endif
+	if (info->uses_dma_in) {
+		/* reset the input dma channel to be sure it works */
+
+		*info->icmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, reset);
+		while (IO_EXTRACT(R_DMA_CH6_CMD, cmd, *info->icmdadr) ==
+		       IO_STATE_VALUE(R_DMA_CH6_CMD, cmd, reset));
+
+		start_recv_dma(info);
+	}
+}
+
+
+/* the bits in the MASK2 register are laid out like this:
+   DMAI_EOP DMAI_DESCR DMAO_EOP DMAO_DESCR
+   where I is the input channel and O is the output channel for the port.
+   info->irq is the bit number for the DMAO_DESCR so to check the others we
+   shift info->irq to the left.
+*/
+
+/* dma output channel interrupt handler
+   this interrupt is called from DMA2(ser2), DMA4(ser3), DMA6(ser0) or
+   DMA8(ser1) when they have finished a descriptor with the intr flag set.
+*/
+
+static irqreturn_t
+tr_interrupt(int irq, void *dev_id)
+{
+	struct e100_serial *info;
+	unsigned long ireg;
+	int i;
+	int handled = 0;
+
+#ifdef CONFIG_SVINTO_SIM
+	/* No receive in the simulator.  Will probably be when the rest of
+	 * the serial interface works, and this piece will just be removed.
+	 */
+	{
+		const char *s = "What? tr_interrupt in simulator??\n";
+		SIMCOUT(s,strlen(s));
+	}
+	return IRQ_HANDLED;
+#endif
+
+	/* find out the line that caused this irq and get it from rs_table */
+
+	ireg = *R_IRQ_MASK2_RD;  /* get the active irq bits for the dma channels */
+
+	for (i = 0; i < NR_PORTS; i++) {
+		info = rs_table + i;
+		if (!info->enabled || !info->uses_dma_out)
+			continue;
+		/* check for dma_descr (don't need to check for dma_eop in output dma for serial */
+		if (ireg & info->irq) {
+			handled = 1;
+			/* we can send a new dma bunch. make it so. */
+			DINTR2(DEBUG_LOG(info->line, "tr_interrupt %i\n", i));
+			/* Read jiffies_usec first,
+			 * we want this time to be as late as possible
+			 */
+ 			PROCSTAT(ser_stat[info->line].tx_dma_ints++);
+			info->last_tx_active_usec = GET_JIFFIES_USEC();
+			info->last_tx_active = jiffies;
+			transmit_chars_dma(info);
+		}
+
+		/* FIXME: here we should really check for a change in the
+		   status lines and if so call status_handle(info) */
+	}
+	return IRQ_RETVAL(handled);
+} /* tr_interrupt */
+
+/* dma input channel interrupt handler */
+
+static irqreturn_t
+rec_interrupt(int irq, void *dev_id)
+{
+	struct e100_serial *info;
+	unsigned long ireg;
+	int i;
+	int handled = 0;
+
+#ifdef CONFIG_SVINTO_SIM
+	/* No receive in the simulator.  Will probably be when the rest of
+	 * the serial interface works, and this piece will just be removed.
+	 */
+	{
+		const char *s = "What? rec_interrupt in simulator??\n";
+		SIMCOUT(s,strlen(s));
+	}
+	return IRQ_HANDLED;
+#endif
+
+	/* find out the line that caused this irq and get it from rs_table */
+
+	ireg = *R_IRQ_MASK2_RD;  /* get the active irq bits for the dma channels */
+
+	for (i = 0; i < NR_PORTS; i++) {
+		info = rs_table + i;
+		if (!info->enabled || !info->uses_dma_in)
+			continue;
+		/* check for both dma_eop and dma_descr for the input dma channel */
+		if (ireg & ((info->irq << 2) | (info->irq << 3))) {
+			handled = 1;
+			/* we have received something */
+			receive_chars_dma(info);
+		}
+
+		/* FIXME: here we should really check for a change in the
+		   status lines and if so call status_handle(info) */
+	}
+	return IRQ_RETVAL(handled);
+} /* rec_interrupt */
+
+static int force_eop_if_needed(struct e100_serial *info)
+{
+	/* We check data_avail bit to determine if data has
+	 * arrived since last time
+	 */
+	unsigned char rstat = info->ioport[REG_STATUS];
+
+	/* error or datavail? */
+	if (rstat & SER_ERROR_MASK) {
+		/* Some error has occurred. If there has been valid data, an
+		 * EOP interrupt will be made automatically. If no data, the
+		 * normal ser_interrupt should be enabled and handle it.
+		 * So do nothing!
+		 */
+		DEBUG_LOG(info->line, "timeout err: rstat 0x%03X\n",
+		          rstat | (info->line << 8));
+		return 0;
+	}
+
+	if (rstat & SER_DATA_AVAIL_MASK) {
+		/* Ok data, no error, count it */
+		TIMERD(DEBUG_LOG(info->line, "timeout: rstat 0x%03X\n",
+		          rstat | (info->line << 8)));
+		/* Read data to clear status flags */
+		(void)info->ioport[REG_DATA];
+
+		info->forced_eop = 0;
+		START_FLUSH_FAST_TIMER(info, "magic");
+		return 0;
+	}
+
+	/* hit the timeout, force an EOP for the input
+	 * dma channel if we haven't already
+	 */
+	if (!info->forced_eop) {
+		info->forced_eop = 1;
+		PROCSTAT(ser_stat[info->line].timeout_flush_cnt++);
+		TIMERD(DEBUG_LOG(info->line, "timeout EOP %i\n", info->line));
+		FORCE_EOP(info);
+	}
+
+	return 1;
+}
+
+static void flush_to_flip_buffer(struct e100_serial *info)
+{
+	struct tty_struct *tty;
+	struct etrax_recv_buffer *buffer;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	tty = info->port.tty;
+
+	if (!tty) {
+		local_irq_restore(flags);
+		return;
+	}
+
+	while ((buffer = info->first_recv_buffer) != NULL) {
+		unsigned int count = buffer->length;
+
+		tty_insert_flip_string(tty, buffer->buffer, count);
+		info->recv_cnt -= count;
+
+		if (count == buffer->length) {
+			info->first_recv_buffer = buffer->next;
+			kfree(buffer);
+		} else {
+			buffer->length -= count;
+			memmove(buffer->buffer, buffer->buffer + count, buffer->length);
+			buffer->error = TTY_NORMAL;
+		}
+	}
+
+	if (!info->first_recv_buffer)
+		info->last_recv_buffer = NULL;
+
+	local_irq_restore(flags);
+
+	/* This includes a check for low-latency */
+	tty_flip_buffer_push(tty);
+}
+
+static void check_flush_timeout(struct e100_serial *info)
+{
+	/* Flip what we've got (if we can) */
+	flush_to_flip_buffer(info);
+
+	/* We might need to flip later, but not to fast
+	 * since the system is busy processing input... */
+	if (info->first_recv_buffer)
+		START_FLUSH_FAST_TIMER_TIME(info, "flip", 2000);
+
+	/* Force eop last, since data might have come while we're processing
+	 * and if we started the slow timer above, we won't start a fast
+	 * below.
+	 */
+	force_eop_if_needed(info);
+}
+
+#ifdef CONFIG_ETRAX_SERIAL_FAST_TIMER
+static void flush_timeout_function(unsigned long data)
+{
+	struct e100_serial *info = (struct e100_serial *)data;
+
+	fast_timers[info->line].function = NULL;
+	serial_fast_timer_expired++;
+	TIMERD(DEBUG_LOG(info->line, "flush_timout %i ", info->line));
+	TIMERD(DEBUG_LOG(info->line, "num expired: %i\n", serial_fast_timer_expired));
+	check_flush_timeout(info);
+}
+
+#else
+
+/* dma fifo/buffer timeout handler
+   forces an end-of-packet for the dma input channel if no chars
+   have been received for CONFIG_ETRAX_SERIAL_RX_TIMEOUT_TICKS/100 s.
+*/
+
+static struct timer_list flush_timer;
+
+static void
+timed_flush_handler(unsigned long ptr)
+{
+	struct e100_serial *info;
+	int i;
+
+#ifdef CONFIG_SVINTO_SIM
+	return;
+#endif
+
+	for (i = 0; i < NR_PORTS; i++) {
+		info = rs_table + i;
+		if (info->uses_dma_in)
+			check_flush_timeout(info);
+	}
+
+	/* restart flush timer */
+	mod_timer(&flush_timer, jiffies + CONFIG_ETRAX_SERIAL_RX_TIMEOUT_TICKS);
+}
+#endif
+
+#ifdef SERIAL_HANDLE_EARLY_ERRORS
+
+/* If there is an error (ie break) when the DMA is running and
+ * there are no bytes in the fifo the DMA is stopped and we get no
+ * eop interrupt. Thus we have to monitor the first bytes on a DMA
+ * transfer, and if it is without error we can turn the serial
+ * interrupts off.
+ */
+
+/*
+BREAK handling on ETRAX 100:
+ETRAX will generate interrupt although there is no stop bit between the
+characters.
+
+Depending on how long the break sequence is, the end of the breaksequence
+will look differently:
+| indicates start/end of a character.
+
+B= Break character (0x00) with framing error.
+E= Error byte with parity error received after B characters.
+F= "Faked" valid byte received immediately after B characters.
+V= Valid byte
+
+1.
+    B          BL         ___________________________ V
+.._|__________|__________|                           |valid data |
+
+Multiple frame errors with data == 0x00 (B),
+the timing matches up "perfectly" so no extra ending char is detected.
+The RXD pin is 1 in the last interrupt, in that case
+we set info->errorcode = ERRCODE_INSERT_BREAK, but we can't really
+know if another byte will come and this really is case 2. below
+(e.g F=0xFF or 0xFE)
+If RXD pin is 0 we can expect another character (see 2. below).
+
+
+2.
+
+    B          B          E or F__________________..__ V
+.._|__________|__________|______    |                 |valid data
+                          "valid" or
+                          parity error
+
+Multiple frame errors with data == 0x00 (B),
+but the part of the break trigs is interpreted as a start bit (and possibly
+some 0 bits followed by a number of 1 bits and a stop bit).
+Depending on parity settings etc. this last character can be either
+a fake "valid" char (F) or have a parity error (E).
+
+If the character is valid it will be put in the buffer,
+we set info->errorcode = ERRCODE_SET_BREAK so the receive interrupt
+will set the flags so the tty will handle it,
+if it's an error byte it will not be put in the buffer
+and we set info->errorcode = ERRCODE_INSERT_BREAK.
+
+To distinguish a V byte in 1. from an F byte in 2. we keep a timestamp
+of the last faulty char (B) and compares it with the current time:
+If the time elapsed time is less then 2*char_time_usec we will assume
+it's a faked F char and not a Valid char and set
+info->errorcode = ERRCODE_SET_BREAK.
+
+Flaws in the above solution:
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+We use the timer to distinguish a F character from a V character,
+if a V character is to close after the break we might make the wrong decision.
+
+TODO: The break will be delayed until an F or V character is received.
+
+*/
+
+static
+struct e100_serial * handle_ser_rx_interrupt_no_dma(struct e100_serial *info)
+{
+	unsigned long data_read;
+	struct tty_struct *tty = info->port.tty;
+
+	if (!tty) {
+		printk("!NO TTY!\n");
+		return info;
+	}
+
+	/* Read data and status at the same time */
+	data_read = *((unsigned long *)&info->ioport[REG_DATA_STATUS32]);
+more_data:
+	if (data_read & IO_MASK(R_SERIAL0_READ, xoff_detect) ) {
+		DFLOW(DEBUG_LOG(info->line, "XOFF detect\n", 0));
+	}
+	DINTR2(DEBUG_LOG(info->line, "ser_rx   %c\n", IO_EXTRACT(R_SERIAL0_READ, data_in, data_read)));
+
+	if (data_read & ( IO_MASK(R_SERIAL0_READ, framing_err) |
+			  IO_MASK(R_SERIAL0_READ, par_err) |
+			  IO_MASK(R_SERIAL0_READ, overrun) )) {
+		/* An error */
+		info->last_rx_active_usec = GET_JIFFIES_USEC();
+		info->last_rx_active = jiffies;
+		DINTR1(DEBUG_LOG(info->line, "ser_rx err stat_data %04X\n", data_read));
+		DLOG_INT_TRIG(
+		if (!log_int_trig1_pos) {
+			log_int_trig1_pos = log_int_pos;
+			log_int(rdpc(), 0, 0);
+		}
+		);
+
+
+		if ( ((data_read & IO_MASK(R_SERIAL0_READ, data_in)) == 0) &&
+		     (data_read & IO_MASK(R_SERIAL0_READ, framing_err)) ) {
+			/* Most likely a break, but we get interrupts over and
+			 * over again.
+			 */
+
+			if (!info->break_detected_cnt) {
+				DEBUG_LOG(info->line, "#BRK start\n", 0);
+			}
+			if (data_read & IO_MASK(R_SERIAL0_READ, rxd)) {
+				/* The RX pin is high now, so the break
+				 * must be over, but....
+				 * we can't really know if we will get another
+				 * last byte ending the break or not.
+				 * And we don't know if the byte (if any) will
+				 * have an error or look valid.
+				 */
+				DEBUG_LOG(info->line, "# BL BRK\n", 0);
+				info->errorcode = ERRCODE_INSERT_BREAK;
+			}
+			info->break_detected_cnt++;
+		} else {
+			/* The error does not look like a break, but could be
+			 * the end of one
+			 */
+			if (info->break_detected_cnt) {
+				DEBUG_LOG(info->line, "EBRK %i\n", info->break_detected_cnt);
+				info->errorcode = ERRCODE_INSERT_BREAK;
+			} else {
+				unsigned char data = IO_EXTRACT(R_SERIAL0_READ,
+					data_in, data_read);
+				char flag = TTY_NORMAL;
+				if (info->errorcode == ERRCODE_INSERT_BREAK) {
+					struct tty_struct *tty = info->port.tty;
+					tty_insert_flip_char(tty, 0, flag);
+					info->icount.rx++;
+				}
+
+				if (data_read & IO_MASK(R_SERIAL0_READ, par_err)) {
+					info->icount.parity++;
+					flag = TTY_PARITY;
+				} else if (data_read & IO_MASK(R_SERIAL0_READ, overrun)) {
+					info->icount.overrun++;
+					flag = TTY_OVERRUN;
+				} else if (data_read & IO_MASK(R_SERIAL0_READ, framing_err)) {
+					info->icount.frame++;
+					flag = TTY_FRAME;
+				}
+				tty_insert_flip_char(tty, data, flag);
+				info->errorcode = 0;
+			}
+			info->break_detected_cnt = 0;
+		}
+	} else if (data_read & IO_MASK(R_SERIAL0_READ, data_avail)) {
+		/* No error */
+		DLOG_INT_TRIG(
+		if (!log_int_trig1_pos) {
+			if (log_int_pos >= log_int_size) {
+				log_int_pos = 0;
+			}
+			log_int_trig0_pos = log_int_pos;
+			log_int(rdpc(), 0, 0);
+		}
+		);
+		tty_insert_flip_char(tty,
+			IO_EXTRACT(R_SERIAL0_READ, data_in, data_read),
+			TTY_NORMAL);
+	} else {
+		DEBUG_LOG(info->line, "ser_rx int but no data_avail  %08lX\n", data_read);
+	}
+
+
+	info->icount.rx++;
+	data_read = *((unsigned long *)&info->ioport[REG_DATA_STATUS32]);
+	if (data_read & IO_MASK(R_SERIAL0_READ, data_avail)) {
+		DEBUG_LOG(info->line, "ser_rx   %c in loop\n", IO_EXTRACT(R_SERIAL0_READ, data_in, data_read));
+		goto more_data;
+	}
+
+	tty_flip_buffer_push(info->port.tty);
+	return info;
+}
+
+static struct e100_serial* handle_ser_rx_interrupt(struct e100_serial *info)
+{
+	unsigned char rstat;
+
+#ifdef SERIAL_DEBUG_INTR
+	printk("Interrupt from serport %d\n", i);
+#endif
+/*	DEBUG_LOG(info->line, "ser_interrupt stat %03X\n", rstat | (i << 8)); */
+	if (!info->uses_dma_in) {
+		return handle_ser_rx_interrupt_no_dma(info);
+	}
+	/* DMA is used */
+	rstat = info->ioport[REG_STATUS];
+	if (rstat & IO_MASK(R_SERIAL0_STATUS, xoff_detect) ) {
+		DFLOW(DEBUG_LOG(info->line, "XOFF detect\n", 0));
+	}
+
+	if (rstat & SER_ERROR_MASK) {
+		unsigned char data;
+
+		info->last_rx_active_usec = GET_JIFFIES_USEC();
+		info->last_rx_active = jiffies;
+		/* If we got an error, we must reset it by reading the
+		 * data_in field
+		 */
+		data = info->ioport[REG_DATA];
+		DINTR1(DEBUG_LOG(info->line, "ser_rx!  %c\n", data));
+		DINTR1(DEBUG_LOG(info->line, "ser_rx err stat %02X\n", rstat));
+		if (!data && (rstat & SER_FRAMING_ERR_MASK)) {
+			/* Most likely a break, but we get interrupts over and
+			 * over again.
+			 */
+
+			if (!info->break_detected_cnt) {
+				DEBUG_LOG(info->line, "#BRK start\n", 0);
+			}
+			if (rstat & SER_RXD_MASK) {
+				/* The RX pin is high now, so the break
+				 * must be over, but....
+				 * we can't really know if we will get another
+				 * last byte ending the break or not.
+				 * And we don't know if the byte (if any) will
+				 * have an error or look valid.
+				 */
+				DEBUG_LOG(info->line, "# BL BRK\n", 0);
+				info->errorcode = ERRCODE_INSERT_BREAK;
+			}
+			info->break_detected_cnt++;
+		} else {
+			/* The error does not look like a break, but could be
+			 * the end of one
+			 */
+			if (info->break_detected_cnt) {
+				DEBUG_LOG(info->line, "EBRK %i\n", info->break_detected_cnt);
+				info->errorcode = ERRCODE_INSERT_BREAK;
+			} else {
+				if (info->errorcode == ERRCODE_INSERT_BREAK) {
+					info->icount.brk++;
+					add_char_and_flag(info, '\0', TTY_BREAK);
+				}
+
+				if (rstat & SER_PAR_ERR_MASK) {
+					info->icount.parity++;
+					add_char_and_flag(info, data, TTY_PARITY);
+				} else if (rstat & SER_OVERRUN_MASK) {
+					info->icount.overrun++;
+					add_char_and_flag(info, data, TTY_OVERRUN);
+				} else if (rstat & SER_FRAMING_ERR_MASK) {
+					info->icount.frame++;
+					add_char_and_flag(info, data, TTY_FRAME);
+				}
+
+				info->errorcode = 0;
+			}
+			info->break_detected_cnt = 0;
+			DEBUG_LOG(info->line, "#iERR s d %04X\n",
+			          ((rstat & SER_ERROR_MASK) << 8) | data);
+		}
+		PROCSTAT(ser_stat[info->line].early_errors_cnt++);
+	} else { /* It was a valid byte, now let the DMA do the rest */
+		unsigned long curr_time_u = GET_JIFFIES_USEC();
+		unsigned long curr_time = jiffies;
+
+		if (info->break_detected_cnt) {
+			/* Detect if this character is a new valid char or the
+			 * last char in a break sequence: If LSBits are 0 and
+			 * MSBits are high AND the time is close to the
+			 * previous interrupt we should discard it.
+			 */
+			long elapsed_usec =
+			  (curr_time - info->last_rx_active) * (1000000/HZ) +
+			  curr_time_u - info->last_rx_active_usec;
+			if (elapsed_usec < 2*info->char_time_usec) {
+				DEBUG_LOG(info->line, "FBRK %i\n", info->line);
+				/* Report as BREAK (error) and let
+				 * receive_chars_dma() handle it
+				 */
+				info->errorcode = ERRCODE_SET_BREAK;
+			} else {
+				DEBUG_LOG(info->line, "Not end of BRK (V)%i\n", info->line);
+			}
+			DEBUG_LOG(info->line, "num brk %i\n", info->break_detected_cnt);
+		}
+
+#ifdef SERIAL_DEBUG_INTR
+		printk("** OK, disabling ser_interrupts\n");
+#endif
+		e100_disable_serial_data_irq(info);
+		DINTR2(DEBUG_LOG(info->line, "ser_rx OK %d\n", info->line));
+		info->break_detected_cnt = 0;
+
+		PROCSTAT(ser_stat[info->line].ser_ints_ok_cnt++);
+	}
+	/* Restarting the DMA never hurts */
+	*info->icmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, restart);
+	START_FLUSH_FAST_TIMER(info, "ser_int");
+	return info;
+} /* handle_ser_rx_interrupt */
+
+static void handle_ser_tx_interrupt(struct e100_serial *info)
+{
+	unsigned long flags;
+
+	if (info->x_char) {
+		unsigned char rstat;
+		DFLOW(DEBUG_LOG(info->line, "tx_int: xchar 0x%02X\n", info->x_char));
+		local_irq_save(flags);
+		rstat = info->ioport[REG_STATUS];
+		DFLOW(DEBUG_LOG(info->line, "stat %x\n", rstat));
+
+		info->ioport[REG_TR_DATA] = info->x_char;
+		info->icount.tx++;
+		info->x_char = 0;
+		/* We must enable since it is disabled in ser_interrupt */
+		e100_enable_serial_tx_ready_irq(info);
+		local_irq_restore(flags);
+		return;
+	}
+	if (info->uses_dma_out) {
+		unsigned char rstat;
+		int i;
+		/* We only use normal tx interrupt when sending x_char */
+		DFLOW(DEBUG_LOG(info->line, "tx_int: xchar sent\n", 0));
+		local_irq_save(flags);
+		rstat = info->ioport[REG_STATUS];
+		DFLOW(DEBUG_LOG(info->line, "stat %x\n", rstat));
+		e100_disable_serial_tx_ready_irq(info);
+		if (info->port.tty->stopped)
+			rs_stop(info->port.tty);
+		/* Enable the DMA channel and tell it to continue */
+		e100_enable_txdma_channel(info);
+		/* Wait 12 cycles before doing the DMA command */
+		for(i = 6;  i > 0; i--)
+			nop();
+
+		*info->ocmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, continue);
+		local_irq_restore(flags);
+		return;
+	}
+	/* Normal char-by-char interrupt */
+	if (info->xmit.head == info->xmit.tail
+	    || info->port.tty->stopped
+	    || info->port.tty->hw_stopped) {
+		DFLOW(DEBUG_LOG(info->line, "tx_int: stopped %i\n",
+				info->port.tty->stopped));
+		e100_disable_serial_tx_ready_irq(info);
+		info->tr_running = 0;
+		return;
+	}
+	DINTR2(DEBUG_LOG(info->line, "tx_int %c\n", info->xmit.buf[info->xmit.tail]));
+	/* Send a byte, rs485 timing is critical so turn of ints */
+	local_irq_save(flags);
+	info->ioport[REG_TR_DATA] = info->xmit.buf[info->xmit.tail];
+	info->xmit.tail = (info->xmit.tail + 1) & (SERIAL_XMIT_SIZE-1);
+	info->icount.tx++;
+	if (info->xmit.head == info->xmit.tail) {
+#if defined(CONFIG_ETRAX_RS485) && defined(CONFIG_ETRAX_FAST_TIMER)
+		if (info->rs485.flags & SER_RS485_ENABLED) {
+			/* Set a short timer to toggle RTS */
+			start_one_shot_timer(&fast_timers_rs485[info->line],
+			                     rs485_toggle_rts_timer_function,
+			                     (unsigned long)info,
+			                     info->char_time_usec*2,
+			                     "RS-485");
+		}
+#endif /* RS485 */
+		info->last_tx_active_usec = GET_JIFFIES_USEC();
+		info->last_tx_active = jiffies;
+		e100_disable_serial_tx_ready_irq(info);
+		info->tr_running = 0;
+		DFLOW(DEBUG_LOG(info->line, "tx_int: stop2\n", 0));
+	} else {
+		/* We must enable since it is disabled in ser_interrupt */
+		e100_enable_serial_tx_ready_irq(info);
+	}
+	local_irq_restore(flags);
+
+	if (CIRC_CNT(info->xmit.head,
+		     info->xmit.tail,
+		     SERIAL_XMIT_SIZE) < WAKEUP_CHARS)
+		rs_sched_event(info, RS_EVENT_WRITE_WAKEUP);
+
+} /* handle_ser_tx_interrupt */
+
+/* result of time measurements:
+ * RX duration 54-60 us when doing something, otherwise 6-9 us
+ * ser_int duration: just sending: 8-15 us normally, up to 73 us
+ */
+static irqreturn_t
+ser_interrupt(int irq, void *dev_id)
+{
+	static volatile int tx_started = 0;
+	struct e100_serial *info;
+	int i;
+	unsigned long flags;
+	unsigned long irq_mask1_rd;
+	unsigned long data_mask = (1 << (8+2*0)); /* ser0 data_avail */
+	int handled = 0;
+	static volatile unsigned long reentered_ready_mask = 0;
+
+	local_irq_save(flags);
+	irq_mask1_rd = *R_IRQ_MASK1_RD;
+	/* First handle all rx interrupts with ints disabled */
+	info = rs_table;
+	irq_mask1_rd &= e100_ser_int_mask;
+	for (i = 0; i < NR_PORTS; i++) {
+		/* Which line caused the data irq? */
+		if (irq_mask1_rd & data_mask) {
+			handled = 1;
+			handle_ser_rx_interrupt(info);
+		}
+		info += 1;
+		data_mask <<= 2;
+	}
+	/* Handle tx interrupts with interrupts enabled so we
+	 * can take care of new data interrupts while transmitting
+	 * We protect the tx part with the tx_started flag.
+	 * We disable the tr_ready interrupts we are about to handle and
+	 * unblock the serial interrupt so new serial interrupts may come.
+	 *
+	 * If we get a new interrupt:
+	 *  - it migth be due to synchronous serial ports.
+	 *  - serial irq will be blocked by general irq handler.
+	 *  - async data will be handled above (sync will be ignored).
+	 *  - tx_started flag will prevent us from trying to send again and
+	 *    we will exit fast - no need to unblock serial irq.
+	 *  - Next (sync) serial interrupt handler will be runned with
+	 *    disabled interrupt due to restore_flags() at end of function,
+	 *    so sync handler will not be preempted or reentered.
+	 */
+	if (!tx_started) {
+		unsigned long ready_mask;
+		unsigned long
+		tx_started = 1;
+		/* Only the tr_ready interrupts left */
+		irq_mask1_rd &= (IO_MASK(R_IRQ_MASK1_RD, ser0_ready) |
+				 IO_MASK(R_IRQ_MASK1_RD, ser1_ready) |
+				 IO_MASK(R_IRQ_MASK1_RD, ser2_ready) |
+				 IO_MASK(R_IRQ_MASK1_RD, ser3_ready));
+		while (irq_mask1_rd) {
+			/* Disable those we are about to handle */
+			*R_IRQ_MASK1_CLR = irq_mask1_rd;
+			/* Unblock the serial interrupt */
+			*R_VECT_MASK_SET = IO_STATE(R_VECT_MASK_SET, serial, set);
+
+			local_irq_enable();
+			ready_mask = (1 << (8+1+2*0)); /* ser0 tr_ready */
+			info = rs_table;
+			for (i = 0; i < NR_PORTS; i++) {
+				/* Which line caused the ready irq? */
+				if (irq_mask1_rd & ready_mask) {
+					handled = 1;
+					handle_ser_tx_interrupt(info);
+				}
+				info += 1;
+				ready_mask <<= 2;
+			}
+			/* handle_ser_tx_interrupt enables tr_ready interrupts */
+			local_irq_disable();
+			/* Handle reentered TX interrupt */
+			irq_mask1_rd = reentered_ready_mask;
+		}
+		local_irq_disable();
+		tx_started = 0;
+	} else {
+		unsigned long ready_mask;
+		ready_mask = irq_mask1_rd & (IO_MASK(R_IRQ_MASK1_RD, ser0_ready) |
+					     IO_MASK(R_IRQ_MASK1_RD, ser1_ready) |
+					     IO_MASK(R_IRQ_MASK1_RD, ser2_ready) |
+					     IO_MASK(R_IRQ_MASK1_RD, ser3_ready));
+		if (ready_mask) {
+			reentered_ready_mask |= ready_mask;
+			/* Disable those we are about to handle */
+			*R_IRQ_MASK1_CLR = ready_mask;
+			DFLOW(DEBUG_LOG(SERIAL_DEBUG_LINE, "ser_int reentered with TX %X\n", ready_mask));
+		}
+	}
+
+	local_irq_restore(flags);
+	return IRQ_RETVAL(handled);
+} /* ser_interrupt */
+#endif
+
+/*
+ * -------------------------------------------------------------------
+ * Here ends the serial interrupt routines.
+ * -------------------------------------------------------------------
+ */
+
+/*
+ * This routine is used to handle the "bottom half" processing for the
+ * serial driver, known also the "software interrupt" processing.
+ * This processing is done at the kernel interrupt level, after the
+ * rs_interrupt() has returned, BUT WITH INTERRUPTS TURNED ON.  This
+ * is where time-consuming activities which can not be done in the
+ * interrupt driver proper are done; the interrupt driver schedules
+ * them using rs_sched_event(), and they get done here.
+ */
+static void
+do_softint(struct work_struct *work)
+{
+	struct e100_serial	*info;
+	struct tty_struct	*tty;
+
+	info = container_of(work, struct e100_serial, work);
+
+	tty = info->port.tty;
+	if (!tty)
+		return;
+
+	if (test_and_clear_bit(RS_EVENT_WRITE_WAKEUP, &info->event))
+		tty_wakeup(tty);
+}
+
+static int
+startup(struct e100_serial * info)
+{
+	unsigned long flags;
+	unsigned long xmit_page;
+	int i;
+
+	xmit_page = get_zeroed_page(GFP_KERNEL);
+	if (!xmit_page)
+		return -ENOMEM;
+
+	local_irq_save(flags);
+
+	/* if it was already initialized, skip this */
+
+	if (info->flags & ASYNC_INITIALIZED) {
+		local_irq_restore(flags);
+		free_page(xmit_page);
+		return 0;
+	}
+
+	if (info->xmit.buf)
+		free_page(xmit_page);
+	else
+		info->xmit.buf = (unsigned char *) xmit_page;
+
+#ifdef SERIAL_DEBUG_OPEN
+	printk("starting up ttyS%d (xmit_buf 0x%p)...\n", info->line, info->xmit.buf);
+#endif
+
+#ifdef CONFIG_SVINTO_SIM
+	/* Bits and pieces collected from below.  Better to have them
+	   in one ifdef:ed clause than to mix in a lot of ifdefs,
+	   right? */
+	if (info->port.tty)
+		clear_bit(TTY_IO_ERROR, &info->port.tty->flags);
+
+	info->xmit.head = info->xmit.tail = 0;
+	info->first_recv_buffer = info->last_recv_buffer = NULL;
+	info->recv_cnt = info->max_recv_cnt = 0;
+
+	for (i = 0; i < SERIAL_RECV_DESCRIPTORS; i++)
+		info->rec_descr[i].buf = NULL;
+
+	/* No real action in the simulator, but may set info important
+	   to ioctl. */
+	change_speed(info);
+#else
+
+	/*
+	 * Clear the FIFO buffers and disable them
+	 * (they will be reenabled in change_speed())
+	 */
+
+	/*
+	 * Reset the DMA channels and make sure their interrupts are cleared
+	 */
+
+	if (info->dma_in_enabled) {
+		info->uses_dma_in = 1;
+		e100_enable_rxdma_channel(info);
+
+		*info->icmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, reset);
+
+		/* Wait until reset cycle is complete */
+		while (IO_EXTRACT(R_DMA_CH6_CMD, cmd, *info->icmdadr) ==
+		       IO_STATE_VALUE(R_DMA_CH6_CMD, cmd, reset));
+
+		/* Make sure the irqs are cleared */
+		*info->iclrintradr =
+			IO_STATE(R_DMA_CH6_CLR_INTR, clr_descr, do) |
+			IO_STATE(R_DMA_CH6_CLR_INTR, clr_eop, do);
+	} else {
+		e100_disable_rxdma_channel(info);
+	}
+
+	if (info->dma_out_enabled) {
+		info->uses_dma_out = 1;
+		e100_enable_txdma_channel(info);
+		*info->ocmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, reset);
+
+		while (IO_EXTRACT(R_DMA_CH6_CMD, cmd, *info->ocmdadr) ==
+		       IO_STATE_VALUE(R_DMA_CH6_CMD, cmd, reset));
+
+		/* Make sure the irqs are cleared */
+		*info->oclrintradr =
+			IO_STATE(R_DMA_CH6_CLR_INTR, clr_descr, do) |
+			IO_STATE(R_DMA_CH6_CLR_INTR, clr_eop, do);
+	} else {
+		e100_disable_txdma_channel(info);
+	}
+
+	if (info->port.tty)
+		clear_bit(TTY_IO_ERROR, &info->port.tty->flags);
+
+	info->xmit.head = info->xmit.tail = 0;
+	info->first_recv_buffer = info->last_recv_buffer = NULL;
+	info->recv_cnt = info->max_recv_cnt = 0;
+
+	for (i = 0; i < SERIAL_RECV_DESCRIPTORS; i++)
+		info->rec_descr[i].buf = 0;
+
+	/*
+	 * and set the speed and other flags of the serial port
+	 * this will start the rx/tx as well
+	 */
+#ifdef SERIAL_HANDLE_EARLY_ERRORS
+	e100_enable_serial_data_irq(info);
+#endif
+	change_speed(info);
+
+	/* dummy read to reset any serial errors */
+
+	(void)info->ioport[REG_DATA];
+
+	/* enable the interrupts */
+	if (info->uses_dma_out)
+		e100_enable_txdma_irq(info);
+
+	e100_enable_rx_irq(info);
+
+	info->tr_running = 0; /* to be sure we don't lock up the transmitter */
+
+	/* setup the dma input descriptor and start dma */
+
+	start_receive(info);
+
+	/* for safety, make sure the descriptors last result is 0 bytes written */
+
+	info->tr_descr.sw_len = 0;
+	info->tr_descr.hw_len = 0;
+	info->tr_descr.status = 0;
+
+	/* enable RTS/DTR last */
+
+	e100_rts(info, 1);
+	e100_dtr(info, 1);
+
+#endif /* CONFIG_SVINTO_SIM */
+
+	info->flags |= ASYNC_INITIALIZED;
+
+	local_irq_restore(flags);
+	return 0;
+}
+
+/*
+ * This routine will shutdown a serial port; interrupts are disabled, and
+ * DTR is dropped if the hangup on close termio flag is on.
+ */
+static void
+shutdown(struct e100_serial * info)
+{
+	unsigned long flags;
+	struct etrax_dma_descr *descr = info->rec_descr;
+	struct etrax_recv_buffer *buffer;
+	int i;
+
+#ifndef CONFIG_SVINTO_SIM
+	/* shut down the transmitter and receiver */
+	DFLOW(DEBUG_LOG(info->line, "shutdown %i\n", info->line));
+	e100_disable_rx(info);
+	info->ioport[REG_TR_CTRL] = (info->tx_ctrl &= ~0x40);
+
+	/* disable interrupts, reset dma channels */
+	if (info->uses_dma_in) {
+		e100_disable_rxdma_irq(info);
+		*info->icmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, reset);
+		info->uses_dma_in = 0;
+	} else {
+		e100_disable_serial_data_irq(info);
+	}
+
+	if (info->uses_dma_out) {
+		e100_disable_txdma_irq(info);
+		info->tr_running = 0;
+		*info->ocmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, reset);
+		info->uses_dma_out = 0;
+	} else {
+		e100_disable_serial_tx_ready_irq(info);
+		info->tr_running = 0;
+	}
+
+#endif /* CONFIG_SVINTO_SIM */
+
+	if (!(info->flags & ASYNC_INITIALIZED))
+		return;
+
+#ifdef SERIAL_DEBUG_OPEN
+	printk("Shutting down serial port %d (irq %d)....\n", info->line,
+	       info->irq);
+#endif
+
+	local_irq_save(flags);
+
+	if (info->xmit.buf) {
+		free_page((unsigned long)info->xmit.buf);
+		info->xmit.buf = NULL;
+	}
+
+	for (i = 0; i < SERIAL_RECV_DESCRIPTORS; i++)
+		if (descr[i].buf) {
+			buffer = phys_to_virt(descr[i].buf) - sizeof *buffer;
+			kfree(buffer);
+			descr[i].buf = 0;
+		}
+
+	if (!info->port.tty || (info->port.tty->termios->c_cflag & HUPCL)) {
+		/* hang up DTR and RTS if HUPCL is enabled */
+		e100_dtr(info, 0);
+		e100_rts(info, 0); /* could check CRTSCTS before doing this */
+	}
+
+	if (info->port.tty)
+		set_bit(TTY_IO_ERROR, &info->port.tty->flags);
+
+	info->flags &= ~ASYNC_INITIALIZED;
+	local_irq_restore(flags);
+}
+
+
+/* change baud rate and other assorted parameters */
+
+static void
+change_speed(struct e100_serial *info)
+{
+	unsigned int cflag;
+	unsigned long xoff;
+	unsigned long flags;
+	/* first some safety checks */
+
+	if (!info->port.tty || !info->port.tty->termios)
+		return;
+	if (!info->ioport)
+		return;
+
+	cflag = info->port.tty->termios->c_cflag;
+
+	/* possibly, the tx/rx should be disabled first to do this safely */
+
+	/* change baud-rate and write it to the hardware */
+	if ((info->flags & ASYNC_SPD_MASK) == ASYNC_SPD_CUST) {
+		/* Special baudrate */
+		u32 mask = 0xFF << (info->line*8); /* Each port has 8 bits */
+		unsigned long alt_source =
+				IO_STATE(R_ALT_SER_BAUDRATE, ser0_rec, normal) |
+				IO_STATE(R_ALT_SER_BAUDRATE, ser0_tr, normal);
+		/* R_ALT_SER_BAUDRATE selects the source */
+		DBAUD(printk("Custom baudrate: baud_base/divisor %lu/%i\n",
+		       (unsigned long)info->baud_base, info->custom_divisor));
+		if (info->baud_base == SERIAL_PRESCALE_BASE) {
+			/* 0, 2-65535 (0=65536) */
+			u16 divisor = info->custom_divisor;
+			/* R_SERIAL_PRESCALE (upper 16 bits of R_CLOCK_PRESCALE) */
+			/* baudrate is 3.125MHz/custom_divisor */
+			alt_source =
+				IO_STATE(R_ALT_SER_BAUDRATE, ser0_rec, prescale) |
+				IO_STATE(R_ALT_SER_BAUDRATE, ser0_tr, prescale);
+			alt_source = 0x11;
+			DBAUD(printk("Writing SERIAL_PRESCALE: divisor %i\n", divisor));
+			*R_SERIAL_PRESCALE = divisor;
+			info->baud = SERIAL_PRESCALE_BASE/divisor;
+		}
+#ifdef CONFIG_ETRAX_EXTERN_PB6CLK_ENABLED
+		else if ((info->baud_base==CONFIG_ETRAX_EXTERN_PB6CLK_FREQ/8 &&
+			  info->custom_divisor == 1) ||
+			 (info->baud_base==CONFIG_ETRAX_EXTERN_PB6CLK_FREQ &&
+			  info->custom_divisor == 8)) {
+				/* ext_clk selected */
+				alt_source =
+					IO_STATE(R_ALT_SER_BAUDRATE, ser0_rec, extern) |
+					IO_STATE(R_ALT_SER_BAUDRATE, ser0_tr, extern);
+				DBAUD(printk("using external baudrate: %lu\n", CONFIG_ETRAX_EXTERN_PB6CLK_FREQ/8));
+				info->baud = CONFIG_ETRAX_EXTERN_PB6CLK_FREQ/8;
+			}
+#endif
+		else
+		{
+			/* Bad baudbase, we don't support using timer0
+			 * for baudrate.
+			 */
+			printk(KERN_WARNING "Bad baud_base/custom_divisor: %lu/%i\n",
+			       (unsigned long)info->baud_base, info->custom_divisor);
+		}
+		r_alt_ser_baudrate_shadow &= ~mask;
+		r_alt_ser_baudrate_shadow |= (alt_source << (info->line*8));
+		*R_ALT_SER_BAUDRATE = r_alt_ser_baudrate_shadow;
+	} else {
+		/* Normal baudrate */
+		/* Make sure we use normal baudrate */
+		u32 mask = 0xFF << (info->line*8); /* Each port has 8 bits */
+		unsigned long alt_source =
+			IO_STATE(R_ALT_SER_BAUDRATE, ser0_rec, normal) |
+			IO_STATE(R_ALT_SER_BAUDRATE, ser0_tr, normal);
+		r_alt_ser_baudrate_shadow &= ~mask;
+		r_alt_ser_baudrate_shadow |= (alt_source << (info->line*8));
+#ifndef CONFIG_SVINTO_SIM
+		*R_ALT_SER_BAUDRATE = r_alt_ser_baudrate_shadow;
+#endif /* CONFIG_SVINTO_SIM */
+
+		info->baud = cflag_to_baud(cflag);
+#ifndef CONFIG_SVINTO_SIM
+		info->ioport[REG_BAUD] = cflag_to_etrax_baud(cflag);
+#endif /* CONFIG_SVINTO_SIM */
+	}
+
+#ifndef CONFIG_SVINTO_SIM
+	/* start with default settings and then fill in changes */
+	local_irq_save(flags);
+	/* 8 bit, no/even parity */
+	info->rx_ctrl &= ~(IO_MASK(R_SERIAL0_REC_CTRL, rec_bitnr) |
+			   IO_MASK(R_SERIAL0_REC_CTRL, rec_par_en) |
+			   IO_MASK(R_SERIAL0_REC_CTRL, rec_par));
+
+	/* 8 bit, no/even parity, 1 stop bit, no cts */
+	info->tx_ctrl &= ~(IO_MASK(R_SERIAL0_TR_CTRL, tr_bitnr) |
+			   IO_MASK(R_SERIAL0_TR_CTRL, tr_par_en) |
+			   IO_MASK(R_SERIAL0_TR_CTRL, tr_par) |
+			   IO_MASK(R_SERIAL0_TR_CTRL, stop_bits) |
+			   IO_MASK(R_SERIAL0_TR_CTRL, auto_cts));
+
+	if ((cflag & CSIZE) == CS7) {
+		/* set 7 bit mode */
+		info->tx_ctrl |= IO_STATE(R_SERIAL0_TR_CTRL, tr_bitnr, tr_7bit);
+		info->rx_ctrl |= IO_STATE(R_SERIAL0_REC_CTRL, rec_bitnr, rec_7bit);
+	}
+
+	if (cflag & CSTOPB) {
+		/* set 2 stop bit mode */
+		info->tx_ctrl |= IO_STATE(R_SERIAL0_TR_CTRL, stop_bits, two_bits);
+	}
+
+	if (cflag & PARENB) {
+		/* enable parity */
+		info->tx_ctrl |= IO_STATE(R_SERIAL0_TR_CTRL, tr_par_en, enable);
+		info->rx_ctrl |= IO_STATE(R_SERIAL0_REC_CTRL, rec_par_en, enable);
+	}
+
+	if (cflag & CMSPAR) {
+		/* enable stick parity, PARODD mean Mark which matches ETRAX */
+		info->tx_ctrl |= IO_STATE(R_SERIAL0_TR_CTRL, tr_stick_par, stick);
+		info->rx_ctrl |= IO_STATE(R_SERIAL0_REC_CTRL, rec_stick_par, stick);
+	}
+	if (cflag & PARODD) {
+		/* set odd parity (or Mark if CMSPAR) */
+		info->tx_ctrl |= IO_STATE(R_SERIAL0_TR_CTRL, tr_par, odd);
+		info->rx_ctrl |= IO_STATE(R_SERIAL0_REC_CTRL, rec_par, odd);
+	}
+
+	if (cflag & CRTSCTS) {
+		/* enable automatic CTS handling */
+		DFLOW(DEBUG_LOG(info->line, "FLOW auto_cts enabled\n", 0));
+		info->tx_ctrl |= IO_STATE(R_SERIAL0_TR_CTRL, auto_cts, active);
+	}
+
+	/* make sure the tx and rx are enabled */
+
+	info->tx_ctrl |= IO_STATE(R_SERIAL0_TR_CTRL, tr_enable, enable);
+	info->rx_ctrl |= IO_STATE(R_SERIAL0_REC_CTRL, rec_enable, enable);
+
+	/* actually write the control regs to the hardware */
+
+	info->ioport[REG_TR_CTRL] = info->tx_ctrl;
+	info->ioport[REG_REC_CTRL] = info->rx_ctrl;
+	xoff = IO_FIELD(R_SERIAL0_XOFF, xoff_char, STOP_CHAR(info->port.tty));
+	xoff |= IO_STATE(R_SERIAL0_XOFF, tx_stop, enable);
+	if (info->port.tty->termios->c_iflag & IXON ) {
+		DFLOW(DEBUG_LOG(info->line, "FLOW XOFF enabled 0x%02X\n",
+				STOP_CHAR(info->port.tty)));
+		xoff |= IO_STATE(R_SERIAL0_XOFF, auto_xoff, enable);
+	}
+
+	*((unsigned long *)&info->ioport[REG_XOFF]) = xoff;
+	local_irq_restore(flags);
+#endif /* !CONFIG_SVINTO_SIM */
+
+	update_char_time(info);
+
+} /* change_speed */
+
+/* start transmitting chars NOW */
+
+static void
+rs_flush_chars(struct tty_struct *tty)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	unsigned long flags;
+
+	if (info->tr_running ||
+	    info->xmit.head == info->xmit.tail ||
+	    tty->stopped ||
+	    tty->hw_stopped ||
+	    !info->xmit.buf)
+		return;
+
+#ifdef SERIAL_DEBUG_FLOW
+	printk("rs_flush_chars\n");
+#endif
+
+	/* this protection might not exactly be necessary here */
+
+	local_irq_save(flags);
+	start_transmit(info);
+	local_irq_restore(flags);
+}
+
+static int rs_raw_write(struct tty_struct *tty,
+			const unsigned char *buf, int count)
+{
+	int	c, ret = 0;
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	unsigned long flags;
+
+	/* first some sanity checks */
+
+	if (!tty || !info->xmit.buf || !tmp_buf)
+		return 0;
+
+#ifdef SERIAL_DEBUG_DATA
+	if (info->line == SERIAL_DEBUG_LINE)
+		printk("rs_raw_write (%d), status %d\n",
+		       count, info->ioport[REG_STATUS]);
+#endif
+
+#ifdef CONFIG_SVINTO_SIM
+	/* Really simple.  The output is here and now. */
+	SIMCOUT(buf, count);
+	return count;
+#endif
+	local_save_flags(flags);
+	DFLOW(DEBUG_LOG(info->line, "write count %i ", count));
+	DFLOW(DEBUG_LOG(info->line, "ldisc %i\n", tty->ldisc.chars_in_buffer(tty)));
+
+
+	/* The local_irq_disable/restore_flags pairs below are needed
+	 * because the DMA interrupt handler moves the info->xmit values.
+	 * the memcpy needs to be in the critical region unfortunately,
+	 * because we need to read xmit values, memcpy, write xmit values
+	 * in one atomic operation... this could perhaps be avoided by
+	 * more clever design.
+	 */
+	local_irq_disable();
+		while (count) {
+			c = CIRC_SPACE_TO_END(info->xmit.head,
+					      info->xmit.tail,
+					      SERIAL_XMIT_SIZE);
+
+			if (count < c)
+				c = count;
+			if (c <= 0)
+				break;
+
+			memcpy(info->xmit.buf + info->xmit.head, buf, c);
+			info->xmit.head = (info->xmit.head + c) &
+				(SERIAL_XMIT_SIZE-1);
+			buf += c;
+			count -= c;
+			ret += c;
+		}
+	local_irq_restore(flags);
+
+	/* enable transmitter if not running, unless the tty is stopped
+	 * this does not need IRQ protection since if tr_running == 0
+	 * the IRQ's are not running anyway for this port.
+	 */
+	DFLOW(DEBUG_LOG(info->line, "write ret %i\n", ret));
+
+	if (info->xmit.head != info->xmit.tail &&
+	    !tty->stopped &&
+	    !tty->hw_stopped &&
+	    !info->tr_running) {
+		start_transmit(info);
+	}
+
+	return ret;
+} /* raw_raw_write() */
+
+static int
+rs_write(struct tty_struct *tty,
+	 const unsigned char *buf, int count)
+{
+#if defined(CONFIG_ETRAX_RS485)
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+
+	if (info->rs485.flags & SER_RS485_ENABLED)
+	{
+		/* If we are in RS-485 mode, we need to toggle RTS and disable
+		 * the receiver before initiating a DMA transfer
+		 */
+#ifdef CONFIG_ETRAX_FAST_TIMER
+		/* Abort any started timer */
+		fast_timers_rs485[info->line].function = NULL;
+		del_fast_timer(&fast_timers_rs485[info->line]);
+#endif
+		e100_rts(info, (info->rs485.flags & SER_RS485_RTS_ON_SEND));
+#if defined(CONFIG_ETRAX_RS485_DISABLE_RECEIVER)
+		e100_disable_rx(info);
+		e100_enable_rx_irq(info);
+#endif
+		if ((info->rs485.flags & SER_RS485_RTS_BEFORE_SEND) &&
+			(info->rs485.delay_rts_before_send > 0))
+				msleep(info->rs485.delay_rts_before_send);
+	}
+#endif /* CONFIG_ETRAX_RS485 */
+
+	count = rs_raw_write(tty, buf, count);
+
+#if defined(CONFIG_ETRAX_RS485)
+	if (info->rs485.flags & SER_RS485_ENABLED)
+	{
+		unsigned int val;
+		/* If we are in RS-485 mode the following has to be done:
+		 * wait until DMA is ready
+		 * wait on transmit shift register
+		 * toggle RTS
+		 * enable the receiver
+		 */
+
+		/* Sleep until all sent */
+		tty_wait_until_sent(tty, 0);
+#ifdef CONFIG_ETRAX_FAST_TIMER
+		/* Now sleep a little more so that shift register is empty */
+		schedule_usleep(info->char_time_usec * 2);
+#endif
+		/* wait on transmit shift register */
+		do{
+			get_lsr_info(info, &val);
+		}while (!(val & TIOCSER_TEMT));
+
+		e100_rts(info, (info->rs485.flags & SER_RS485_RTS_AFTER_SEND));
+
+#if defined(CONFIG_ETRAX_RS485_DISABLE_RECEIVER)
+		e100_enable_rx(info);
+		e100_enable_rxdma_irq(info);
+#endif
+	}
+#endif /* CONFIG_ETRAX_RS485 */
+
+	return count;
+} /* rs_write */
+
+
+/* how much space is available in the xmit buffer? */
+
+static int
+rs_write_room(struct tty_struct *tty)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+
+	return CIRC_SPACE(info->xmit.head, info->xmit.tail, SERIAL_XMIT_SIZE);
+}
+
+/* How many chars are in the xmit buffer?
+ * This does not include any chars in the transmitter FIFO.
+ * Use wait_until_sent for waiting for FIFO drain.
+ */
+
+static int
+rs_chars_in_buffer(struct tty_struct *tty)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+
+	return CIRC_CNT(info->xmit.head, info->xmit.tail, SERIAL_XMIT_SIZE);
+}
+
+/* discard everything in the xmit buffer */
+
+static void
+rs_flush_buffer(struct tty_struct *tty)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	info->xmit.head = info->xmit.tail = 0;
+	local_irq_restore(flags);
+
+	tty_wakeup(tty);
+}
+
+/*
+ * This function is used to send a high-priority XON/XOFF character to
+ * the device
+ *
+ * Since we use DMA we don't check for info->x_char in transmit_chars_dma(),
+ * but we do it in handle_ser_tx_interrupt().
+ * We disable DMA channel and enable tx ready interrupt and write the
+ * character when possible.
+ */
+static void rs_send_xchar(struct tty_struct *tty, char ch)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	unsigned long flags;
+	local_irq_save(flags);
+	if (info->uses_dma_out) {
+		/* Put the DMA on hold and disable the channel */
+		*info->ocmdadr = IO_STATE(R_DMA_CH6_CMD, cmd, hold);
+		while (IO_EXTRACT(R_DMA_CH6_CMD, cmd, *info->ocmdadr) !=
+		       IO_STATE_VALUE(R_DMA_CH6_CMD, cmd, hold));
+		e100_disable_txdma_channel(info);
+	}
+
+	/* Must make sure transmitter is not stopped before we can transmit */
+	if (tty->stopped)
+		rs_start(tty);
+
+	/* Enable manual transmit interrupt and send from there */
+	DFLOW(DEBUG_LOG(info->line, "rs_send_xchar 0x%02X\n", ch));
+	info->x_char = ch;
+	e100_enable_serial_tx_ready_irq(info);
+	local_irq_restore(flags);
+}
+
+/*
+ * ------------------------------------------------------------
+ * rs_throttle()
+ *
+ * This routine is called by the upper-layer tty layer to signal that
+ * incoming characters should be throttled.
+ * ------------------------------------------------------------
+ */
+static void
+rs_throttle(struct tty_struct * tty)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+#ifdef SERIAL_DEBUG_THROTTLE
+	char	buf[64];
+
+	printk("throttle %s: %lu....\n", tty_name(tty, buf),
+	       (unsigned long)tty->ldisc.chars_in_buffer(tty));
+#endif
+	DFLOW(DEBUG_LOG(info->line,"rs_throttle %lu\n", tty->ldisc.chars_in_buffer(tty)));
+
+	/* Do RTS before XOFF since XOFF might take some time */
+	if (tty->termios->c_cflag & CRTSCTS) {
+		/* Turn off RTS line */
+		e100_rts(info, 0);
+	}
+	if (I_IXOFF(tty))
+		rs_send_xchar(tty, STOP_CHAR(tty));
+
+}
+
+static void
+rs_unthrottle(struct tty_struct * tty)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+#ifdef SERIAL_DEBUG_THROTTLE
+	char	buf[64];
+
+	printk("unthrottle %s: %lu....\n", tty_name(tty, buf),
+	       (unsigned long)tty->ldisc.chars_in_buffer(tty));
+#endif
+	DFLOW(DEBUG_LOG(info->line,"rs_unthrottle ldisc %d\n", tty->ldisc.chars_in_buffer(tty)));
+	DFLOW(DEBUG_LOG(info->line,"rs_unthrottle flip.count: %i\n", tty->flip.count));
+	/* Do RTS before XOFF since XOFF might take some time */
+	if (tty->termios->c_cflag & CRTSCTS) {
+		/* Assert RTS line  */
+		e100_rts(info, 1);
+	}
+
+	if (I_IXOFF(tty)) {
+		if (info->x_char)
+			info->x_char = 0;
+		else
+			rs_send_xchar(tty, START_CHAR(tty));
+	}
+
+}
+
+/*
+ * ------------------------------------------------------------
+ * rs_ioctl() and friends
+ * ------------------------------------------------------------
+ */
+
+static int
+get_serial_info(struct e100_serial * info,
+		struct serial_struct * retinfo)
+{
+	struct serial_struct tmp;
+
+	/* this is all probably wrong, there are a lot of fields
+	 * here that we don't have in e100_serial and maybe we
+	 * should set them to something else than 0.
+	 */
+
+	if (!retinfo)
+		return -EFAULT;
+	memset(&tmp, 0, sizeof(tmp));
+	tmp.type = info->type;
+	tmp.line = info->line;
+	tmp.port = (int)info->ioport;
+	tmp.irq = info->irq;
+	tmp.flags = info->flags;
+	tmp.baud_base = info->baud_base;
+	tmp.close_delay = info->close_delay;
+	tmp.closing_wait = info->closing_wait;
+	tmp.custom_divisor = info->custom_divisor;
+	if (copy_to_user(retinfo, &tmp, sizeof(*retinfo)))
+		return -EFAULT;
+	return 0;
+}
+
+static int
+set_serial_info(struct e100_serial *info,
+		struct serial_struct *new_info)
+{
+	struct serial_struct new_serial;
+	struct e100_serial old_info;
+	int retval = 0;
+
+	if (copy_from_user(&new_serial, new_info, sizeof(new_serial)))
+		return -EFAULT;
+
+	old_info = *info;
+
+	if (!capable(CAP_SYS_ADMIN)) {
+		if ((new_serial.type != info->type) ||
+		    (new_serial.close_delay != info->close_delay) ||
+		    ((new_serial.flags & ~ASYNC_USR_MASK) !=
+		     (info->flags & ~ASYNC_USR_MASK)))
+			return -EPERM;
+		info->flags = ((info->flags & ~ASYNC_USR_MASK) |
+			       (new_serial.flags & ASYNC_USR_MASK));
+		goto check_and_exit;
+	}
+
+	if (info->count > 1)
+		return -EBUSY;
+
+	/*
+	 * OK, past this point, all the error checking has been done.
+	 * At this point, we start making changes.....
+	 */
+
+	info->baud_base = new_serial.baud_base;
+	info->flags = ((info->flags & ~ASYNC_FLAGS) |
+		       (new_serial.flags & ASYNC_FLAGS));
+	info->custom_divisor = new_serial.custom_divisor;
+	info->type = new_serial.type;
+	info->close_delay = new_serial.close_delay;
+	info->closing_wait = new_serial.closing_wait;
+	info->port.tty->low_latency = (info->flags & ASYNC_LOW_LATENCY) ? 1 : 0;
+
+ check_and_exit:
+	if (info->flags & ASYNC_INITIALIZED) {
+		change_speed(info);
+	} else
+		retval = startup(info);
+	return retval;
+}
+
+/*
+ * get_lsr_info - get line status register info
+ *
+ * Purpose: Let user call ioctl() to get info when the UART physically
+ * 	    is emptied.  On bus types like RS485, the transmitter must
+ * 	    release the bus after transmitting. This must be done when
+ * 	    the transmit shift register is empty, not be done when the
+ * 	    transmit holding register is empty.  This functionality
+ * 	    allows an RS485 driver to be written in user space.
+ */
+static int
+get_lsr_info(struct e100_serial * info, unsigned int *value)
+{
+	unsigned int result = TIOCSER_TEMT;
+#ifndef CONFIG_SVINTO_SIM
+	unsigned long curr_time = jiffies;
+	unsigned long curr_time_usec = GET_JIFFIES_USEC();
+	unsigned long elapsed_usec =
+		(curr_time - info->last_tx_active) * 1000000/HZ +
+		curr_time_usec - info->last_tx_active_usec;
+
+	if (info->xmit.head != info->xmit.tail ||
+	    elapsed_usec < 2*info->char_time_usec) {
+		result = 0;
+	}
+#endif
+
+	if (copy_to_user(value, &result, sizeof(int)))
+		return -EFAULT;
+	return 0;
+}
+
+#ifdef SERIAL_DEBUG_IO
+struct state_str
+{
+	int state;
+	const char *str;
+};
+
+const struct state_str control_state_str[] = {
+	{TIOCM_DTR, "DTR" },
+	{TIOCM_RTS, "RTS"},
+	{TIOCM_ST, "ST?" },
+	{TIOCM_SR, "SR?" },
+	{TIOCM_CTS, "CTS" },
+	{TIOCM_CD, "CD" },
+	{TIOCM_RI, "RI" },
+	{TIOCM_DSR, "DSR" },
+	{0, NULL }
+};
+
+char *get_control_state_str(int MLines, char *s)
+{
+	int i = 0;
+
+	s[0]='\0';
+	while (control_state_str[i].str != NULL) {
+		if (MLines & control_state_str[i].state) {
+			if (s[0] != '\0') {
+				strcat(s, ", ");
+			}
+			strcat(s, control_state_str[i].str);
+		}
+		i++;
+	}
+	return s;
+}
+#endif
+
+static int
+rs_break(struct tty_struct *tty, int break_state)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	unsigned long flags;
+
+	if (!info->ioport)
+		return -EIO;
+
+	local_irq_save(flags);
+	if (break_state == -1) {
+		/* Go to manual mode and set the txd pin to 0 */
+		/* Clear bit 7 (txd) and 6 (tr_enable) */
+		info->tx_ctrl &= 0x3F;
+	} else {
+		/* Set bit 7 (txd) and 6 (tr_enable) */
+		info->tx_ctrl |= (0x80 | 0x40);
+	}
+	info->ioport[REG_TR_CTRL] = info->tx_ctrl;
+	local_irq_restore(flags);
+	return 0;
+}
+
+static int
+rs_tiocmset(struct tty_struct *tty, unsigned int set, unsigned int clear)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	if (clear & TIOCM_RTS)
+		e100_rts(info, 0);
+	if (clear & TIOCM_DTR)
+		e100_dtr(info, 0);
+	/* Handle FEMALE behaviour */
+	if (clear & TIOCM_RI)
+		e100_ri_out(info, 0);
+	if (clear & TIOCM_CD)
+		e100_cd_out(info, 0);
+
+	if (set & TIOCM_RTS)
+		e100_rts(info, 1);
+	if (set & TIOCM_DTR)
+		e100_dtr(info, 1);
+	/* Handle FEMALE behaviour */
+	if (set & TIOCM_RI)
+		e100_ri_out(info, 1);
+	if (set & TIOCM_CD)
+		e100_cd_out(info, 1);
+
+	local_irq_restore(flags);
+	return 0;
+}
+
+static int
+rs_tiocmget(struct tty_struct *tty)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	unsigned int result;
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	result =
+		(!E100_RTS_GET(info) ? TIOCM_RTS : 0)
+		| (!E100_DTR_GET(info) ? TIOCM_DTR : 0)
+		| (!E100_RI_GET(info) ? TIOCM_RNG : 0)
+		| (!E100_DSR_GET(info) ? TIOCM_DSR : 0)
+		| (!E100_CD_GET(info) ? TIOCM_CAR : 0)
+		| (!E100_CTS_GET(info) ? TIOCM_CTS : 0);
+
+	local_irq_restore(flags);
+
+#ifdef SERIAL_DEBUG_IO
+	printk(KERN_DEBUG "ser%i: modem state: %i 0x%08X\n",
+		info->line, result, result);
+	{
+		char s[100];
+
+		get_control_state_str(result, s);
+		printk(KERN_DEBUG "state: %s\n", s);
+	}
+#endif
+	return result;
+
+}
+
+
+static int
+rs_ioctl(struct tty_struct *tty,
+	 unsigned int cmd, unsigned long arg)
+{
+	struct e100_serial * info = (struct e100_serial *)tty->driver_data;
+
+	if ((cmd != TIOCGSERIAL) && (cmd != TIOCSSERIAL) &&
+	    (cmd != TIOCSERCONFIG) && (cmd != TIOCSERGWILD)  &&
+	    (cmd != TIOCSERSWILD) && (cmd != TIOCSERGSTRUCT)) {
+		if (tty->flags & (1 << TTY_IO_ERROR))
+			return -EIO;
+	}
+
+	switch (cmd) {
+	case TIOCGSERIAL:
+		return get_serial_info(info,
+				       (struct serial_struct *) arg);
+	case TIOCSSERIAL:
+		return set_serial_info(info,
+				       (struct serial_struct *) arg);
+	case TIOCSERGETLSR: /* Get line status register */
+		return get_lsr_info(info, (unsigned int *) arg);
+
+	case TIOCSERGSTRUCT:
+		if (copy_to_user((struct e100_serial *) arg,
+				 info, sizeof(struct e100_serial)))
+			return -EFAULT;
+		return 0;
+
+#if defined(CONFIG_ETRAX_RS485)
+	case TIOCSERSETRS485:
+	{
+		/* In this ioctl we still use the old structure
+		 * rs485_control for backward compatibility
+		 * (if we use serial_rs485, then old user-level code
+		 * wouldn't work anymore...).
+		 * The use of this ioctl is deprecated: use TIOCSRS485
+		 * instead.*/
+		struct rs485_control rs485ctrl;
+		struct serial_rs485 rs485data;
+		printk(KERN_DEBUG "The use of this ioctl is deprecated. Use TIOCSRS485 instead\n");
+		if (copy_from_user(&rs485ctrl, (struct rs485_control *)arg,
+				sizeof(rs485ctrl)))
+			return -EFAULT;
+
+		rs485data.delay_rts_before_send = rs485ctrl.delay_rts_before_send;
+		rs485data.flags = 0;
+		if (rs485data.delay_rts_before_send != 0)
+			rs485data.flags |= SER_RS485_RTS_BEFORE_SEND;
+		else
+			rs485data.flags &= ~(SER_RS485_RTS_BEFORE_SEND);
+
+		if (rs485ctrl.enabled)
+			rs485data.flags |= SER_RS485_ENABLED;
+		else
+			rs485data.flags &= ~(SER_RS485_ENABLED);
+
+		if (rs485ctrl.rts_on_send)
+			rs485data.flags |= SER_RS485_RTS_ON_SEND;
+		else
+			rs485data.flags &= ~(SER_RS485_RTS_ON_SEND);
+
+		if (rs485ctrl.rts_after_sent)
+			rs485data.flags |= SER_RS485_RTS_AFTER_SEND;
+		else
+			rs485data.flags &= ~(SER_RS485_RTS_AFTER_SEND);
+
+		return e100_enable_rs485(tty, &rs485data);
+	}
+
+	case TIOCSRS485:
+	{
+		/* This is the new version of TIOCSRS485, with new
+		 * data structure serial_rs485 */
+		struct serial_rs485 rs485data;
+		if (copy_from_user(&rs485data, (struct rs485_control *)arg,
+				sizeof(rs485data)))
+			return -EFAULT;
+
+		return e100_enable_rs485(tty, &rs485data);
+	}
+
+	case TIOCGRS485:
+	{
+		struct serial_rs485 *rs485data =
+			&(((struct e100_serial *)tty->driver_data)->rs485);
+		/* This is the ioctl to get RS485 data from user-space */
+		if (copy_to_user((struct serial_rs485 *) arg,
+					rs485data,
+					sizeof(struct serial_rs485)))
+			return -EFAULT;
+		break;
+	}
+
+	case TIOCSERWRRS485:
+	{
+		struct rs485_write rs485wr;
+		if (copy_from_user(&rs485wr, (struct rs485_write *)arg,
+				sizeof(rs485wr)))
+			return -EFAULT;
+
+		return e100_write_rs485(tty, rs485wr.outc, rs485wr.outc_size);
+	}
+#endif
+
+	default:
+		return -ENOIOCTLCMD;
+	}
+	return 0;
+}
+
+static void
+rs_set_termios(struct tty_struct *tty, struct ktermios *old_termios)
+{
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+
+	change_speed(info);
+
+	/* Handle turning off CRTSCTS */
+	if ((old_termios->c_cflag & CRTSCTS) &&
+	    !(tty->termios->c_cflag & CRTSCTS)) {
+		tty->hw_stopped = 0;
+		rs_start(tty);
+	}
+
+}
+
+/*
+ * ------------------------------------------------------------
+ * rs_close()
+ *
+ * This routine is called when the serial port gets closed.  First, we
+ * wait for the last remaining data to be sent.  Then, we unlink its
+ * S structure from the interrupt chain if necessary, and we free
+ * that IRQ if nothing is left in the chain.
+ * ------------------------------------------------------------
+ */
+static void
+rs_close(struct tty_struct *tty, struct file * filp)
+{
+	struct e100_serial * info = (struct e100_serial *)tty->driver_data;
+	unsigned long flags;
+
+	if (!info)
+		return;
+
+	/* interrupts are disabled for this entire function */
+
+	local_irq_save(flags);
+
+	if (tty_hung_up_p(filp)) {
+		local_irq_restore(flags);
+		return;
+	}
+
+#ifdef SERIAL_DEBUG_OPEN
+	printk("[%d] rs_close ttyS%d, count = %d\n", current->pid,
+	       info->line, info->count);
+#endif
+	if ((tty->count == 1) && (info->count != 1)) {
+		/*
+		 * Uh, oh.  tty->count is 1, which means that the tty
+		 * structure will be freed.  Info->count should always
+		 * be one in these conditions.  If it's greater than
+		 * one, we've got real problems, since it means the
+		 * serial port won't be shutdown.
+		 */
+		printk(KERN_CRIT
+		       "rs_close: bad serial port count; tty->count is 1, "
+		       "info->count is %d\n", info->count);
+		info->count = 1;
+	}
+	if (--info->count < 0) {
+		printk(KERN_CRIT "rs_close: bad serial port count for ttyS%d: %d\n",
+		       info->line, info->count);
+		info->count = 0;
+	}
+	if (info->count) {
+		local_irq_restore(flags);
+		return;
+	}
+	info->flags |= ASYNC_CLOSING;
+	/*
+	 * Save the termios structure, since this port may have
+	 * separate termios for callout and dialin.
+	 */
+	if (info->flags & ASYNC_NORMAL_ACTIVE)
+		info->normal_termios = *tty->termios;
+	/*
+	 * Now we wait for the transmit buffer to clear; and we notify
+	 * the line discipline to only process XON/XOFF characters.
+	 */
+	tty->closing = 1;
+	if (info->closing_wait != ASYNC_CLOSING_WAIT_NONE)
+		tty_wait_until_sent(tty, info->closing_wait);
+	/*
+	 * At this point we stop accepting input.  To do this, we
+	 * disable the serial receiver and the DMA receive interrupt.
+	 */
+#ifdef SERIAL_HANDLE_EARLY_ERRORS
+	e100_disable_serial_data_irq(info);
+#endif
+
+#ifndef CONFIG_SVINTO_SIM
+	e100_disable_rx(info);
+	e100_disable_rx_irq(info);
+
+	if (info->flags & ASYNC_INITIALIZED) {
+		/*
+		 * Before we drop DTR, make sure the UART transmitter
+		 * has completely drained; this is especially
+		 * important as we have a transmit FIFO!
+		 */
+		rs_wait_until_sent(tty, HZ);
+	}
+#endif
+
+	shutdown(info);
+	rs_flush_buffer(tty);
+	tty_ldisc_flush(tty);
+	tty->closing = 0;
+	info->event = 0;
+	info->port.tty = NULL;
+	if (info->blocked_open) {
+		if (info->close_delay)
+			schedule_timeout_interruptible(info->close_delay);
+		wake_up_interruptible(&info->open_wait);
+	}
+	info->flags &= ~(ASYNC_NORMAL_ACTIVE|ASYNC_CLOSING);
+	wake_up_interruptible(&info->close_wait);
+	local_irq_restore(flags);
+
+	/* port closed */
+
+#if defined(CONFIG_ETRAX_RS485)
+	if (info->rs485.flags & SER_RS485_ENABLED) {
+		info->rs485.flags &= ~(SER_RS485_ENABLED);
+#if defined(CONFIG_ETRAX_RS485_ON_PA)
+		*R_PORT_PA_DATA = port_pa_data_shadow &= ~(1 << rs485_pa_bit);
+#endif
+#if defined(CONFIG_ETRAX_RS485_ON_PORT_G)
+		REG_SHADOW_SET(R_PORT_G_DATA, port_g_data_shadow,
+			       rs485_port_g_bit, 0);
+#endif
+#if defined(CONFIG_ETRAX_RS485_LTC1387)
+		REG_SHADOW_SET(R_PORT_G_DATA, port_g_data_shadow,
+			       CONFIG_ETRAX_RS485_LTC1387_DXEN_PORT_G_BIT, 0);
+		REG_SHADOW_SET(R_PORT_G_DATA, port_g_data_shadow,
+			       CONFIG_ETRAX_RS485_LTC1387_RXEN_PORT_G_BIT, 0);
+#endif
+	}
+#endif
+
+	/*
+	 * Release any allocated DMA irq's.
+	 */
+	if (info->dma_in_enabled) {
+		free_irq(info->dma_in_irq_nbr, info);
+		cris_free_dma(info->dma_in_nbr, info->dma_in_irq_description);
+		info->uses_dma_in = 0;
+#ifdef SERIAL_DEBUG_OPEN
+		printk(KERN_DEBUG "DMA irq '%s' freed\n",
+			info->dma_in_irq_description);
+#endif
+	}
+	if (info->dma_out_enabled) {
+		free_irq(info->dma_out_irq_nbr, info);
+		cris_free_dma(info->dma_out_nbr, info->dma_out_irq_description);
+		info->uses_dma_out = 0;
+#ifdef SERIAL_DEBUG_OPEN
+		printk(KERN_DEBUG "DMA irq '%s' freed\n",
+			info->dma_out_irq_description);
+#endif
+	}
+}
+
+/*
+ * rs_wait_until_sent() --- wait until the transmitter is empty
+ */
+static void rs_wait_until_sent(struct tty_struct *tty, int timeout)
+{
+	unsigned long orig_jiffies;
+	struct e100_serial *info = (struct e100_serial *)tty->driver_data;
+	unsigned long curr_time = jiffies;
+	unsigned long curr_time_usec = GET_JIFFIES_USEC();
+	long elapsed_usec =
+		(curr_time - info->last_tx_active) * (1000000/HZ) +
+		curr_time_usec - info->last_tx_active_usec;
+
+	/*
+	 * Check R_DMA_CHx_STATUS bit 0-6=number of available bytes in FIFO
+	 * R_DMA_CHx_HWSW bit 31-16=nbr of bytes left in DMA buffer (0=64k)
+	 */
+	orig_jiffies = jiffies;
+	while (info->xmit.head != info->xmit.tail || /* More in send queue */
+	       (*info->ostatusadr & 0x007f) ||  /* more in FIFO */
+	       (elapsed_usec < 2*info->char_time_usec)) {
+		schedule_timeout_interruptible(1);
+		if (signal_pending(current))
+			break;
+		if (timeout && time_after(jiffies, orig_jiffies + timeout))
+			break;
+		curr_time = jiffies;
+		curr_time_usec = GET_JIFFIES_USEC();
+		elapsed_usec =
+			(curr_time - info->last_tx_active) * (1000000/HZ) +
+			curr_time_usec - info->last_tx_active_usec;
+	}
+	set_current_state(TASK_RUNNING);
+}
+
+/*
+ * rs_hangup() --- called by tty_hangup() when a hangup is signaled.
+ */
+void
+rs_hangup(struct tty_struct *tty)
+{
+	struct e100_serial * info = (struct e100_serial *)tty->driver_data;
+
+	rs_flush_buffer(tty);
+	shutdown(info);
+	info->event = 0;
+	info->count = 0;
+	info->flags &= ~ASYNC_NORMAL_ACTIVE;
+	info->port.tty = NULL;
+	wake_up_interruptible(&info->open_wait);
+}
+
+/*
+ * ------------------------------------------------------------
+ * rs_open() and friends
+ * ------------------------------------------------------------
+ */
+static int
+block_til_ready(struct tty_struct *tty, struct file * filp,
+		struct e100_serial *info)
+{
+	DECLARE_WAITQUEUE(wait, current);
+	unsigned long	flags;
+	int		retval;
+	int		do_clocal = 0, extra_count = 0;
+
+	/*
+	 * If the device is in the middle of being closed, then block
+	 * until it's done, and then try again.
+	 */
+	if (tty_hung_up_p(filp) ||
+	    (info->flags & ASYNC_CLOSING)) {
+		wait_event_interruptible_tty(info->close_wait,
+			!(info->flags & ASYNC_CLOSING));
+#ifdef SERIAL_DO_RESTART
+		if (info->flags & ASYNC_HUP_NOTIFY)
+			return -EAGAIN;
+		else
+			return -ERESTARTSYS;
+#else
+		return -EAGAIN;
+#endif
+	}
+
+	/*
+	 * If non-blocking mode is set, or the port is not enabled,
+	 * then make the check up front and then exit.
+	 */
+	if ((filp->f_flags & O_NONBLOCK) ||
+	    (tty->flags & (1 << TTY_IO_ERROR))) {
+		info->flags |= ASYNC_NORMAL_ACTIVE;
+		return 0;
+	}
+
+	if (tty->termios->c_cflag & CLOCAL) {
+			do_clocal = 1;
+	}
+
+	/*
+	 * Block waiting for the carrier detect and the line to become
+	 * free (i.e., not in use by the callout).  While we are in
+	 * this loop, info->count is dropped by one, so that
+	 * rs_close() knows when to free things.  We restore it upon
+	 * exit, either normal or abnormal.
+	 */
+	retval = 0;
+	add_wait_queue(&info->open_wait, &wait);
+#ifdef SERIAL_DEBUG_OPEN
+	printk("block_til_ready before block: ttyS%d, count = %d\n",
+	       info->line, info->count);
+#endif
+	local_irq_save(flags);
+	if (!tty_hung_up_p(filp)) {
+		extra_count++;
+		info->count--;
+	}
+	local_irq_restore(flags);
+	info->blocked_open++;
+	while (1) {
+		local_irq_save(flags);
+		/* assert RTS and DTR */
+		e100_rts(info, 1);
+		e100_dtr(info, 1);
+		local_irq_restore(flags);
+		set_current_state(TASK_INTERRUPTIBLE);
+		if (tty_hung_up_p(filp) ||
+		    !(info->flags & ASYNC_INITIALIZED)) {
+#ifdef SERIAL_DO_RESTART
+			if (info->flags & ASYNC_HUP_NOTIFY)
+				retval = -EAGAIN;
+			else
+				retval = -ERESTARTSYS;
+#else
+			retval = -EAGAIN;
+#endif
+			break;
+		}
+		if (!(info->flags & ASYNC_CLOSING) && do_clocal)
+			/* && (do_clocal || DCD_IS_ASSERTED) */
+			break;
+		if (signal_pending(current)) {
+			retval = -ERESTARTSYS;
+			break;
+		}
+#ifdef SERIAL_DEBUG_OPEN
+		printk("block_til_ready blocking: ttyS%d, count = %d\n",
+		       info->line, info->count);
+#endif
+		tty_unlock();
+		schedule();
+		tty_lock();
+	}
+	set_current_state(TASK_RUNNING);
+	remove_wait_queue(&info->open_wait, &wait);
+	if (extra_count)
+		info->count++;
+	info->blocked_open--;
+#ifdef SERIAL_DEBUG_OPEN
+	printk("block_til_ready after blocking: ttyS%d, count = %d\n",
+	       info->line, info->count);
+#endif
+	if (retval)
+		return retval;
+	info->flags |= ASYNC_NORMAL_ACTIVE;
+	return 0;
+}
+
+static void
+deinit_port(struct e100_serial *info)
+{
+	if (info->dma_out_enabled) {
+		cris_free_dma(info->dma_out_nbr, info->dma_out_irq_description);
+		free_irq(info->dma_out_irq_nbr, info);
+	}
+	if (info->dma_in_enabled) {
+		cris_free_dma(info->dma_in_nbr, info->dma_in_irq_description);
+		free_irq(info->dma_in_irq_nbr, info);
+	}
+}
+
+/*
+ * This routine is called whenever a serial port is opened.
+ * It performs the serial-specific initialization for the tty structure.
+ */
+static int
+rs_open(struct tty_struct *tty, struct file * filp)
+{
+	struct e100_serial	*info;
+	int 			retval, line;
+	unsigned long           page;
+	int                     allocated_resources = 0;
+
+	/* find which port we want to open */
+	line = tty->index;
+
+	if (line < 0 || line >= NR_PORTS)
+		return -ENODEV;
+
+	/* find the corresponding e100_serial struct in the table */
+	info = rs_table + line;
+
+	/* don't allow the opening of ports that are not enabled in the HW config */
+	if (!info->enabled)
+		return -ENODEV;
+
+#ifdef SERIAL_DEBUG_OPEN
+        printk("[%d] rs_open %s, count = %d\n", current->pid, tty->name,
+ 	       info->count);
+#endif
+
+	info->count++;
+	tty->driver_data = info;
+	info->port.tty = tty;
+
+	info->port.tty->low_latency = (info->flags & ASYNC_LOW_LATENCY) ? 1 : 0;
+
+	if (!tmp_buf) {
+		page = get_zeroed_page(GFP_KERNEL);
+		if (!page) {
+			return -ENOMEM;
+		}
+		if (tmp_buf)
+			free_page(page);
+		else
+			tmp_buf = (unsigned char *) page;
+	}
+
+	/*
+	 * If the port is in the middle of closing, bail out now
+	 */
+	if (tty_hung_up_p(filp) ||
+	    (info->flags & ASYNC_CLOSING)) {
+		wait_event_interruptible_tty(info->close_wait,
+			!(info->flags & ASYNC_CLOSING));
+#ifdef SERIAL_DO_RESTART
+		return ((info->flags & ASYNC_HUP_NOTIFY) ?
+			-EAGAIN : -ERESTARTSYS);
+#else
+		return -EAGAIN;
+#endif
+	}
+
+	/*
+	 * If DMA is enabled try to allocate the irq's.
+	 */
+	if (info->count == 1) {
+		allocated_resources = 1;
+		if (info->dma_in_enabled) {
+			if (request_irq(info->dma_in_irq_nbr,
+					rec_interrupt,
+					info->dma_in_irq_flags,
+					info->dma_in_irq_description,
+					info)) {
+				printk(KERN_WARNING "DMA irq '%s' busy; "
+					"falling back to non-DMA mode\n",
+					info->dma_in_irq_description);
+				/* Make sure we never try to use DMA in */
+				/* for the port again. */
+				info->dma_in_enabled = 0;
+			} else if (cris_request_dma(info->dma_in_nbr,
+					info->dma_in_irq_description,
+					DMA_VERBOSE_ON_ERROR,
+					info->dma_owner)) {
+				free_irq(info->dma_in_irq_nbr, info);
+				printk(KERN_WARNING "DMA '%s' busy; "
+					"falling back to non-DMA mode\n",
+					info->dma_in_irq_description);
+				/* Make sure we never try to use DMA in */
+				/* for the port again. */
+				info->dma_in_enabled = 0;
+			}
+#ifdef SERIAL_DEBUG_OPEN
+			else
+				printk(KERN_DEBUG "DMA irq '%s' allocated\n",
+					info->dma_in_irq_description);
+#endif
+		}
+		if (info->dma_out_enabled) {
+			if (request_irq(info->dma_out_irq_nbr,
+					       tr_interrupt,
+					       info->dma_out_irq_flags,
+					       info->dma_out_irq_description,
+					       info)) {
+				printk(KERN_WARNING "DMA irq '%s' busy; "
+					"falling back to non-DMA mode\n",
+					info->dma_out_irq_description);
+				/* Make sure we never try to use DMA out */
+				/* for the port again. */
+				info->dma_out_enabled = 0;
+			} else if (cris_request_dma(info->dma_out_nbr,
+					     info->dma_out_irq_description,
+					     DMA_VERBOSE_ON_ERROR,
+					     info->dma_owner)) {
+				free_irq(info->dma_out_irq_nbr, info);
+				printk(KERN_WARNING "DMA '%s' busy; "
+					"falling back to non-DMA mode\n",
+					info->dma_out_irq_description);
+				/* Make sure we never try to use DMA out */
+				/* for the port again. */
+				info->dma_out_enabled = 0;
+			}
+#ifdef SERIAL_DEBUG_OPEN
+			else
+				printk(KERN_DEBUG "DMA irq '%s' allocated\n",
+					info->dma_out_irq_description);
+#endif
+		}
+	}
+
+	/*
+	 * Start up the serial port
+	 */
+
+	retval = startup(info);
+	if (retval) {
+		if (allocated_resources)
+			deinit_port(info);
+
+		/* FIXME Decrease count info->count here too? */
+		return retval;
+	}
+
+
+	retval = block_til_ready(tty, filp, info);
+	if (retval) {
+#ifdef SERIAL_DEBUG_OPEN
+		printk("rs_open returning after block_til_ready with %d\n",
+		       retval);
+#endif
+		if (allocated_resources)
+			deinit_port(info);
+
+		return retval;
+	}
+
+	if ((info->count == 1) && (info->flags & ASYNC_SPLIT_TERMIOS)) {
+		*tty->termios = info->normal_termios;
+		change_speed(info);
+	}
+
+#ifdef SERIAL_DEBUG_OPEN
+	printk("rs_open ttyS%d successful...\n", info->line);
+#endif
+	DLOG_INT_TRIG( log_int_pos = 0);
+
+	DFLIP(	if (info->line == SERIAL_DEBUG_LINE) {
+			info->icount.rx = 0;
+		} );
+
+	return 0;
+}
+
+#ifdef CONFIG_PROC_FS
+/*
+ * /proc fs routines....
+ */
+
+static void seq_line_info(struct seq_file *m, struct e100_serial *info)
+{
+	unsigned long tmp;
+
+	seq_printf(m, "%d: uart:E100 port:%lX irq:%d",
+		   info->line, (unsigned long)info->ioport, info->irq);
+
+	if (!info->ioport || (info->type == PORT_UNKNOWN)) {
+		seq_printf(m, "\n");
+		return;
+	}
+
+	seq_printf(m, " baud:%d", info->baud);
+	seq_printf(m, " tx:%lu rx:%lu",
+		       (unsigned long)info->icount.tx,
+		       (unsigned long)info->icount.rx);
+	tmp = CIRC_CNT(info->xmit.head, info->xmit.tail, SERIAL_XMIT_SIZE);
+	if (tmp)
+		seq_printf(m, " tx_pend:%lu/%lu",
+			   (unsigned long)tmp,
+			   (unsigned long)SERIAL_XMIT_SIZE);
+
+	seq_printf(m, " rx_pend:%lu/%lu",
+		   (unsigned long)info->recv_cnt,
+		   (unsigned long)info->max_recv_cnt);
+
+#if 1
+	if (info->port.tty) {
+		if (info->port.tty->stopped)
+			seq_printf(m, " stopped:%i",
+				   (int)info->port.tty->stopped);
+		if (info->port.tty->hw_stopped)
+			seq_printf(m, " hw_stopped:%i",
+				   (int)info->port.tty->hw_stopped);
+	}
+
+	{
+		unsigned char rstat = info->ioport[REG_STATUS];
+		if (rstat & IO_MASK(R_SERIAL0_STATUS, xoff_detect))
+			seq_printf(m, " xoff_detect:1");
+	}
+
+#endif
+
+	if (info->icount.frame)
+		seq_printf(m, " fe:%lu", (unsigned long)info->icount.frame);
+
+	if (info->icount.parity)
+		seq_printf(m, " pe:%lu", (unsigned long)info->icount.parity);
+
+	if (info->icount.brk)
+		seq_printf(m, " brk:%lu", (unsigned long)info->icount.brk);
+
+	if (info->icount.overrun)
+		seq_printf(m, " oe:%lu", (unsigned long)info->icount.overrun);
+
+	/*
+	 * Last thing is the RS-232 status lines
+	 */
+	if (!E100_RTS_GET(info))
+		seq_puts(m, "|RTS");
+	if (!E100_CTS_GET(info))
+		seq_puts(m, "|CTS");
+	if (!E100_DTR_GET(info))
+		seq_puts(m, "|DTR");
+	if (!E100_DSR_GET(info))
+		seq_puts(m, "|DSR");
+	if (!E100_CD_GET(info))
+		seq_puts(m, "|CD");
+	if (!E100_RI_GET(info))
+		seq_puts(m, "|RI");
+	seq_puts(m, "\n");
+}
+
+
+static int crisv10_proc_show(struct seq_file *m, void *v)
+{
+	int i;
+
+	seq_printf(m, "serinfo:1.0 driver:%s\n", serial_version);
+
+	for (i = 0; i < NR_PORTS; i++) {
+		if (!rs_table[i].enabled)
+			continue;
+		seq_line_info(m, &rs_table[i]);
+	}
+#ifdef DEBUG_LOG_INCLUDED
+	for (i = 0; i < debug_log_pos; i++) {
+		seq_printf(m, "%-4i %lu.%lu ",
+			 i, debug_log[i].time,
+			 timer_data_to_ns(debug_log[i].timer_data));
+		seq_printf(m, debug_log[i].string, debug_log[i].value);
+	}
+	seq_printf(m, "debug_log %i/%i\n", i, DEBUG_LOG_SIZE);
+	debug_log_pos = 0;
+#endif
+	return 0;
+}
+
+static int crisv10_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, crisv10_proc_show, NULL);
+}
+
+static const struct file_operations crisv10_proc_fops = {
+	.owner		= THIS_MODULE,
+	.open		= crisv10_proc_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+#endif
+
+
+/* Finally, routines used to initialize the serial driver. */
+
+static void show_serial_version(void)
+{
+	printk(KERN_INFO
+	       "ETRAX 100LX serial-driver %s, "
+	       "(c) 2000-2004 Axis Communications AB\r\n",
+	       &serial_version[11]); /* "$Revision: x.yy" */
+}
+
+/* rs_init inits the driver at boot (using the module_init chain) */
+
+static const struct tty_operations rs_ops = {
+	.open = rs_open,
+	.close = rs_close,
+	.write = rs_write,
+	.flush_chars = rs_flush_chars,
+	.write_room = rs_write_room,
+	.chars_in_buffer = rs_chars_in_buffer,
+	.flush_buffer = rs_flush_buffer,
+	.ioctl = rs_ioctl,
+	.throttle = rs_throttle,
+        .unthrottle = rs_unthrottle,
+	.set_termios = rs_set_termios,
+	.stop = rs_stop,
+	.start = rs_start,
+	.hangup = rs_hangup,
+	.break_ctl = rs_break,
+	.send_xchar = rs_send_xchar,
+	.wait_until_sent = rs_wait_until_sent,
+	.tiocmget = rs_tiocmget,
+	.tiocmset = rs_tiocmset,
+#ifdef CONFIG_PROC_FS
+	.proc_fops = &crisv10_proc_fops,
+#endif
+};
+
+static int __init rs_init(void)
+{
+	int i;
+	struct e100_serial *info;
+	struct tty_driver *driver = alloc_tty_driver(NR_PORTS);
+
+	if (!driver)
+		return -ENOMEM;
+
+	show_serial_version();
+
+	/* Setup the timed flush handler system */
+
+#if !defined(CONFIG_ETRAX_SERIAL_FAST_TIMER)
+	setup_timer(&flush_timer, timed_flush_handler, 0);
+	mod_timer(&flush_timer, jiffies + 5);
+#endif
+
+#if defined(CONFIG_ETRAX_RS485)
+#if defined(CONFIG_ETRAX_RS485_ON_PA)
+	if (cris_io_interface_allocate_pins(if_ser0, 'a', rs485_pa_bit,
+			rs485_pa_bit)) {
+		printk(KERN_CRIT "ETRAX100LX serial: Could not allocate "
+			"RS485 pin\n");
+		put_tty_driver(driver);
+		return -EBUSY;
+	}
+#endif
+#if defined(CONFIG_ETRAX_RS485_ON_PORT_G)
+	if (cris_io_interface_allocate_pins(if_ser0, 'g', rs485_pa_bit,
+			rs485_port_g_bit)) {
+		printk(KERN_CRIT "ETRAX100LX serial: Could not allocate "
+			"RS485 pin\n");
+		put_tty_driver(driver);
+		return -EBUSY;
+	}
+#endif
+#endif
+
+	/* Initialize the tty_driver structure */
+
+	driver->driver_name = "serial";
+	driver->name = "ttyS";
+	driver->major = TTY_MAJOR;
+	driver->minor_start = 64;
+	driver->type = TTY_DRIVER_TYPE_SERIAL;
+	driver->subtype = SERIAL_TYPE_NORMAL;
+	driver->init_termios = tty_std_termios;
+	driver->init_termios.c_cflag =
+		B115200 | CS8 | CREAD | HUPCL | CLOCAL; /* is normally B9600 default... */
+	driver->init_termios.c_ispeed = 115200;
+	driver->init_termios.c_ospeed = 115200;
+	driver->flags = TTY_DRIVER_REAL_RAW | TTY_DRIVER_DYNAMIC_DEV;
+
+	tty_set_operations(driver, &rs_ops);
+        serial_driver = driver;
+	if (tty_register_driver(driver))
+		panic("Couldn't register serial driver\n");
+	/* do some initializing for the separate ports */
+
+	for (i = 0, info = rs_table; i < NR_PORTS; i++,info++) {
+		if (info->enabled) {
+			if (cris_request_io_interface(info->io_if,
+					info->io_if_description)) {
+				printk(KERN_CRIT "ETRAX100LX async serial: "
+					"Could not allocate IO pins for "
+					"%s, port %d\n",
+					info->io_if_description, i);
+				info->enabled = 0;
+			}
+		}
+		info->uses_dma_in = 0;
+		info->uses_dma_out = 0;
+		info->line = i;
+		info->port.tty = NULL;
+		info->type = PORT_ETRAX;
+		info->tr_running = 0;
+		info->forced_eop = 0;
+		info->baud_base = DEF_BAUD_BASE;
+		info->custom_divisor = 0;
+		info->flags = 0;
+		info->close_delay = 5*HZ/10;
+		info->closing_wait = 30*HZ;
+		info->x_char = 0;
+		info->event = 0;
+		info->count = 0;
+		info->blocked_open = 0;
+		info->normal_termios = driver->init_termios;
+		init_waitqueue_head(&info->open_wait);
+		init_waitqueue_head(&info->close_wait);
+		info->xmit.buf = NULL;
+		info->xmit.tail = info->xmit.head = 0;
+		info->first_recv_buffer = info->last_recv_buffer = NULL;
+		info->recv_cnt = info->max_recv_cnt = 0;
+		info->last_tx_active_usec = 0;
+		info->last_tx_active = 0;
+
+#if defined(CONFIG_ETRAX_RS485)
+		/* Set sane defaults */
+		info->rs485.flags &= ~(SER_RS485_RTS_ON_SEND);
+		info->rs485.flags |= SER_RS485_RTS_AFTER_SEND;
+		info->rs485.flags &= ~(SER_RS485_RTS_BEFORE_SEND);
+		info->rs485.delay_rts_before_send = 0;
+		info->rs485.flags &= ~(SER_RS485_ENABLED);
+#endif
+		INIT_WORK(&info->work, do_softint);
+
+		if (info->enabled) {
+			printk(KERN_INFO "%s%d at %p is a builtin UART with DMA\n",
+			       serial_driver->name, info->line, info->ioport);
+		}
+	}
+#ifdef CONFIG_ETRAX_FAST_TIMER
+#ifdef CONFIG_ETRAX_SERIAL_FAST_TIMER
+	memset(fast_timers, 0, sizeof(fast_timers));
+#endif
+#ifdef CONFIG_ETRAX_RS485
+	memset(fast_timers_rs485, 0, sizeof(fast_timers_rs485));
+#endif
+	fast_timer_init();
+#endif
+
+#ifndef CONFIG_SVINTO_SIM
+#ifndef CONFIG_ETRAX_KGDB
+	/* Not needed in simulator.  May only complicate stuff. */
+	/* hook the irq's for DMA channel 6 and 7, serial output and input, and some more... */
+
+	if (request_irq(SERIAL_IRQ_NBR, ser_interrupt,
+			IRQF_SHARED | IRQF_DISABLED, "serial ", driver))
+		panic("%s: Failed to request irq8", __func__);
+
+#endif
+#endif /* CONFIG_SVINTO_SIM */
+
+	return 0;
+}
+
+/* this makes sure that rs_init is called during kernel boot */
+
+module_init(rs_init);
diff -Nur linux-2.6.39.orig/drivers/usb/host/hc-cris-dbg.h linux-2.6.39/drivers/usb/host/hc-cris-dbg.h
--- linux-2.6.39.orig/drivers/usb/host/hc-cris-dbg.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.39/drivers/usb/host/hc-cris-dbg.h	2011-07-28 16:16:37.503543830 +0200
@@ -0,0 +1,146 @@
+
+/* macros for debug output */
+
+#define warn(fmt, args...) \
+        printk(KERN_INFO "crisv10 warn: ");printk(fmt, ## args)
+
+#define hcd_dbg(hcd, fmt, args...) \
+	dev_info(hcd->self.controller, fmt, ## args)
+#define hcd_err(hcd, fmt, args...) \
+	dev_err(hcd->self.controller, fmt, ## args)
+#define hcd_info(hcd, fmt, args...) \
+	dev_info(hcd->self.controller, fmt, ## args)
+#define hcd_warn(hcd, fmt, args...) \
+	dev_warn(hcd->self.controller, fmt, ## args)
+
+/*
+#define devdrv_dbg(fmt, args...) \
+        printk(KERN_INFO "usb_devdrv dbg: ");printk(fmt, ## args)
+*/
+#define devdrv_dbg(fmt, args...) {}
+
+#define devdrv_err(fmt, args...) \
+        printk(KERN_ERR "usb_devdrv error: ");printk(fmt, ## args)
+#define devdrv_info(fmt, args...) \
+        printk(KERN_INFO "usb_devdrv: ");printk(fmt, ## args)
+
+#define irq_dbg(fmt, args...) \
+        printk(KERN_INFO "crisv10_irq dbg: ");printk(fmt, ## args)
+#define irq_err(fmt, args...) \
+        printk(KERN_ERR "crisv10_irq error: ");printk(fmt, ## args)
+#define irq_warn(fmt, args...) \
+        printk(KERN_INFO "crisv10_irq warn: ");printk(fmt, ## args)
+#define irq_info(fmt, args...) \
+        printk(KERN_INFO "crisv10_hcd: ");printk(fmt, ## args)
+
+/*
+#define rh_dbg(fmt, args...) \
+  printk(KERN_DEBUG "crisv10_rh dbg: ");printk(fmt, ## args)
+*/
+#define rh_dbg(fmt, args...) {}
+
+#define rh_err(fmt, args...) \
+        printk(KERN_ERR "crisv10_rh error: ");printk(fmt, ## args)
+#define rh_warn(fmt, args...) \
+        printk(KERN_INFO "crisv10_rh warning: ");printk(fmt, ## args)
+#define rh_info(fmt, args...) \
+        printk(KERN_INFO "crisv10_rh: ");printk(fmt, ## args)
+
+/*
+#define tc_dbg(fmt, args...) \
+        printk(KERN_INFO "crisv10_tc dbg: ");printk(fmt, ## args)
+*/
+#define tc_dbg(fmt, args...) {while(0){}}
+
+#define tc_err(fmt, args...) \
+        printk(KERN_ERR "crisv10_tc error: ");printk(fmt, ## args)
+/*
+#define tc_warn(fmt, args...) \
+        printk(KERN_INFO "crisv10_tc warning: ");printk(fmt, ## args)
+*/
+#define tc_warn(fmt, args...) {while(0){}}
+
+#define tc_info(fmt, args...) \
+        printk(KERN_INFO "crisv10_tc: ");printk(fmt, ## args)
+
+
+/* Debug print-outs for various traffic types */
+
+#define intr_warn(fmt, args...) \
+        printk(KERN_INFO "crisv10_intr warning: ");printk(fmt, ## args)
+
+#define intr_dbg(fmt, args...) \
+        printk(KERN_DEBUG "crisv10_intr dbg: ");printk(fmt, ## args)
+/*
+#define intr_dbg(fmt, args...) {while(0){}}
+*/
+
+
+#define isoc_err(fmt, args...) \
+        printk(KERN_ERR "crisv10_isoc error: ");printk(fmt, ## args)
+/*
+#define isoc_warn(fmt, args...) \
+        printk(KERN_INFO "crisv10_isoc warning: ");printk(fmt, ## args)
+*/
+#define isoc_warn(fmt, args...) {while(0){}}
+
+/*
+#define isoc_dbg(fmt, args...) \
+        printk(KERN_INFO "crisv10_isoc dbg: ");printk(fmt, ## args)
+*/
+#define isoc_dbg(fmt, args...) {while(0){}}
+
+/*
+#define timer_warn(fmt, args...) \
+        printk(KERN_INFO "crisv10_timer warning: ");printk(fmt, ## args)
+*/
+#define timer_warn(fmt, args...) {while(0){}}
+
+/*
+#define timer_dbg(fmt, args...) \
+        printk(KERN_INFO "crisv10_timer dbg: ");printk(fmt, ## args)
+*/
+#define timer_dbg(fmt, args...) {while(0){}}
+
+
+/* Debug printouts for events related to late finishing of URBs */
+
+#define late_dbg(fmt, args...) \
+        printk(KERN_INFO "crisv10_late dbg: ");printk(fmt, ## args)
+/*
+#define late_dbg(fmt, args...) {while(0){}}
+*/
+
+#define late_warn(fmt, args...) \
+        printk(KERN_INFO "crisv10_late warning: ");printk(fmt, ## args)
+/*
+#define errno_dbg(fmt, args...) \
+        printk(KERN_INFO "crisv10_errno dbg: ");printk(fmt, ## args)
+*/
+#define errno_dbg(fmt, args...) {while(0){}}
+
+
+#define dma_dbg(fmt, args...) \
+        printk(KERN_INFO "crisv10_dma dbg: ");printk(fmt, ## args)
+#define dma_err(fmt, args...) \
+        printk(KERN_ERR "crisv10_dma error: ");printk(fmt, ## args)
+#define dma_warn(fmt, args...) \
+        printk(KERN_INFO "crisv10_dma warning: ");printk(fmt, ## args)
+#define dma_info(fmt, args...) \
+        printk(KERN_INFO "crisv10_dma: ");printk(fmt, ## args)
+
+
+
+#define str_dir(pipe) \
+	(usb_pipeout(pipe) ? "out" : "in")
+#define str_type(pipe) \
+	({								\
+		char *s = "?";						\
+		switch (usb_pipetype(pipe)) {				\
+		case PIPE_ISOCHRONOUS:	s = "iso";  break;		\
+		case PIPE_INTERRUPT:	s = "intr"; break;		\
+		case PIPE_CONTROL:	s = "ctrl"; break;		\
+		case PIPE_BULK:		s = "bulk"; break;		\
+		};							\
+		s;							\
+	})
diff -Nur linux-2.6.39.orig/drivers/usb/host/hc-crisv10.c linux-2.6.39/drivers/usb/host/hc-crisv10.c
--- linux-2.6.39.orig/drivers/usb/host/hc-crisv10.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.39/drivers/usb/host/hc-crisv10.c	2011-07-28 16:16:37.633441816 +0200
@@ -0,0 +1,4801 @@
+/*
+ *
+ * ETRAX 100LX USB Host Controller Driver
+ *
+ * Copyright (C) 2005, 2006  Axis Communications AB
+ *
+ * Author: Konrad Eriksson <konrad.eriksson@axis.se>
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/moduleparam.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/usb.h>
+#include <linux/platform_device.h>
+#include <linux/usb/hcd.h>
+
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <arch/dma.h>
+#include <arch/io_interface_mux.h>
+
+#include "hc-crisv10.h"
+#include "hc-cris-dbg.h"
+
+
+/***************************************************************************/
+/***************************************************************************/
+/* Host Controller settings                                                */
+/***************************************************************************/
+/***************************************************************************/
+
+#define VERSION			"1.00 hinko.4"
+#define COPYRIGHT		"(c) 2005, 2006 Axis Communications AB"
+#define DESCRIPTION     "ETRAX 100LX USB Host Controller"
+
+#define ETRAX_USB_HC_IRQ USB_HC_IRQ_NBR
+#define ETRAX_USB_RX_IRQ USB_DMA_RX_IRQ_NBR
+#define ETRAX_USB_TX_IRQ USB_DMA_TX_IRQ_NBR
+
+/* Number of physical ports in Etrax 100LX */
+#define USB_ROOT_HUB_PORTS 2
+
+const char hc_name[] = "hc-crisv10";
+const char product_desc[] = DESCRIPTION;
+
+/* The number of epids is, among other things, used for pre-allocating
+   ctrl, bulk and isoc EP descriptors (one for each epid).
+   Assumed to be > 1 when initiating the DMA lists. */
+#define NBR_OF_EPIDS       32
+
+/* Support interrupt traffic intervals up to 128 ms. */
+#define MAX_INTR_INTERVAL  128
+
+/* If periodic traffic (intr or isoc) is to be used, then one entry in the EP
+   table must be "invalid". By this we mean that we shouldn't care about epid
+   attentions for this epid, or at least handle them differently from epid
+   attentions for "valid" epids. This define determines which one to use
+   (don't change it). */
+#define INVALID_EPID       31
+/* A special epid for the bulk dummys. */
+#define DUMMY_EPID         30
+
+/* Module settings */
+
+MODULE_DESCRIPTION(DESCRIPTION);
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Konrad Eriksson <konrad.eriksson@axis.se>");
+
+
+/* Module parameters */
+
+/* 0 = No ports enabled
+   1 = Only port 1 enabled (on board ethernet on devboard)
+   2 = Only port 2 enabled (external connector on devboard)
+   3 = Both ports enabled
+*/
+static unsigned int ports = 3;
+module_param(ports, uint, S_IRUGO);
+MODULE_PARM_DESC(ports, "Bitmask indicating USB ports to use");
+
+
+/***************************************************************************/
+/***************************************************************************/
+/* Shared global variables for this module                                 */
+/***************************************************************************/
+/***************************************************************************/
+
+/* EP descriptor lists for non period transfers. Must be 32-bit aligned. */
+static volatile struct USB_EP_Desc TxBulkEPList[NBR_OF_EPIDS] __attribute__ ((aligned (4)));
+
+static volatile struct USB_EP_Desc TxCtrlEPList[NBR_OF_EPIDS] __attribute__ ((aligned (4)));
+
+/* EP descriptor lists for period transfers. Must be 32-bit aligned. */
+static volatile struct USB_EP_Desc TxIntrEPList[MAX_INTR_INTERVAL] __attribute__ ((aligned (4)));
+static volatile struct USB_SB_Desc TxIntrSB_zout __attribute__ ((aligned (4)));
+
+static volatile struct USB_EP_Desc TxIsocEPList[NBR_OF_EPIDS] __attribute__ ((aligned (4)));
+static volatile struct USB_SB_Desc TxIsocSB_zout __attribute__ ((aligned (4)));
+
+//static volatile struct USB_SB_Desc TxIsocSBList[NBR_OF_EPIDS] __attribute__ ((aligned (4))); 
+
+/* After each enabled bulk EP IN we put two disabled EP descriptors with the eol flag set,
+   causing the DMA to stop the DMA channel. The first of these two has the intr flag set, which
+   gives us a dma8_sub0_descr interrupt. When we receive this, we advance the DMA one step in the
+   EP list and then restart the bulk channel, thus forcing a switch between bulk EP descriptors
+   in each frame. */
+static volatile struct USB_EP_Desc TxBulkDummyEPList[NBR_OF_EPIDS][2] __attribute__ ((aligned (4)));
+
+/* List of URB pointers, where each points to the active URB for a epid.
+   For Bulk, Ctrl and Intr this means which URB that currently is added to
+   DMA lists (Isoc URBs are all directly added to DMA lists). As soon as
+   URB has completed is the queue examined and the first URB in queue is
+   removed and moved to the activeUrbList while its state change to STARTED and
+   its transfer(s) gets added to DMA list (exception Isoc where URBs enter
+   state STARTED directly and added transfers added to DMA lists). */
+static struct urb *activeUrbList[NBR_OF_EPIDS];
+
+/* Additional software state info for each epid */
+static struct etrax_epid epid_state[NBR_OF_EPIDS];
+
+/* Timer handles for bulk traffic timer used to avoid DMA bug where DMA stops
+   even if there is new data waiting to be processed */
+static struct timer_list bulk_start_timer = TIMER_INITIALIZER(NULL, 0, 0);
+static struct timer_list bulk_eot_timer = TIMER_INITIALIZER(NULL, 0, 0);
+
+/* We want the start timer to expire before the eot timer, because the former
+   might start traffic, thus making it unnecessary for the latter to time
+   out. */
+#define BULK_START_TIMER_INTERVAL (HZ/50) /* 20 ms */
+#define BULK_EOT_TIMER_INTERVAL (HZ/16) /* 60 ms */
+
+/* Delay before a URB completion happen when it's scheduled to be delayed */
+#define LATER_TIMER_DELAY (HZ/50) /* 20 ms */
+
+/* Simplifying macros for checking software state info of a epid */
+/* ----------------------------------------------------------------------- */
+#define epid_inuse(epid)       epid_state[epid].inuse
+#define epid_out_traffic(epid) epid_state[epid].out_traffic
+#define epid_isoc(epid)   (epid_state[epid].type == PIPE_ISOCHRONOUS ? 1 : 0)
+#define epid_intr(epid)   (epid_state[epid].type == PIPE_INTERRUPT ? 1 : 0)
+
+
+/***************************************************************************/
+/***************************************************************************/
+/* DEBUG FUNCTIONS                                                         */
+/***************************************************************************/
+/***************************************************************************/
+/* Note that these functions are always available in their "__" variants,
+   for use in error situations. The "__" missing variants are controlled by
+   the USB_DEBUG_DESC/USB_DEBUG_URB macros. */
+static void __dump_urb(struct urb* purb)
+{
+  struct crisv10_urb_priv *urb_priv = purb->hcpriv;
+  int urb_num = -1;
+  if(urb_priv) {
+    urb_num = urb_priv->urb_num;
+  }
+  printk("\nURB:0x%x[%d]\n", (unsigned int)purb, urb_num);
+  printk("dev                   :0x%08lx\n", (unsigned long)purb->dev);
+  printk("pipe                  :0x%08x\n", purb->pipe);
+  printk("status                :%d\n", purb->status);
+  printk("transfer_flags        :0x%08x\n", purb->transfer_flags);
+  printk("transfer_buffer       :0x%08lx\n", (unsigned long)purb->transfer_buffer);
+  printk("transfer_buffer_length:%d\n", purb->transfer_buffer_length);
+  printk("actual_length         :%d\n", purb->actual_length);
+  printk("setup_packet          :0x%08lx\n", (unsigned long)purb->setup_packet);
+  printk("start_frame           :%d\n", purb->start_frame);
+  printk("number_of_packets     :%d\n", purb->number_of_packets);
+  printk("interval              :%d\n", purb->interval);
+  printk("error_count           :%d\n", purb->error_count);
+  printk("context               :0x%08lx\n", (unsigned long)purb->context);
+  printk("complete              :0x%08lx\n\n", (unsigned long)purb->complete);
+}
+
+static void __dump_in_desc(volatile struct USB_IN_Desc *in)
+{
+  printk("\nUSB_IN_Desc at 0x%08lx\n", (unsigned long)in);
+  printk("  sw_len  : 0x%04x (%d)\n", in->sw_len, in->sw_len);
+  printk("  command : 0x%04x\n", in->command);
+  printk("  next    : 0x%08lx\n", in->next);
+  printk("  buf     : 0x%08lx\n", in->buf);
+  printk("  hw_len  : 0x%04x (%d)\n", in->hw_len, in->hw_len);
+  printk("  status  : 0x%04x\n\n", in->status);
+}
+
+static void __dump_sb_desc(volatile struct USB_SB_Desc *sb)
+{
+  char tt = (sb->command & 0x30) >> 4;
+  char *tt_string;
+
+  switch (tt) {
+  case 0:
+    tt_string = "zout";
+    break;
+  case 1:
+    tt_string = "in";
+    break;
+  case 2:
+    tt_string = "out";
+    break;
+  case 3:
+    tt_string = "setup";
+    break;
+  default:
+    tt_string = "unknown (weird)";
+  }
+
+  printk(" USB_SB_Desc at 0x%08lx ", (unsigned long)sb);
+  printk(" command:0x%04x (", sb->command);
+  printk("rem:%d ", (sb->command & 0x3f00) >> 8);
+  printk("full:%d ", (sb->command & 0x40) >> 6);
+  printk("tt:%d(%s) ", tt, tt_string);
+  printk("intr:%d ", (sb->command & 0x8) >> 3);
+  printk("eot:%d ", (sb->command & 0x2) >> 1);
+  printk("eol:%d)", sb->command & 0x1);
+  printk(" sw_len:0x%04x(%d)", sb->sw_len, sb->sw_len);
+  printk(" next:0x%08lx", sb->next);
+  printk(" buf:0x%08lx\n", sb->buf);
+}
+
+
+static void __dump_ep_desc(volatile struct USB_EP_Desc *ep)
+{
+  printk("USB_EP_Desc at 0x%08lx ", (unsigned long)ep);
+  printk(" command:0x%04x (", ep->command);
+  printk("ep_id:%d ", (ep->command & 0x1f00) >> 8);
+  printk("enable:%d ", (ep->command & 0x10) >> 4);
+  printk("intr:%d ", (ep->command & 0x8) >> 3);
+  printk("eof:%d ", (ep->command & 0x2) >> 1);
+  printk("eol:%d)", ep->command & 0x1);
+  printk(" hw_len:0x%04x(%d)", ep->hw_len, ep->hw_len);
+  printk(" next:0x%08lx", ep->next);
+  printk(" sub:0x%08lx\n", ep->sub);
+}
+
+static inline void __dump_ep_list(int pipe_type)
+{
+  volatile struct USB_EP_Desc *ep;
+  volatile struct USB_EP_Desc *first_ep;
+  volatile struct USB_SB_Desc *sb;
+
+  switch (pipe_type)
+    {
+    case PIPE_BULK:
+      first_ep = &TxBulkEPList[0];
+      break;
+    case PIPE_CONTROL:
+      first_ep = &TxCtrlEPList[0];
+      break;
+    case PIPE_INTERRUPT:
+      first_ep = &TxIntrEPList[0];
+      break;
+    case PIPE_ISOCHRONOUS:
+      first_ep = &TxIsocEPList[0];
+      break;
+    default:
+      warn("Cannot dump unknown traffic type");
+      return;
+    }
+  ep = first_ep;
+
+  printk("\n\nDumping EP list...\n\n");
+
+  do {
+    __dump_ep_desc(ep);
+    /* Cannot phys_to_virt on 0 as it turns into 80000000, which is != 0. */
+    sb = ep->sub ? phys_to_virt(ep->sub) : 0;
+    while (sb) {
+      __dump_sb_desc(sb);
+      sb = sb->next ? phys_to_virt(sb->next) : 0;
+    }
+    ep = (volatile struct USB_EP_Desc *)(phys_to_virt(ep->next));
+
+  } while (ep != first_ep);
+}
+
+static inline void __dump_ept_data(int epid)
+{
+  unsigned long flags;
+  __u32 r_usb_ept_data;
+
+  if (epid < 0 || epid > 31) {
+    printk("Cannot dump ept data for invalid epid %d\n", epid);
+    return;
+  }
+
+  local_irq_save(flags);
+  *R_USB_EPT_INDEX = IO_FIELD(R_USB_EPT_INDEX, value, epid);
+  nop();
+  r_usb_ept_data = *R_USB_EPT_DATA;
+  local_irq_restore(flags);
+
+  printk(" R_USB_EPT_DATA = 0x%x for epid %d :\n", r_usb_ept_data, epid);
+  if (r_usb_ept_data == 0) {
+    /* No need for more detailed printing. */
+    return;
+  }
+  printk("  valid           : %d\n", (r_usb_ept_data & 0x80000000) >> 31);
+  printk("  hold            : %d\n", (r_usb_ept_data & 0x40000000) >> 30);
+  printk("  error_count_in  : %d\n", (r_usb_ept_data & 0x30000000) >> 28);
+  printk("  t_in            : %d\n", (r_usb_ept_data & 0x08000000) >> 27);
+  printk("  low_speed       : %d\n", (r_usb_ept_data & 0x04000000) >> 26);
+  printk("  port            : %d\n", (r_usb_ept_data & 0x03000000) >> 24);
+  printk("  error_code      : %d\n", (r_usb_ept_data & 0x00c00000) >> 22);
+  printk("  t_out           : %d\n", (r_usb_ept_data & 0x00200000) >> 21);
+  printk("  error_count_out : %d\n", (r_usb_ept_data & 0x00180000) >> 19);
+  printk("  max_len         : %d\n", (r_usb_ept_data & 0x0003f800) >> 11);
+  printk("  ep              : %d\n", (r_usb_ept_data & 0x00000780) >> 7);
+  printk("  dev             : %d\n", (r_usb_ept_data & 0x0000003f));
+}
+
+static inline void __dump_ept_data_iso(int epid)
+{
+  unsigned long flags;
+  __u32 ept_data;
+
+  if (epid < 0 || epid > 31) {
+    printk("Cannot dump ept data for invalid epid %d\n", epid);
+    return;
+  }
+
+  local_irq_save(flags);
+  *R_USB_EPT_INDEX = IO_FIELD(R_USB_EPT_INDEX, value, epid);
+  nop();
+  ept_data = *R_USB_EPT_DATA_ISO;
+  local_irq_restore(flags);
+
+  printk(" R_USB_EPT_DATA = 0x%x for epid %d :\n", ept_data, epid);
+  if (ept_data == 0) {
+    /* No need for more detailed printing. */
+    return;
+  }
+  printk("  valid           : %d\n", IO_EXTRACT(R_USB_EPT_DATA_ISO, valid,
+						ept_data));
+  printk("  port            : %d\n", IO_EXTRACT(R_USB_EPT_DATA_ISO, port,
+						ept_data));
+  printk("  error_code      : %d\n", IO_EXTRACT(R_USB_EPT_DATA_ISO, error_code,
+						ept_data));
+  printk("  max_len         : %d\n", IO_EXTRACT(R_USB_EPT_DATA_ISO, max_len,
+						ept_data));
+  printk("  ep              : %d\n", IO_EXTRACT(R_USB_EPT_DATA_ISO, ep,
+						ept_data));
+  printk("  dev             : %d\n", IO_EXTRACT(R_USB_EPT_DATA_ISO, dev,
+						ept_data));
+}
+
+static inline void __dump_ept_data_list(void)
+{
+  int i;
+
+  printk("Dumping the whole R_USB_EPT_DATA list\n");
+
+  for (i = 0; i < 32; i++) {
+    __dump_ept_data(i);
+  }
+}
+
+static void debug_epid(int epid) {
+  int i;
+  
+  if(epid_isoc(epid)) {
+    __dump_ept_data_iso(epid);
+  } else {
+    __dump_ept_data(epid);
+  }
+
+  printk("Bulk:\n");
+  for(i = 0; i < 32; i++) {
+    if(IO_EXTRACT(USB_EP_command, epid, TxBulkEPList[i].command) ==
+       epid) {
+      printk("%d: ", i); __dump_ep_desc(&(TxBulkEPList[i]));
+    }
+  }
+
+  printk("Ctrl:\n");
+  for(i = 0; i < 32; i++) {
+    if(IO_EXTRACT(USB_EP_command, epid, TxCtrlEPList[i].command) ==
+       epid) {
+      printk("%d: ", i); __dump_ep_desc(&(TxCtrlEPList[i]));
+    }
+  }
+
+  printk("Intr:\n");
+  for(i = 0; i < MAX_INTR_INTERVAL; i++) {
+    if(IO_EXTRACT(USB_EP_command, epid, TxIntrEPList[i].command) ==
+       epid) {
+      printk("%d: ", i); __dump_ep_desc(&(TxIntrEPList[i]));
+    }
+  }
+  
+  printk("Isoc:\n");
+  for(i = 0; i < 32; i++) {
+    if(IO_EXTRACT(USB_EP_command, epid, TxIsocEPList[i].command) ==
+       epid) {
+      printk("%d: ", i); __dump_ep_desc(&(TxIsocEPList[i]));
+    }
+  }
+
+  __dump_ept_data_list();
+  __dump_ep_list(PIPE_INTERRUPT);
+  printk("\n\n");
+}
+
+
+
+char* hcd_status_to_str(__u8 bUsbStatus) {
+  static char hcd_status_str[128];
+  hcd_status_str[0] = '\0';
+  if(bUsbStatus & IO_STATE(R_USB_STATUS, ourun, yes)) {
+    strcat(hcd_status_str, "ourun ");
+  }
+  if(bUsbStatus & IO_STATE(R_USB_STATUS, perror, yes)) {
+    strcat(hcd_status_str, "perror ");
+  }
+  if(bUsbStatus & IO_STATE(R_USB_STATUS, device_mode, yes)) {
+    strcat(hcd_status_str, "device_mode ");
+  }
+  if(bUsbStatus & IO_STATE(R_USB_STATUS, host_mode, yes)) {
+    strcat(hcd_status_str, "host_mode ");
+  }
+  if(bUsbStatus & IO_STATE(R_USB_STATUS, started, yes)) {
+    strcat(hcd_status_str, "started ");
+  }
+  if(bUsbStatus & IO_STATE(R_USB_STATUS, running, yes)) {
+    strcat(hcd_status_str, "running ");
+  }
+  return hcd_status_str;
+}
+
+
+char* sblist_to_str(struct USB_SB_Desc* sb_desc) {
+  static char sblist_to_str_buff[128];
+  char tmp[32], tmp2[32];
+  sblist_to_str_buff[0] = '\0';
+  while(sb_desc != NULL) {
+    switch(IO_EXTRACT(USB_SB_command, tt, sb_desc->command)) {
+    case 0: sprintf(tmp, "zout");  break;
+    case 1: sprintf(tmp, "in");    break;
+    case 2: sprintf(tmp, "out");   break;
+    case 3: sprintf(tmp, "setup"); break;
+    }
+    sprintf(tmp2, "(%s %d)", tmp, sb_desc->sw_len);
+    strcat(sblist_to_str_buff, tmp2);
+    if(sb_desc->next != 0) {
+      sb_desc = phys_to_virt(sb_desc->next);
+    } else {
+      sb_desc = NULL;
+    }
+  }
+  return sblist_to_str_buff;
+}
+
+char* port_status_to_str(__u16 wPortStatus) {
+  static char port_status_str[128];
+  port_status_str[0] = '\0';
+  if(wPortStatus & IO_STATE(R_USB_RH_PORT_STATUS_1, connected, yes)) {
+    strcat(port_status_str, "connected ");
+  }
+  if(wPortStatus & IO_STATE(R_USB_RH_PORT_STATUS_1, enabled, yes)) {
+    strcat(port_status_str, "enabled ");
+  }
+  if(wPortStatus & IO_STATE(R_USB_RH_PORT_STATUS_1, suspended, yes)) {
+    strcat(port_status_str, "suspended ");
+  }
+  if(wPortStatus & IO_STATE(R_USB_RH_PORT_STATUS_1, reset, yes)) {
+    strcat(port_status_str, "reset ");
+  }
+  if(wPortStatus & IO_STATE(R_USB_RH_PORT_STATUS_1, speed, full)) {
+    strcat(port_status_str, "full-speed ");
+  } else {
+    strcat(port_status_str, "low-speed ");
+  }
+  return port_status_str;
+}
+
+
+char* endpoint_to_str(struct usb_endpoint_descriptor *ed) {
+  static char endpoint_to_str_buff[128];
+  char tmp[32];
+  int epnum = ed->bEndpointAddress & 0x0F;
+  int dir = ed->bEndpointAddress & 0x80;
+  int type = ed->bmAttributes & 0x03;
+  endpoint_to_str_buff[0] = '\0';
+  sprintf(endpoint_to_str_buff, "ep:%d ", epnum);
+  switch(type) {
+  case 0:
+    sprintf(tmp, " ctrl");
+    break;
+  case 1:
+    sprintf(tmp, " isoc");
+    break;
+  case 2:
+    sprintf(tmp, " bulk");
+    break;
+  case 3:
+    sprintf(tmp, " intr");
+    break;
+  }
+  strcat(endpoint_to_str_buff, tmp);
+  if(dir) {
+    sprintf(tmp, " in");
+  } else {
+    sprintf(tmp, " out");
+  }
+  strcat(endpoint_to_str_buff, tmp);
+
+  return endpoint_to_str_buff;
+}
+
+/* Debug helper functions for Transfer Controller */
+char* pipe_to_str(unsigned int pipe) {
+  static char pipe_to_str_buff[128];
+  char tmp[64];
+  sprintf(pipe_to_str_buff, "dir:%s", str_dir(pipe));
+  sprintf(tmp, " type:%s", str_type(pipe));
+  strcat(pipe_to_str_buff, tmp);
+
+  sprintf(tmp, " dev:%d", usb_pipedevice(pipe));
+  strcat(pipe_to_str_buff, tmp);
+  sprintf(tmp, " ep:%d", usb_pipeendpoint(pipe));
+  strcat(pipe_to_str_buff, tmp);
+  return pipe_to_str_buff;
+}
+
+
+#define USB_DEBUG_DESC 1
+
+#ifdef USB_DEBUG_DESC
+#define dump_in_desc(x) __dump_in_desc(x)
+#define dump_sb_desc(...) __dump_sb_desc(...)
+#define dump_ep_desc(x) __dump_ep_desc(x)
+#define dump_ept_data(x) __dump_ept_data(x)
+#else
+#define dump_in_desc(...) do {} while (0)
+#define dump_sb_desc(...) do {} while (0)
+#define dump_ep_desc(...) do {} while (0)
+#endif
+
+
+/* Uncomment this to enable massive function call trace
+   #define USB_DEBUG_TRACE */
+//#define USB_DEBUG_TRACE 1
+
+#ifdef USB_DEBUG_TRACE
+#define DBFENTER (printk(": Entering: %s\n", __FUNCTION__))
+#define DBFEXIT  (printk(": Exiting:  %s\n", __FUNCTION__))
+#else
+#define DBFENTER do {} while (0)
+#define DBFEXIT  do {} while (0)
+#endif
+
+#define CHECK_ALIGN(x) if (((__u32)(x)) & 0x00000003) \
+{panic("Alignment check (DWORD) failed at %s:%s:%d\n", __FILE__, __FUNCTION__, __LINE__);}
+
+/* Most helpful debugging aid */
+#define ASSERT(expr) ((void) ((expr) ? 0 : (err("assert failed at: %s %d",__FUNCTION__, __LINE__))))
+
+
+/***************************************************************************/
+/***************************************************************************/
+/* Forward declarations                                                    */
+/***************************************************************************/
+/***************************************************************************/
+void crisv10_hcd_epid_attn_irq(struct crisv10_irq_reg *reg);
+void crisv10_hcd_port_status_irq(struct crisv10_irq_reg *reg);
+void crisv10_hcd_ctl_status_irq(struct crisv10_irq_reg *reg);
+void crisv10_hcd_isoc_eof_irq(struct crisv10_irq_reg *reg);
+
+void rh_port_status_change(__u16[]);
+int  rh_clear_port_feature(__u8, __u16);
+int  rh_set_port_feature(__u8, __u16);
+static void rh_disable_port(unsigned int port);
+
+static void check_finished_bulk_tx_epids(struct usb_hcd *hcd,
+					 int timer);
+
+//static int  tc_setup_epid(struct usb_host_endpoint *ep, struct urb *urb,
+//			 int mem_flags);
+static int tc_setup_epid(struct urb *urb, int mem_flags);
+static void tc_free_epid(struct usb_host_endpoint *ep);
+static int  tc_allocate_epid(void);
+static void tc_finish_urb(struct usb_hcd *hcd, struct urb *urb, int status);
+static void tc_finish_urb_later(struct usb_hcd *hcd, struct urb *urb,
+				int status);
+
+static int  urb_priv_create(struct usb_hcd *hcd, struct urb *urb, int epid,
+			   int mem_flags);
+static void urb_priv_free(struct usb_hcd *hcd, struct urb *urb);
+
+static inline struct urb *urb_list_first(int epid);
+static inline void        urb_list_add(struct urb *urb, int epid,
+				      int mem_flags);
+static inline urb_entry_t *urb_list_entry(struct urb *urb, int epid);
+static inline void        urb_list_del(struct urb *urb, int epid);
+static inline void        urb_list_move_last(struct urb *urb, int epid);
+static inline struct urb *urb_list_next(struct urb *urb, int epid);
+
+int create_sb_for_urb(struct urb *urb, int mem_flags);
+int init_intr_urb(struct urb *urb, int mem_flags);
+
+static inline void  etrax_epid_set(__u8 index, __u32 data);
+static inline void  etrax_epid_clear_error(__u8 index);
+static inline void  etrax_epid_set_toggle(__u8 index, __u8 dirout,
+					      __u8 toggle);
+static inline __u8  etrax_epid_get_toggle(__u8 index, __u8 dirout);
+static inline __u32 etrax_epid_get(__u8 index);
+
+/* We're accessing the same register position in Etrax so
+   when we do full access the internal difference doesn't matter */
+#define etrax_epid_iso_set(index, data) etrax_epid_set(index, data)
+#define etrax_epid_iso_get(index) etrax_epid_get(index)
+
+
+//static void        tc_dma_process_isoc_urb(struct urb *urb);
+static void        tc_dma_process_queue(int epid);
+static void        tc_dma_unlink_intr_urb(struct urb *urb);
+static irqreturn_t tc_dma_tx_interrupt(int irq, void *vhc);
+static irqreturn_t tc_dma_rx_interrupt(int irq, void *vhc);
+
+static void tc_bulk_start_timer_func(unsigned long dummy);
+static void tc_bulk_eot_timer_func(unsigned long dummy);
+
+
+/*************************************************************/
+/*************************************************************/
+/* Host Controler Driver block                               */
+/*************************************************************/
+/*************************************************************/
+
+/* HCD operations */
+static irqreturn_t crisv10_hcd_top_irq(int irq, void*);
+static int crisv10_hcd_reset(struct usb_hcd *);
+static int crisv10_hcd_start(struct usb_hcd *);
+static void crisv10_hcd_stop(struct usb_hcd *);
+#ifdef CONFIG_PM
+static int crisv10_hcd_suspend(struct device *, u32, u32);
+static int crisv10_hcd_resume(struct device *, u32);
+#endif /* CONFIG_PM */
+static int crisv10_hcd_get_frame(struct usb_hcd *);
+
+//static int  tc_urb_enqueue(struct usb_hcd *, struct usb_host_endpoint *ep, struct urb *, gfp_t mem_flags);
+static int tc_urb_enqueue(struct usb_hcd *hcd, struct urb *urb, gfp_t mem_flags);
+//static int  tc_urb_dequeue(struct usb_hcd *, struct urb *);
+static int tc_urb_dequeue(struct usb_hcd *hcd, struct urb *urb, int status);
+static void tc_endpoint_disable(struct usb_hcd *, struct usb_host_endpoint *ep);
+
+static int rh_status_data_request(struct usb_hcd *, char *);
+static int rh_control_request(struct usb_hcd *, u16, u16, u16, char*, u16);
+
+#ifdef CONFIG_PM
+static int crisv10_hcd_hub_suspend(struct usb_hcd *);
+static int crisv10_hcd_hub_resume(struct usb_hcd *);
+#endif /* CONFIG_PM */
+#ifdef CONFIG_USB_OTG
+static int crisv10_hcd_start_port_reset(struct usb_hcd *, unsigned);
+#endif /* CONFIG_USB_OTG */
+
+/* host controller driver interface */
+static const struct hc_driver crisv10_hc_driver = 
+  {
+    .description =	hc_name,
+    .product_desc =	product_desc,
+    .hcd_priv_size =	sizeof(struct crisv10_hcd),
+
+    /* Attaching IRQ handler manualy in probe() */
+    /* .irq =		crisv10_hcd_irq, */
+
+    .flags =		HCD_USB11,
+
+    /* called to init HCD and root hub */
+    .reset =		crisv10_hcd_reset,
+    .start =		crisv10_hcd_start,	
+
+    /* cleanly make HCD stop writing memory and doing I/O */
+    .stop =		crisv10_hcd_stop,
+
+    /* return current frame number */
+    .get_frame_number =	crisv10_hcd_get_frame,
+
+
+    /* Manage i/o requests via the Transfer Controller */
+    .urb_enqueue =	tc_urb_enqueue,
+    .urb_dequeue =	tc_urb_dequeue,
+
+    /* hw synch, freeing endpoint resources that urb_dequeue can't */
+    .endpoint_disable = tc_endpoint_disable,
+
+
+    /* Root Hub support */
+    .hub_status_data =	rh_status_data_request,
+    .hub_control =	rh_control_request,
+#ifdef CONFIG_PM
+    .hub_suspend =	rh_suspend_request,
+    .hub_resume =	rh_resume_request,
+#endif /* CONFIG_PM */
+#ifdef	CONFIG_USB_OTG
+    .start_port_reset =	crisv10_hcd_start_port_reset,
+#endif /* CONFIG_USB_OTG */
+  };
+
+
+/*
+ * conversion between pointers to a hcd and the corresponding
+ * crisv10_hcd 
+ */
+
+static inline struct crisv10_hcd *hcd_to_crisv10_hcd(struct usb_hcd *hcd)
+{
+	return (struct crisv10_hcd *) hcd->hcd_priv;
+}
+
+static inline struct usb_hcd *crisv10_hcd_to_hcd(struct crisv10_hcd *hcd)
+{
+	return container_of((void *) hcd, struct usb_hcd, hcd_priv);
+}
+
+/* check if specified port is in use */
+static inline int port_in_use(unsigned int port)
+{
+	return ports & (1 << port);
+}
+
+/* number of ports in use */
+static inline unsigned int num_ports(void)
+{
+	unsigned int i, num = 0;
+	for (i = 0; i < USB_ROOT_HUB_PORTS; i++)
+		if (port_in_use(i))
+			num++;
+	return num;
+}
+
+/* map hub port number to the port number used internally by the HC */
+static inline unsigned int map_port(unsigned int port)
+{
+  unsigned int i, num = 0;
+  for (i = 0; i < USB_ROOT_HUB_PORTS; i++)
+    if (port_in_use(i))
+      if (++num == port)
+	return i;
+  return -1;
+}
+
+/* size of descriptors in slab cache */
+#ifndef MAX
+#define MAX(x, y)		((x) > (y) ? (x) : (y))
+#endif
+
+
+/******************************************************************/
+/* Hardware Interrupt functions                                   */
+/******************************************************************/
+
+/* Fast interrupt handler for HC */
+static irqreturn_t crisv10_hcd_top_irq(int irq, void *vcd)
+{
+  struct usb_hcd *hcd = vcd;
+  struct crisv10_irq_reg reg;
+  __u32 irq_mask;
+  unsigned long flags;
+
+  DBFENTER;
+
+  ASSERT(hcd != NULL);
+  reg.hcd = hcd;
+
+  /* Turn of other interrupts while handling these sensitive cases */
+  local_irq_save(flags);
+  
+  /* Read out which interrupts that are flaged */
+  irq_mask = *R_USB_IRQ_MASK_READ;
+  reg.r_usb_irq_mask_read = irq_mask;
+
+  /* Reading R_USB_STATUS clears the ctl_status interrupt. Note that
+     R_USB_STATUS must be read before R_USB_EPID_ATTN since reading the latter
+     clears the ourun and perror fields of R_USB_STATUS. */
+  reg.r_usb_status = *R_USB_STATUS;
+  
+  /* Reading R_USB_EPID_ATTN clears the iso_eof, bulk_eot and epid_attn
+     interrupts. */
+  reg.r_usb_epid_attn = *R_USB_EPID_ATTN;
+  
+  /* Reading R_USB_RH_PORT_STATUS_1 and R_USB_RH_PORT_STATUS_2 clears the
+     port_status interrupt. */
+  reg.r_usb_rh_port_status_1 = *R_USB_RH_PORT_STATUS_1;
+  reg.r_usb_rh_port_status_2 = *R_USB_RH_PORT_STATUS_2;
+  
+  /* Reading R_USB_FM_NUMBER clears the sof interrupt. */
+  /* Note: the lower 11 bits contain the actual frame number, sent with each
+     sof. */
+  reg.r_usb_fm_number = *R_USB_FM_NUMBER;
+
+  /* Interrupts are handled in order of priority. */
+  if (irq_mask & IO_MASK(R_USB_IRQ_MASK_READ, port_status)) {
+    crisv10_hcd_port_status_irq(&reg);
+  }
+  if (irq_mask & IO_MASK(R_USB_IRQ_MASK_READ, epid_attn)) {
+    crisv10_hcd_epid_attn_irq(&reg);
+  }
+  if (irq_mask & IO_MASK(R_USB_IRQ_MASK_READ, ctl_status)) {
+    crisv10_hcd_ctl_status_irq(&reg);
+  }
+  if (irq_mask & IO_MASK(R_USB_IRQ_MASK_READ, iso_eof)) {
+    crisv10_hcd_isoc_eof_irq(&reg);
+  }
+  if (irq_mask & IO_MASK(R_USB_IRQ_MASK_READ, bulk_eot)) {
+    /* Update/restart the bulk start timer since obviously the channel is
+       running. */
+    mod_timer(&bulk_start_timer, jiffies + BULK_START_TIMER_INTERVAL);
+    /* Update/restart the bulk eot timer since we just received an bulk eot
+       interrupt. */
+    mod_timer(&bulk_eot_timer, jiffies + BULK_EOT_TIMER_INTERVAL);
+
+    /* Check for finished bulk transfers on epids */
+    check_finished_bulk_tx_epids(hcd, 0);
+  }
+  local_irq_restore(flags);
+
+  DBFEXIT;
+  return IRQ_HANDLED;
+}
+
+
+void crisv10_hcd_epid_attn_irq(struct crisv10_irq_reg *reg) {
+  struct usb_hcd *hcd = reg->hcd;
+  struct crisv10_urb_priv *urb_priv;
+  int epid;
+  DBFENTER;
+
+  for (epid = 0; epid < NBR_OF_EPIDS; epid++) {
+    if (test_bit(epid, (void *)&reg->r_usb_epid_attn)) {
+      struct urb *urb;
+      __u32 ept_data;
+      int error_code;
+
+      if (epid == DUMMY_EPID || epid == INVALID_EPID) {
+	/* We definitely don't care about these ones. Besides, they are
+	   always disabled, so any possible disabling caused by the
+	   epid attention interrupt is irrelevant. */
+	warn("Got epid_attn for INVALID_EPID or DUMMY_EPID (%d).", epid);
+	continue;
+      }
+
+      if(!epid_inuse(epid)) {
+	irq_err("Epid attention on epid:%d that isn't in use\n", epid);
+	printk("R_USB_STATUS: 0x%x\n", reg->r_usb_status);
+	debug_epid(epid);
+	continue;
+      }
+
+      /* Note that although there are separate R_USB_EPT_DATA and
+	 R_USB_EPT_DATA_ISO registers, they are located at the same address and
+	 are of the same size. In other words, this read should be ok for isoc
+	 also. */
+      ept_data = etrax_epid_get(epid);
+      error_code = IO_EXTRACT(R_USB_EPT_DATA, error_code, ept_data);
+
+      /* Get the active URB for this epid. We blatantly assume
+	 that only this URB could have caused the epid attention. */
+      urb = activeUrbList[epid];
+      if (urb == NULL) {
+	irq_err("Attention on epid:%d error:%d with no active URB.\n",
+		epid, error_code);
+	printk("R_USB_STATUS: 0x%x\n", reg->r_usb_status);
+	debug_epid(epid);
+	continue;
+      }
+
+      urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+      ASSERT(urb_priv);
+
+      /* Using IO_STATE_VALUE on R_USB_EPT_DATA should be ok for isoc also. */
+      if (error_code == IO_STATE_VALUE(R_USB_EPT_DATA, error_code, no_error)) {
+
+	/* Isoc traffic doesn't have error_count_in/error_count_out. */
+	if ((usb_pipetype(urb->pipe) != PIPE_ISOCHRONOUS) &&
+	    (IO_EXTRACT(R_USB_EPT_DATA, error_count_in, ept_data) == 3 ||
+	     IO_EXTRACT(R_USB_EPT_DATA, error_count_out, ept_data) == 3)) {
+	  /* Check if URB allready is marked for late-finish, we can get
+	     several 3rd error for Intr traffic when a device is unplugged */
+	  if(urb_priv->later_data == NULL) {
+	    /* 3rd error. */
+	    irq_warn("3rd error for epid:%d (%s %s) URB:0x%x[%d]\n", epid,
+		     str_dir(urb->pipe), str_type(urb->pipe),
+		     (unsigned int)urb, urb_priv->urb_num);
+	  
+	    tc_finish_urb_later(hcd, urb, -EPROTO);
+	  }
+
+	} else if (reg->r_usb_status & IO_MASK(R_USB_STATUS, perror)) {
+	  irq_warn("Perror for epid:%d\n", epid);
+	  printk("FM_NUMBER: %d\n", reg->r_usb_fm_number & 0x7ff);
+	  printk("R_USB_STATUS: 0x%x\n", reg->r_usb_status);
+	  __dump_urb(urb);
+	  debug_epid(epid);
+
+	  if (!(ept_data & IO_MASK(R_USB_EPT_DATA, valid))) {
+	    /* invalid ep_id */
+	    panic("Perror because of invalid epid."
+		  " Deconfigured too early?");
+	  } else {
+	    /* past eof1, near eof, zout transfer, setup transfer */
+	    /* Dump the urb and the relevant EP descriptor. */
+	    panic("Something wrong with DMA descriptor contents."
+		  " Too much traffic inserted?");
+	  }
+	} else if (reg->r_usb_status & IO_MASK(R_USB_STATUS, ourun)) {
+	  /* buffer ourun */
+	  printk("FM_NUMBER: %d\n", reg->r_usb_fm_number & 0x7ff);
+	  printk("R_USB_STATUS: 0x%x\n", reg->r_usb_status);
+	  __dump_urb(urb);
+	  debug_epid(epid);
+
+	  panic("Buffer overrun/underrun for epid:%d. DMA too busy?", epid);
+	} else {
+	  irq_warn("Attention on epid:%d (%s %s) with no error code\n", epid,
+		   str_dir(urb->pipe), str_type(urb->pipe));
+	  printk("R_USB_STATUS: 0x%x\n", reg->r_usb_status);
+	  __dump_urb(urb);
+	  debug_epid(epid);
+	}
+
+      } else if (error_code == IO_STATE_VALUE(R_USB_EPT_DATA, error_code,
+					      stall)) {
+	/* Not really a protocol error, just says that the endpoint gave
+	   a stall response. Note that error_code cannot be stall for isoc. */
+	if (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {
+	  panic("Isoc traffic cannot stall");
+	}
+
+	tc_dbg("Stall for epid:%d (%s %s) URB:0x%x\n", epid,
+	       str_dir(urb->pipe), str_type(urb->pipe), (unsigned int)urb);
+	tc_finish_urb(hcd, urb, -EPIPE);
+
+      } else if (error_code == IO_STATE_VALUE(R_USB_EPT_DATA, error_code,
+					      bus_error)) {
+	/* Two devices responded to a transaction request. Must be resolved
+	   by software. FIXME: Reset ports? */
+	panic("Bus error for epid %d."
+	      " Two devices responded to transaction request\n",
+	      epid);
+
+      } else if (error_code == IO_STATE_VALUE(R_USB_EPT_DATA, error_code,
+					      buffer_error)) {
+	/* DMA overrun or underrun. */
+	irq_warn("Buffer overrun/underrun for epid:%d (%s %s)\n", epid,
+		 str_dir(urb->pipe), str_type(urb->pipe));
+
+	/* It seems that error_code = buffer_error in
+	   R_USB_EPT_DATA/R_USB_EPT_DATA_ISO and ourun = yes in R_USB_STATUS
+	   are the same error. */
+	tc_finish_urb(hcd, urb, -EPROTO);
+      } else {
+	  irq_warn("Unknown attention on epid:%d (%s %s)\n", epid,
+		   str_dir(urb->pipe), str_type(urb->pipe));
+	  dump_ept_data(epid);
+      }
+    }
+  }
+  DBFEXIT;
+}
+
+void crisv10_hcd_port_status_irq(struct crisv10_irq_reg *reg)
+{
+  __u16 port_reg[USB_ROOT_HUB_PORTS];
+  DBFENTER;
+  port_reg[0] = reg->r_usb_rh_port_status_1;
+  port_reg[1] = reg->r_usb_rh_port_status_2;
+  rh_port_status_change(port_reg);
+  DBFEXIT;
+}
+
+void crisv10_hcd_isoc_eof_irq(struct crisv10_irq_reg *reg)
+{
+  int epid;
+  struct urb *urb;
+  struct crisv10_urb_priv *urb_priv;
+
+  DBFENTER;
+
+  for (epid = 0; epid < NBR_OF_EPIDS - 1; epid++) {
+
+    /* Only check epids that are in use, is valid and has SB list */
+    if (!epid_inuse(epid) || epid == INVALID_EPID ||
+	TxIsocEPList[epid].sub == 0 || epid == DUMMY_EPID) {
+      /* Nothing here to see. */
+      continue;
+    }
+    ASSERT(epid_isoc(epid));
+
+    /* Get the active URB for this epid (if any). */
+    urb = activeUrbList[epid];
+    if (urb == 0) {
+      isoc_warn("Ignoring NULL urb for epid:%d\n", epid);
+      continue;
+    }
+    if(!epid_out_traffic(epid)) {
+      /* Sanity check. */
+      ASSERT(usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS);
+
+      urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+      ASSERT(urb_priv);
+
+      if (urb_priv->urb_state == NOT_STARTED) {
+	/* If ASAP is not set and urb->start_frame is the current frame,
+	   start the transfer. */
+	if (!(urb->transfer_flags & URB_ISO_ASAP) &&
+	    (urb->start_frame == (*R_USB_FM_NUMBER & 0x7ff))) {
+	  /* EP should not be enabled if we're waiting for start_frame */
+	  ASSERT((TxIsocEPList[epid].command &
+		  IO_STATE(USB_EP_command, enable, yes)) == 0);
+
+	  isoc_warn("Enabling isoc IN EP descr for epid %d\n", epid);
+	  TxIsocEPList[epid].command |= IO_STATE(USB_EP_command, enable, yes);
+
+	  /* This urb is now active. */
+	  urb_priv->urb_state = STARTED;
+	  continue;
+	}
+      }
+    }
+  }
+
+  DBFEXIT;
+}
+
+void crisv10_hcd_ctl_status_irq(struct crisv10_irq_reg *reg)
+{
+  struct crisv10_hcd* crisv10_hcd = hcd_to_crisv10_hcd(reg->hcd);
+
+  DBFENTER;
+  ASSERT(crisv10_hcd);
+
+  irq_dbg("ctr_status_irq, controller status: %s\n",
+	  hcd_status_to_str(reg->r_usb_status));
+  
+  /* FIXME: What should we do if we get ourun or perror? Dump the EP and SB
+     list for the corresponding epid? */
+  if (reg->r_usb_status & IO_MASK(R_USB_STATUS, ourun)) {
+    panic("USB controller got ourun.");
+  }
+  if (reg->r_usb_status & IO_MASK(R_USB_STATUS, perror)) {
+    
+    /* Before, etrax_usb_do_intr_recover was called on this epid if it was
+       an interrupt pipe. I don't see how re-enabling all EP descriptors
+       will help if there was a programming error. */
+    panic("USB controller got perror.");
+  }
+
+  /* Keep track of USB Controller, if it's running or not */
+  if(reg->r_usb_status & IO_STATE(R_USB_STATUS, running, yes)) {
+    crisv10_hcd->running = 1;
+  } else {
+    crisv10_hcd->running = 0;
+  }
+  
+  if (reg->r_usb_status & IO_MASK(R_USB_STATUS, device_mode)) {
+    /* We should never operate in device mode. */
+    panic("USB controller in device mode.");
+  }
+
+  /* Set the flag to avoid getting "Unlink after no-IRQ? Controller is probably
+     using the wrong IRQ" from hcd_unlink_urb() in drivers/usb/core/hcd.c */
+  set_bit(HCD_FLAG_SAW_IRQ, &reg->hcd->flags);
+  
+  DBFEXIT;
+}
+
+
+/******************************************************************/
+/* Host Controller interface functions                            */
+/******************************************************************/
+
+static inline void crisv10_ready_wait(void) {
+  volatile int timeout = 10000;
+  /* Check the busy bit of USB controller in Etrax */
+  while((*R_USB_COMMAND & IO_MASK(R_USB_COMMAND, busy)) &&
+	(timeout-- > 0));
+  if(timeout == 0) {
+    warn("Timeout while waiting for USB controller to be idle\n");
+  }
+}
+
+/* reset host controller */
+static int crisv10_hcd_reset(struct usb_hcd *hcd)
+{
+  DBFENTER;
+  hcd_dbg(hcd, "reset\n");
+
+
+  /* Reset the USB interface. */
+  /*
+  *R_USB_COMMAND =
+    IO_STATE(R_USB_COMMAND, port_sel, nop) |
+    IO_STATE(R_USB_COMMAND, port_cmd, reset) |
+    IO_STATE(R_USB_COMMAND, ctrl_cmd, reset);
+  nop();
+  */
+  DBFEXIT;
+  return 0;
+}
+
+/* start host controller */
+static int crisv10_hcd_start(struct usb_hcd *hcd)
+{
+  DBFENTER;
+  hcd_dbg(hcd, "start\n");
+
+  crisv10_ready_wait();
+
+  /* Start processing of USB traffic. */
+  *R_USB_COMMAND =
+    IO_STATE(R_USB_COMMAND, port_sel, nop) |
+    IO_STATE(R_USB_COMMAND, port_cmd, reset) |
+    IO_STATE(R_USB_COMMAND, ctrl_cmd, host_run);
+
+  nop();
+
+  hcd->state = HC_STATE_RUNNING;
+
+  DBFEXIT;
+  return 0;
+}
+
+/* stop host controller */
+static void crisv10_hcd_stop(struct usb_hcd *hcd)
+{
+  DBFENTER;
+  hcd_dbg(hcd, "stop\n");
+  crisv10_hcd_reset(hcd);
+  DBFEXIT;
+}
+
+/* return the current frame number */
+static int crisv10_hcd_get_frame(struct usb_hcd *hcd)
+{
+  DBFENTER;
+  DBFEXIT;
+  return (*R_USB_FM_NUMBER & 0x7ff);
+}
+
+#ifdef	CONFIG_USB_OTG
+
+static int crisv10_hcd_start_port_reset(struct usb_hcd *hcd, unsigned port)
+{
+  return 0; /* no-op for now */
+}
+
+#endif /* CONFIG_USB_OTG */
+
+
+/******************************************************************/
+/* Root Hub functions                                             */
+/******************************************************************/
+
+/* root hub status */
+static const struct usb_hub_status rh_hub_status = 
+  {
+    .wHubStatus =		0,
+    .wHubChange =		0,
+  };
+
+/* root hub descriptor */
+static const u8 rh_hub_descr[] =
+  {
+    0x09,			/* bDescLength	       */
+    0x29,			/* bDescriptorType     */
+    USB_ROOT_HUB_PORTS,         /* bNbrPorts	       */
+    0x00,			/* wHubCharacteristics */
+    0x00,		 
+    0x01,			/* bPwrOn2pwrGood      */
+    0x00,			/* bHubContrCurrent    */
+    0x00,			/* DeviceRemovable     */
+    0xff			/* PortPwrCtrlMask     */
+  };
+
+/* Actual holder of root hub status*/
+struct crisv10_rh rh;
+
+/* Initialize root hub data structures (called from dvdrv_hcd_probe()) */
+int rh_init(void) {
+  int i;
+  /* Reset port status flags */
+  for (i = 0; i < USB_ROOT_HUB_PORTS; i++) {
+    rh.wPortChange[i] = 0;
+    rh.wPortStatusPrev[i] = 0;
+  }
+  return 0;
+}
+
+#define RH_FEAT_MASK ((1<<USB_PORT_FEAT_CONNECTION)|\
+		      (1<<USB_PORT_FEAT_ENABLE)|\
+		      (1<<USB_PORT_FEAT_SUSPEND)|\
+		      (1<<USB_PORT_FEAT_RESET))
+
+/* Handle port status change interrupt (called from bottom part interrupt) */
+void rh_port_status_change(__u16 port_reg[]) {
+  int i;
+  __u16 wChange;
+
+  for(i = 0; i < USB_ROOT_HUB_PORTS; i++) {
+    /* Xor out changes since last read, masked for important flags */
+    wChange = (port_reg[i] & RH_FEAT_MASK) ^ rh.wPortStatusPrev[i];
+    /* Or changes together with (if any) saved changes */
+    rh.wPortChange[i] |= wChange;
+    /* Save new status */
+    rh.wPortStatusPrev[i] = port_reg[i];
+
+    if(wChange) {
+      rh_dbg("Interrupt port_status change port%d: %s  Current-status:%s\n", i+1,
+	     port_status_to_str(wChange),
+	     port_status_to_str(port_reg[i]));
+    }
+  }
+}
+
+/* Construct port status change bitmap for the root hub */
+static int rh_status_data_request(struct usb_hcd *hcd, char *buf)
+{
+  struct crisv10_hcd* crisv10_hcd = hcd_to_crisv10_hcd(hcd);
+  unsigned int i;
+
+//  DBFENTER;
+  
+  /*
+   * corresponds to hub status change EP (USB 2.0 spec section 11.13.4)
+   * return bitmap indicating ports with status change
+   */
+  *buf = 0;
+  spin_lock(&crisv10_hcd->lock);
+  for (i = 1; i <= crisv10_hcd->num_ports; i++) {
+    if (rh.wPortChange[map_port(i)]) {
+      *buf |= (1 << i);
+      rh_dbg("rh_status_data_request, change on port %d: %s  Current Status: %s\n", i,
+	     port_status_to_str(rh.wPortChange[map_port(i)]),
+	     port_status_to_str(rh.wPortStatusPrev[map_port(i)]));
+    }
+  }
+  spin_unlock(&crisv10_hcd->lock);
+
+// DBFEXIT;
+
+  return *buf == 0 ? 0 : 1;
+}
+
+/* Handle a control request for the root hub (called from hcd_driver) */
+static int rh_control_request(struct usb_hcd *hcd, 
+			      u16 typeReq, 
+			      u16 wValue, 
+			      u16 wIndex,
+			      char *buf, 
+			      u16 wLength) {
+
+  struct crisv10_hcd *crisv10_hcd = hcd_to_crisv10_hcd(hcd);
+  int retval = 0;
+  int len;
+  DBFENTER;
+
+  switch (typeReq) {
+  case GetHubDescriptor:
+    rh_dbg("GetHubDescriptor\n");
+    len = min_t(unsigned int, sizeof rh_hub_descr, wLength);
+    memcpy(buf, rh_hub_descr, len);
+    buf[2] = crisv10_hcd->num_ports;
+    break;
+  case GetHubStatus:
+    rh_dbg("GetHubStatus\n");
+    len = min_t(unsigned int, sizeof rh_hub_status, wLength);
+    memcpy(buf, &rh_hub_status, len);
+    break;
+  case GetPortStatus:
+    if (!wIndex || wIndex > crisv10_hcd->num_ports)
+      goto error;
+    rh_dbg("GetportStatus, port:%d change:%s  status:%s\n", wIndex,
+	   port_status_to_str(rh.wPortChange[map_port(wIndex)]),
+	   port_status_to_str(rh.wPortStatusPrev[map_port(wIndex)]));
+    *(u16 *) buf = cpu_to_le16(rh.wPortStatusPrev[map_port(wIndex)]);
+    *(u16 *) (buf + 2) = cpu_to_le16(rh.wPortChange[map_port(wIndex)]);
+    break;
+  case SetHubFeature:
+    rh_dbg("SetHubFeature\n");
+  case ClearHubFeature:
+    rh_dbg("ClearHubFeature\n");
+    switch (wValue) {
+    case C_HUB_OVER_CURRENT:
+    case C_HUB_LOCAL_POWER:
+      rh_warn("Not implemented hub request:%d \n", typeReq);
+      /* not implemented */
+      break;
+    default:
+      goto error;
+    }
+    break;
+  case SetPortFeature:
+    if (!wIndex || wIndex > crisv10_hcd->num_ports)
+      goto error;
+    if(rh_set_port_feature(map_port(wIndex), wValue))
+      goto error;
+    break;
+  case ClearPortFeature:
+    if (!wIndex || wIndex > crisv10_hcd->num_ports)
+      goto error;
+    if(rh_clear_port_feature(map_port(wIndex), wValue))
+      goto error;
+    break;
+  default:
+    rh_warn("Unknown hub request: %d\n", typeReq);
+  error:
+    retval = -EPIPE;
+  }
+  DBFEXIT;
+  return retval;
+}
+
+int rh_set_port_feature(__u8 bPort, __u16 wFeature) {
+  __u8 bUsbCommand = 0;
+  switch(wFeature) {
+  case USB_PORT_FEAT_RESET:
+    rh_dbg("SetPortFeature: reset\n");
+    bUsbCommand |= IO_STATE(R_USB_COMMAND, port_cmd, reset);
+    goto set;
+    break;
+  case USB_PORT_FEAT_SUSPEND:
+    rh_dbg("SetPortFeature: suspend\n");
+    bUsbCommand |= IO_STATE(R_USB_COMMAND, port_cmd, suspend);
+    goto set;
+    break;
+  case USB_PORT_FEAT_POWER:
+    rh_dbg("SetPortFeature: power\n");
+    break;
+  case USB_PORT_FEAT_C_CONNECTION:
+    rh_dbg("SetPortFeature: c_connection\n");
+    break;
+  case USB_PORT_FEAT_C_RESET:
+    rh_dbg("SetPortFeature: c_reset\n");
+    break;
+  case USB_PORT_FEAT_C_OVER_CURRENT:
+    rh_dbg("SetPortFeature: c_over_current\n");
+    break;
+
+  set:
+    /* Select which port via the port_sel field */
+    bUsbCommand |= IO_FIELD(R_USB_COMMAND, port_sel, bPort+1);
+
+    /* Make sure the controller isn't busy. */
+    crisv10_ready_wait();
+    /* Send out the actual command to the USB controller */
+    *R_USB_COMMAND = bUsbCommand;
+
+    /* If port reset then also bring USB controller into running state */
+    if(wFeature == USB_PORT_FEAT_RESET) {
+      /* Wait a while for controller to first become started after port reset */
+      udelay(12000); /* 12ms blocking wait */
+      
+      /* Make sure the controller isn't busy. */
+      crisv10_ready_wait();
+
+      /* If all enabled ports were disabled the host controller goes down into
+	 started mode, so we need to bring it back into the running state.
+	 (This is safe even if it's already in the running state.) */
+      *R_USB_COMMAND =
+	IO_STATE(R_USB_COMMAND, port_sel, nop) |
+	IO_STATE(R_USB_COMMAND, port_cmd, reset) |
+	IO_STATE(R_USB_COMMAND, ctrl_cmd, host_run);
+    }
+
+    break;
+  default:
+    rh_dbg("SetPortFeature: unknown feature\n");
+    return -1;
+  }
+  return 0;
+}
+
+int rh_clear_port_feature(__u8 bPort, __u16 wFeature) {
+  switch(wFeature) {
+  case USB_PORT_FEAT_ENABLE:
+    rh_dbg("ClearPortFeature: enable\n");
+    rh_disable_port(bPort);
+    break;
+  case USB_PORT_FEAT_SUSPEND:
+    rh_dbg("ClearPortFeature: suspend\n");
+    break;
+  case USB_PORT_FEAT_POWER:
+    rh_dbg("ClearPortFeature: power\n");
+    break;
+
+  case USB_PORT_FEAT_C_ENABLE:
+    rh_dbg("ClearPortFeature: c_enable\n");
+    goto clear;
+  case USB_PORT_FEAT_C_SUSPEND:
+    rh_dbg("ClearPortFeature: c_suspend\n");
+    goto clear;
+  case USB_PORT_FEAT_C_CONNECTION:
+    rh_dbg("ClearPortFeature: c_connection\n");
+    goto clear;
+  case USB_PORT_FEAT_C_OVER_CURRENT:
+    rh_dbg("ClearPortFeature: c_over_current\n");
+    goto clear;
+  case USB_PORT_FEAT_C_RESET:
+    rh_dbg("ClearPortFeature: c_reset\n");
+    goto clear;
+  clear:
+    rh.wPortChange[bPort] &= ~(1 << (wFeature - 16));
+    break;
+  default:
+    rh_dbg("ClearPortFeature: unknown feature\n");
+    return -1;
+  }
+  return 0;
+}
+
+
+#ifdef	CONFIG_PM
+/* Handle a suspend request for the root hub (called from hcd_driver) */
+static int rh_suspend_request(struct usb_hcd *hcd)
+{
+  return 0; /* no-op for now */
+}
+
+/* Handle a resume request for the root hub (called from hcd_driver) */
+static int rh_resume_request(struct usb_hcd *hcd)
+{
+  return 0; /* no-op for now */
+}
+#endif /* CONFIG_PM */
+
+
+
+/* Wrapper function for workaround port disable registers in USB controller  */
+static void rh_disable_port(unsigned int port) {
+  volatile int timeout = 10000;
+  volatile char* usb_portx_disable;
+  switch(port) {
+  case 0:
+    usb_portx_disable = R_USB_PORT1_DISABLE;
+    break;
+  case 1:
+    usb_portx_disable = R_USB_PORT2_DISABLE;
+    break;
+  default:
+    /* Invalid port index */
+    return;
+  }
+  /* Set disable flag in special register  */
+  *usb_portx_disable = IO_STATE(R_USB_PORT1_DISABLE, disable, yes);
+  /* Wait until not enabled anymore */
+  while((rh.wPortStatusPrev[port] &
+	IO_STATE(R_USB_RH_PORT_STATUS_1, enabled, yes)) &&
+	(timeout-- > 0));
+  if(timeout == 0) {
+    warn("Timeout while waiting for port %d to become disabled\n", port);
+  }
+  /* clear disable flag in special register  */
+  *usb_portx_disable = IO_STATE(R_USB_PORT1_DISABLE, disable, no);
+  rh_info("Physical port %d disabled\n", port+1);
+}
+
+
+/******************************************************************/
+/* Transfer Controller (TC) functions                             */
+/******************************************************************/
+
+/* FIXME: Should RX_BUF_SIZE be a config option, or maybe we should adjust it
+   dynamically?
+   To adjust it dynamically we would have to get an interrupt when we reach
+   the end of the rx descriptor list, or when we get close to the end, and
+   then allocate more descriptors. */
+#define NBR_OF_RX_DESC     512
+#define RX_DESC_BUF_SIZE   1024
+#define RX_BUF_SIZE        (NBR_OF_RX_DESC * RX_DESC_BUF_SIZE)
+
+
+/* Local variables for Transfer Controller */
+/* --------------------------------------- */
+
+/* This is a circular (double-linked) list of the active urbs for each epid.
+   The head is never removed, and new urbs are linked onto the list as
+   urb_entry_t elements. Don't reference urb_list directly; use the wrapper
+   functions instead (which includes spin_locks) */
+static struct list_head urb_list[NBR_OF_EPIDS];
+
+/* Read about the need and usage of this lock in submit_ctrl_urb. */
+/* Lock for URB lists for each EPID */
+static spinlock_t urb_list_lock;
+
+/* Lock for EPID array register (R_USB_EPT_x) in Etrax */
+static spinlock_t etrax_epid_lock;
+
+/* Lock for dma8 sub0 handling */
+static spinlock_t etrax_dma8_sub0_lock;
+
+/* DMA IN cache bug. Align the DMA IN buffers to 32 bytes, i.e. a cache line.
+   Since RX_DESC_BUF_SIZE is 1024 is a multiple of 32, all rx buffers will be
+   cache aligned. */
+static volatile unsigned char RxBuf[RX_BUF_SIZE] __attribute__ ((aligned (32)));
+static volatile struct USB_IN_Desc RxDescList[NBR_OF_RX_DESC] __attribute__ ((aligned (4)));
+
+/* Pointers into RxDescList. */
+static volatile struct USB_IN_Desc *myNextRxDesc;
+static volatile struct USB_IN_Desc *myLastRxDesc;
+
+/* A zout transfer makes a memory access at the address of its buf pointer,
+   which means that setting this buf pointer to 0 will cause an access to the
+   flash. In addition to this, setting sw_len to 0 results in a 16/32 bytes
+   (depending on DMA burst size) transfer.
+   Instead, we set it to 1, and point it to this buffer. */
+static int zout_buffer[4] __attribute__ ((aligned (4)));
+
+/* Cache for allocating new EP and SB descriptors. */
+//static kmem_cache_t *usb_desc_cache;
+static struct kmem_cache *usb_desc_cache;
+
+/* Cache for the data allocated in the isoc descr top half. */
+//static kmem_cache_t *isoc_compl_cache;
+static struct kmem_cache *isoc_compl_cache;
+
+/* Cache for the data allocated when delayed finishing of URBs */
+//static kmem_cache_t *later_data_cache;
+static struct kmem_cache *later_data_cache;
+
+/* Counter to keep track of how many Isoc EP we have sat up. Used to enable
+   and disable iso_eof interrupt. We only need these interrupts when we have
+   Isoc data endpoints (consumes CPU cycles).
+   FIXME: This could be more fine granular, so this interrupt is only enabled
+   when we have a In Isoc URB not URB_ISO_ASAP flaged queued. */
+static int isoc_epid_counter;
+
+/* Protecting wrapper functions for R_USB_EPT_x */
+/* -------------------------------------------- */
+static inline void etrax_epid_set(__u8 index, __u32 data) {
+  unsigned long flags;
+  spin_lock_irqsave(&etrax_epid_lock, flags);
+  *R_USB_EPT_INDEX = IO_FIELD(R_USB_EPT_INDEX, value, index);
+  nop();
+  *R_USB_EPT_DATA = data;
+  spin_unlock_irqrestore(&etrax_epid_lock, flags);
+}
+
+static inline void etrax_epid_clear_error(__u8 index) {
+  unsigned long flags;
+  spin_lock_irqsave(&etrax_epid_lock, flags);
+  *R_USB_EPT_INDEX = IO_FIELD(R_USB_EPT_INDEX, value, index);
+  nop();
+  *R_USB_EPT_DATA &=
+    ~(IO_MASK(R_USB_EPT_DATA, error_count_in) |
+      IO_MASK(R_USB_EPT_DATA, error_count_out) |
+      IO_MASK(R_USB_EPT_DATA, error_code));
+  spin_unlock_irqrestore(&etrax_epid_lock, flags);
+}
+
+static inline void etrax_epid_set_toggle(__u8 index, __u8 dirout,
+                                             __u8 toggle) {
+  unsigned long flags;
+  spin_lock_irqsave(&etrax_epid_lock, flags);
+  *R_USB_EPT_INDEX = IO_FIELD(R_USB_EPT_INDEX, value, index);
+  nop();
+  if(dirout) {
+    *R_USB_EPT_DATA &= ~IO_MASK(R_USB_EPT_DATA, t_out);
+    *R_USB_EPT_DATA |= IO_FIELD(R_USB_EPT_DATA, t_out, toggle);
+  } else {
+    *R_USB_EPT_DATA &= ~IO_MASK(R_USB_EPT_DATA, t_in);
+    *R_USB_EPT_DATA |= IO_FIELD(R_USB_EPT_DATA, t_in, toggle);
+  }
+  spin_unlock_irqrestore(&etrax_epid_lock, flags);
+}
+
+static inline __u8 etrax_epid_get_toggle(__u8 index, __u8 dirout) {
+  unsigned long flags;
+  __u8 toggle;
+  spin_lock_irqsave(&etrax_epid_lock, flags);
+  *R_USB_EPT_INDEX = IO_FIELD(R_USB_EPT_INDEX, value, index);
+  nop();
+  if (dirout) {
+    toggle = IO_EXTRACT(R_USB_EPT_DATA, t_out, *R_USB_EPT_DATA);
+  } else {
+    toggle = IO_EXTRACT(R_USB_EPT_DATA, t_in, *R_USB_EPT_DATA);
+  }
+  spin_unlock_irqrestore(&etrax_epid_lock, flags);
+  return toggle;
+}
+
+
+static inline __u32 etrax_epid_get(__u8 index) {
+  unsigned long flags;
+  __u32 data;
+  spin_lock_irqsave(&etrax_epid_lock, flags);
+  *R_USB_EPT_INDEX = IO_FIELD(R_USB_EPT_INDEX, value, index);
+  nop();
+  data = *R_USB_EPT_DATA;
+  spin_unlock_irqrestore(&etrax_epid_lock, flags);
+  return data;
+}
+
+
+
+
+/* Main functions for Transfer Controller */
+/* -------------------------------------- */
+
+/* Init structs, memories and lists used by Transfer Controller */
+int tc_init(struct usb_hcd *hcd) {
+  int i;
+  /* Clear software state info for all epids */
+  memset(epid_state, 0, sizeof(struct etrax_epid) * NBR_OF_EPIDS);
+
+  /* Set Invalid and Dummy as being in use and disabled */
+  epid_state[INVALID_EPID].inuse = 1;
+  epid_state[DUMMY_EPID].inuse = 1;
+  epid_state[INVALID_EPID].disabled = 1;
+  epid_state[DUMMY_EPID].disabled = 1;
+
+  /* Clear counter for how many Isoc epids we have sat up */
+  isoc_epid_counter = 0;
+
+  /* Initialize the urb list by initiating a head for each list.
+     Also reset list hodling active URB for each epid */
+  for (i = 0; i < NBR_OF_EPIDS; i++) {
+    INIT_LIST_HEAD(&urb_list[i]);
+    activeUrbList[i] = NULL;
+  }
+
+  /* Init lock for URB lists */
+  spin_lock_init(&urb_list_lock);
+  /* Init lock for Etrax R_USB_EPT register */
+  spin_lock_init(&etrax_epid_lock);
+  /* Init lock for Etrax dma8 sub0 handling */
+  spin_lock_init(&etrax_dma8_sub0_lock);
+
+  /* We use kmem_cache_* to make sure that all DMA desc. are dword aligned */
+
+  /* Note that we specify sizeof(struct USB_EP_Desc) as the size, but also
+     allocate SB descriptors from this cache. This is ok since
+     sizeof(struct USB_EP_Desc) == sizeof(struct USB_SB_Desc). */
+//  usb_desc_cache = kmem_cache_create("usb_desc_cache",
+//				     sizeof(struct USB_EP_Desc), 0,
+//				     SLAB_HWCACHE_ALIGN, 0, 0);
+  usb_desc_cache = kmem_cache_create(
+				  "usb_desc_cache",
+				  sizeof(struct USB_EP_Desc),
+				  0,
+				  SLAB_HWCACHE_ALIGN,
+				  NULL);
+  if(usb_desc_cache == NULL) {
+    return -ENOMEM;
+  }
+
+  /* Create slab cache for speedy allocation of memory for isoc bottom-half
+     interrupt handling */
+//  isoc_compl_cache =
+//    kmem_cache_create("isoc_compl_cache",
+//		      sizeof(struct crisv10_isoc_complete_data),
+//		      0, SLAB_HWCACHE_ALIGN, 0, 0);
+  isoc_compl_cache = kmem_cache_create(
+				  "isoc_compl_cache",
+				  sizeof(struct crisv10_isoc_complete_data),
+				  0,
+				  SLAB_HWCACHE_ALIGN,
+				  NULL
+				  );
+
+  if(isoc_compl_cache == NULL) {
+    return -ENOMEM;
+  }
+
+  /* Create slab cache for speedy allocation of memory for later URB finish
+     struct */
+//  later_data_cache =
+//    kmem_cache_create("later_data_cache",
+//		      sizeof(struct urb_later_data),
+//		      0, SLAB_HWCACHE_ALIGN, 0, 0);
+
+  later_data_cache = kmem_cache_create(
+				  "later_data_cache",
+				  sizeof(struct urb_later_data),
+				  0,
+				  SLAB_HWCACHE_ALIGN,
+				  NULL
+				  );
+  
+  if(later_data_cache == NULL) {
+    return -ENOMEM;
+  }
+
+
+  /* Initiate the bulk start timer. */
+  init_timer(&bulk_start_timer);
+  bulk_start_timer.expires = jiffies + BULK_START_TIMER_INTERVAL;
+  bulk_start_timer.function = tc_bulk_start_timer_func;
+  add_timer(&bulk_start_timer);
+
+
+  /* Initiate the bulk eot timer. */
+  init_timer(&bulk_eot_timer);
+  bulk_eot_timer.expires = jiffies + BULK_EOT_TIMER_INTERVAL;
+  bulk_eot_timer.function = tc_bulk_eot_timer_func;
+  bulk_eot_timer.data = (unsigned long)hcd;
+  add_timer(&bulk_eot_timer);
+
+  return 0;
+}
+
+/* Uninitialize all resources used by Transfer Controller */
+void tc_destroy(void) {
+
+  /* Destroy all slab cache */
+  kmem_cache_destroy(usb_desc_cache);
+  kmem_cache_destroy(isoc_compl_cache);
+  kmem_cache_destroy(later_data_cache);
+
+  /* Remove timers */
+  del_timer(&bulk_start_timer);
+  del_timer(&bulk_eot_timer);
+}
+
+static void restart_dma8_sub0(void) {
+  unsigned long flags;
+  spin_lock_irqsave(&etrax_dma8_sub0_lock, flags);
+  /* Verify that the dma is not running */
+  if ((*R_DMA_CH8_SUB0_CMD & IO_MASK(R_DMA_CH8_SUB0_CMD, cmd)) == 0) {
+    struct USB_EP_Desc *ep = (struct USB_EP_Desc *)phys_to_virt(*R_DMA_CH8_SUB0_EP);
+    while (DUMMY_EPID == IO_EXTRACT(USB_EP_command, epid, ep->command)) {
+      ep = (struct USB_EP_Desc *)phys_to_virt(ep->next);
+    }
+    /* Advance the DMA to the next EP descriptor that is not a DUMMY_EPID.
+	 * ep->next is already a physical address. virt_to_phys is needed, see
+	 * http://mhonarc.axis.se/dev-etrax/msg08630.html
+	 */
+    //*R_DMA_CH8_SUB0_EP = ep->next;
+	*R_DMA_CH8_SUB0_EP = virt_to_phys(ep);
+    /* Restart the DMA */
+    *R_DMA_CH8_SUB0_CMD = IO_STATE(R_DMA_CH8_SUB0_CMD, cmd, start);
+  }
+  spin_unlock_irqrestore(&etrax_dma8_sub0_lock, flags);
+}
+
+/* queue an URB with the transfer controller (called from hcd_driver) */
+//static int tc_urb_enqueue(struct usb_hcd *hcd, 
+//			  struct usb_host_endpoint *ep,
+//			  struct urb *urb, 
+//			  gfp_t mem_flags) {
+static int tc_urb_enqueue(struct usb_hcd *hcd, struct urb *urb, gfp_t mem_flags)
+{
+  int epid;
+  int retval;
+//  int bustime = 0;
+  int maxpacket;
+  unsigned long flags;
+  struct crisv10_urb_priv *urb_priv;
+  struct crisv10_hcd* crisv10_hcd = hcd_to_crisv10_hcd(hcd);
+  DBFENTER;
+
+  if(!(crisv10_hcd->running)) {
+    /* The USB Controller is not running, probably because no device is 
+       attached. No idea to enqueue URBs then */
+    tc_warn("Rejected enqueueing of URB:0x%x because no dev attached\n",
+	    (unsigned int)urb);
+    return -ENOENT;
+  }
+
+  maxpacket = usb_maxpacket(urb->dev, urb->pipe, usb_pipeout(urb->pipe));
+  
+  /* hinko ignore usb_pipeisoc */
+#if 0
+  /* Special case check for In Isoc transfers. Specification states that each
+     In Isoc transfer consists of one packet and therefore it should fit into
+     the transfer-buffer of an URB.
+     We do the check here to be sure (an invalid scenario can be produced with
+     parameters to the usbtest suite) */
+  if(usb_pipeisoc(urb->pipe) && usb_pipein(urb->pipe) &&
+     (urb->transfer_buffer_length < maxpacket)) {
+    tc_err("Submit In Isoc URB with buffer length:%d to pipe with maxpacketlen: %d\n", urb->transfer_buffer_length, maxpacket);
+    return -EMSGSIZE;
+  }
+
+  /* Check if there is enough bandwidth for periodic transfer  */
+  if(usb_pipeint(urb->pipe) || usb_pipeisoc(urb->pipe)) {
+    /* only check (and later claim) if not already claimed */
+    if (urb->bandwidth == 0) {
+      bustime = usb_check_bandwidth(urb->dev, urb);
+      if (bustime < 0) {
+	tc_err("Not enough periodic bandwidth\n");
+	return -ENOSPC;
+      }
+    }
+  }
+#endif
+  
+  /* Check if there is a epid for URBs destination, if not this function
+     set up one. */
+  //epid = tc_setup_epid(ep, urb, mem_flags);
+  epid = tc_setup_epid(urb, mem_flags);
+  if (epid < 0) {
+    tc_err("Failed setup epid:%d for URB:0x%x\n", epid, (unsigned int)urb);
+    DBFEXIT;
+    return -ENOMEM;
+  }
+
+  if(urb == activeUrbList[epid]) {
+    tc_err("Resubmition of allready active URB:0x%x\n", (unsigned int)urb);
+    return -ENXIO;
+  }
+
+  if(urb_list_entry(urb, epid)) {
+    tc_err("Resubmition of allready queued URB:0x%x\n", (unsigned int)urb);
+    return -ENXIO;
+  }
+
+  /* If we actively have flaged endpoint as disabled then refuse submition */
+  if(epid_state[epid].disabled) {
+    return -ENOENT;
+  }
+
+  /* Allocate and init HC-private data for URB */
+  if(urb_priv_create(hcd, urb, epid, mem_flags) != 0) {
+    DBFEXIT;
+    return -ENOMEM;
+  }
+  urb_priv = urb->hcpriv;
+
+  tc_dbg("Enqueue URB:0x%x[%d] epid:%d (%s) bufflen:%d\n",
+	 (unsigned int)urb, urb_priv->urb_num, epid,
+	 pipe_to_str(urb->pipe), urb->transfer_buffer_length);
+
+  /* Create and link SBs required for this URB */
+  retval = create_sb_for_urb(urb, mem_flags);
+  if(retval != 0) {
+    tc_err("Failed to create SBs for URB:0x%x[%d]\n", (unsigned int)urb,
+	   urb_priv->urb_num);
+    urb_priv_free(hcd, urb);
+    DBFEXIT;
+    return retval;
+  }
+
+  /* Init intr EP pool if this URB is a INTR transfer. This pool is later
+     used when inserting EPs in the TxIntrEPList. We do the alloc here
+     so we can't run out of memory later */
+  if(usb_pipeint(urb->pipe)) {
+    retval = init_intr_urb(urb, mem_flags);
+    if(retval != 0) {
+      tc_warn("Failed to init Intr URB\n");
+      urb_priv_free(hcd, urb);
+      DBFEXIT;
+      return retval;
+    }
+  }
+
+  /* Disable other access when inserting USB */
+
+  /* BUG on sleeping inside int disabled if using local_irq_save/local_irq_restore
+   * her - because urb_list_add() and tc_dma_process_queue() save irqs again !??!
+   */
+//  local_irq_save(flags);
+
+  /* hinko ignore usb_pipeisoc */
+#if 0
+  /* Claim bandwidth, if needed */
+  if(bustime) {
+    usb_claim_bandwidth(urb->dev, urb, bustime, 0);
+  }
+  
+  /* Add URB to EP queue */
+  urb_list_add(urb, epid, mem_flags);
+
+  if(usb_pipeisoc(urb->pipe)) {
+    /* Special processing of Isoc URBs. */
+    tc_dma_process_isoc_urb(urb);
+  } else {
+    /* Process EP queue for rest of the URB types (Bulk, Ctrl, Intr) */
+    tc_dma_process_queue(epid);
+  }
+#endif
+  /* Add URB to EP queue */
+  urb_list_add(urb, epid, mem_flags);
+
+  /*hinko link/unlink urb -> ep */
+  spin_lock_irqsave(&crisv10_hcd->lock, flags);
+  //spin_lock(&crisv10_hcd->lock);
+  retval = usb_hcd_link_urb_to_ep(hcd, urb);
+  if (retval) {
+    spin_unlock_irqrestore(&crisv10_hcd->lock, flags);
+    tc_warn("Failed to link urb to ep\n");
+    urb_priv_free(hcd, urb);
+    DBFEXIT;
+    return retval;
+  }
+  spin_unlock_irqrestore(&crisv10_hcd->lock, flags);
+  //spin_unlock(&crisv10_hcd->lock);
+  
+  /* Process EP queue for rest of the URB types (Bulk, Ctrl, Intr) */
+  tc_dma_process_queue(epid);
+
+//  local_irq_restore(flags);
+
+  DBFEXIT;
+  return 0;
+}
+
+/* remove an URB from the transfer controller queues (called from hcd_driver)*/
+//static int tc_urb_dequeue(struct usb_hcd *hcd, struct urb *urb)
+static int tc_urb_dequeue(struct usb_hcd *hcd, struct urb *urb, int status)
+{
+  struct crisv10_urb_priv *urb_priv;
+  unsigned long flags;
+  int epid;
+
+  DBFENTER;
+  /* Disable interrupts here since a descriptor interrupt for the isoc epid
+     will modify the sb list.  This could possibly be done more granular, but
+     urb_dequeue should not be used frequently anyway.
+  */
+  local_irq_save(flags);
+
+  urb_priv = urb->hcpriv;
+
+  if (!urb_priv) {
+    /* This happens if a device driver calls unlink on an urb that
+       was never submitted (lazy driver) or if the urb was completed
+       while dequeue was being called. */
+    tc_warn("Dequeing of not enqueued URB:0x%x\n", (unsigned int)urb);
+    local_irq_restore(flags);
+    return 0;
+  }
+  epid = urb_priv->epid;
+
+  tc_warn("Dequeing %s URB:0x%x[%d] (%s %s epid:%d) status:%d %s\n",
+	  (urb == activeUrbList[epid]) ? "active" : "queued",
+	  (unsigned int)urb, urb_priv->urb_num, str_dir(urb->pipe),
+	  str_type(urb->pipe), epid, urb->status,
+	  (urb_priv->later_data) ? "later-sched" : "");
+
+  /* For Bulk, Ctrl and Intr are only one URB active at a time. So any URB
+     that isn't active can be dequeued by just removing it from the queue */
+  if(usb_pipebulk(urb->pipe) || usb_pipecontrol(urb->pipe) ||
+     usb_pipeint(urb->pipe)) {
+
+    /* Check if URB haven't gone further than the queue */
+    if(urb != activeUrbList[epid]) {
+      ASSERT(urb_priv->later_data == NULL);
+      tc_warn("Dequeing URB:0x%x[%d] (%s %s epid:%d) from queue"
+	      " (not active)\n", (unsigned int)urb, urb_priv->urb_num,
+	      str_dir(urb->pipe), str_type(urb->pipe), epid);
+      
+      /* Finish the URB with error status from USB core */
+      tc_finish_urb(hcd, urb, urb->status);
+      local_irq_restore(flags);
+      return 0;
+    }
+  }
+
+  /* Set URB status to Unlink for handling when interrupt comes. */
+  urb_priv->urb_state = UNLINK;
+
+  /* Differentiate dequeing of Bulk and Ctrl from Isoc and Intr */
+  switch(usb_pipetype(urb->pipe)) {
+  case PIPE_BULK:
+    /* Check if EP still is enabled */
+    if (TxBulkEPList[epid].command & IO_MASK(USB_EP_command, enable)) {
+      /* The EP was enabled, disable it. */
+      TxBulkEPList[epid].command &= ~IO_MASK(USB_EP_command, enable);
+    }
+    /* Kicking dummy list out of the party. */
+    TxBulkEPList[epid].next = virt_to_phys(&TxBulkEPList[(epid + 1) % NBR_OF_EPIDS]);
+    break;
+  case PIPE_CONTROL:
+    /* Check if EP still is enabled */
+    if (TxCtrlEPList[epid].command & IO_MASK(USB_EP_command, enable)) {
+      /* The EP was enabled, disable it. */
+      TxCtrlEPList[epid].command &= ~IO_MASK(USB_EP_command, enable);
+    }
+    break;
+  case PIPE_ISOCHRONOUS:
+    /* Disabling, busy-wait and unlinking of Isoc SBs will be done in
+       finish_isoc_urb(). Because there might the case when URB is dequeued
+       but there are other valid URBs waiting */
+
+    /* Check if In Isoc EP still is enabled */
+    if (TxIsocEPList[epid].command & IO_MASK(USB_EP_command, enable)) {
+      /* The EP was enabled, disable it. */
+      TxIsocEPList[epid].command &= ~IO_MASK(USB_EP_command, enable);
+    }
+    break;
+  case PIPE_INTERRUPT:
+    /* Special care is taken for interrupt URBs. EPs are unlinked in
+       tc_finish_urb */
+    break;
+  default:
+    break;
+  }
+
+  /* Asynchronous unlink, finish the URB later from scheduled or other
+     event (data finished, error) */
+  tc_finish_urb_later(hcd, urb, urb->status);
+
+  local_irq_restore(flags);
+  DBFEXIT;
+  return 0;
+}
+
+
+static void tc_sync_finish_epid(struct usb_hcd *hcd, int epid) {
+  volatile int timeout = 10000;
+  struct urb* urb;
+  struct crisv10_urb_priv* urb_priv;
+  unsigned long flags;
+  
+  volatile struct USB_EP_Desc *first_ep;  /* First EP in the list. */
+  volatile struct USB_EP_Desc *curr_ep;   /* Current EP, the iterator. */
+  volatile struct USB_EP_Desc *next_ep;   /* The EP after current. */
+
+  int type = epid_state[epid].type;
+
+  /* Setting this flag will cause enqueue() to return -ENOENT for new
+     submitions on this endpoint and finish_urb() wont process queue further */
+  epid_state[epid].disabled = 1;
+
+  switch(type) {
+  case PIPE_BULK:
+    /* Check if EP still is enabled */
+    if (TxBulkEPList[epid].command & IO_MASK(USB_EP_command, enable)) {
+      /* The EP was enabled, disable it. */
+      TxBulkEPList[epid].command &= ~IO_MASK(USB_EP_command, enable);
+      tc_warn("sync_finish: Disabling EP for epid:%d\n", epid);
+
+      /* Do busy-wait until DMA not using this EP descriptor anymore */
+      while((*R_DMA_CH8_SUB0_EP ==
+	     virt_to_phys(&TxBulkEPList[epid])) &&
+	    (timeout-- > 0));
+      if(timeout == 0) {
+	warn("Timeout while waiting for DMA-TX-Bulk to leave EP for"
+	     " epid:%d\n", epid);
+      }
+    }
+    break;
+
+  case PIPE_CONTROL:
+    /* Check if EP still is enabled */
+    if (TxCtrlEPList[epid].command & IO_MASK(USB_EP_command, enable)) {
+      /* The EP was enabled, disable it. */
+      TxCtrlEPList[epid].command &= ~IO_MASK(USB_EP_command, enable);
+      tc_warn("sync_finish: Disabling EP for epid:%d\n", epid);
+
+      /* Do busy-wait until DMA not using this EP descriptor anymore */
+      while((*R_DMA_CH8_SUB1_EP ==
+	     virt_to_phys(&TxCtrlEPList[epid])) &&
+	    (timeout-- > 0));
+      if(timeout == 0) {
+	warn("Timeout while waiting for DMA-TX-Ctrl to leave EP for"
+	     " epid:%d\n", epid);
+      }
+    }
+    break;
+
+  case PIPE_INTERRUPT:
+    local_irq_save(flags);
+    /* Disable all Intr EPs belonging to epid */
+    first_ep = &TxIntrEPList[0];
+    curr_ep = first_ep;
+    do {
+      next_ep = (struct USB_EP_Desc *)phys_to_virt(curr_ep->next);
+      if (IO_EXTRACT(USB_EP_command, epid, next_ep->command) == epid) {
+	/* Disable EP */
+	next_ep->command &= ~IO_MASK(USB_EP_command, enable);
+      }
+      curr_ep = phys_to_virt(curr_ep->next);
+    } while (curr_ep != first_ep);
+
+    local_irq_restore(flags);
+    break;
+
+  case PIPE_ISOCHRONOUS:
+    /* Check if EP still is enabled */
+    if (TxIsocEPList[epid].command & IO_MASK(USB_EP_command, enable)) {
+      tc_warn("sync_finish: Disabling Isoc EP for epid:%d\n", epid);
+      /* The EP was enabled, disable it. */
+      TxIsocEPList[epid].command &= ~IO_MASK(USB_EP_command, enable);
+      
+      while((*R_DMA_CH8_SUB3_EP == virt_to_phys(&TxIsocEPList[epid])) &&
+	    (timeout-- > 0));
+      if(timeout == 0) {
+	warn("Timeout while waiting for DMA-TX-Isoc to leave EP for"
+	     " epid:%d\n", epid);
+      }
+    }
+    break;
+  }
+
+  local_irq_save(flags);
+
+  /* Finish if there is active URB for this endpoint */
+  if(activeUrbList[epid] != NULL) {
+    urb = activeUrbList[epid];
+    urb_priv = urb->hcpriv;
+    ASSERT(urb_priv);
+    tc_warn("Sync finish %s URB:0x%x[%d] (%s %s epid:%d) status:%d %s\n",
+	    (urb == activeUrbList[epid]) ? "active" : "queued",
+	    (unsigned int)urb, urb_priv->urb_num, str_dir(urb->pipe),
+	    str_type(urb->pipe), epid, urb->status,
+	    (urb_priv->later_data) ? "later-sched" : "");
+
+    tc_finish_urb(hcd, activeUrbList[epid], -ENOENT);
+    ASSERT(activeUrbList[epid] == NULL);
+  }
+
+  /* Finish any queued URBs for this endpoint. There won't be any resubmitions
+     because epid_disabled causes enqueue() to fail for this endpoint */
+  while((urb = urb_list_first(epid)) != NULL) {
+    urb_priv = urb->hcpriv;
+    ASSERT(urb_priv);
+
+    tc_warn("Sync finish %s URB:0x%x[%d] (%s %s epid:%d) status:%d %s\n",
+	    (urb == activeUrbList[epid]) ? "active" : "queued",
+	    (unsigned int)urb, urb_priv->urb_num, str_dir(urb->pipe),
+	    str_type(urb->pipe), epid, urb->status,
+	    (urb_priv->later_data) ? "later-sched" : "");
+
+    tc_finish_urb(hcd, urb, -ENOENT);
+  }
+  epid_state[epid].disabled = 0;
+  local_irq_restore(flags);
+}
+
+/* free resources associated with an endpoint (called from hcd_driver) */
+static void tc_endpoint_disable(struct usb_hcd *hcd, 
+				struct usb_host_endpoint *ep) {
+  DBFENTER;
+  /* Only free epid if it has been allocated. We get two endpoint_disable
+     requests for ctrl endpoints so ignore the second one */
+  if(ep->hcpriv != NULL) {
+    struct crisv10_ep_priv *ep_priv = ep->hcpriv;
+    int epid = ep_priv->epid;
+    tc_warn("endpoint_disable ep:0x%x ep-priv:0x%x (%s) (epid:%d freed)\n",
+	   (unsigned int)ep, (unsigned int)ep->hcpriv,
+	   endpoint_to_str(&(ep->desc)), epid);
+
+    tc_sync_finish_epid(hcd, epid);
+
+    ASSERT(activeUrbList[epid] == NULL);
+    ASSERT(list_empty(&urb_list[epid]));
+
+    tc_free_epid(ep);
+  } else {
+    tc_dbg("endpoint_disable ep:0x%x ep-priv:0x%x (%s)\n", (unsigned int)ep,
+	   (unsigned int)ep->hcpriv, endpoint_to_str(&(ep->desc)));
+  }
+  DBFEXIT;
+}
+
+//static void tc_finish_urb_later_proc(void *data) {
+static void tc_finish_urb_later_proc(struct work_struct *work) {
+  unsigned long flags;
+  //struct urb_later_data* uld = (struct urb_later_data*)data;
+  struct urb_later_data* uld = container_of(work, struct urb_later_data, ws.work);
+  local_irq_save(flags);
+  if(uld->urb == NULL) {
+    late_dbg("Later finish of URB = NULL (allready finished)\n");
+  } else {
+    struct crisv10_urb_priv* urb_priv = uld->urb->hcpriv;
+    ASSERT(urb_priv);
+    if(urb_priv->urb_num == uld->urb_num) {
+      late_dbg("Later finish of URB:0x%x[%d]\n", (unsigned int)(uld->urb),
+	       urb_priv->urb_num);
+      if(uld->status != uld->urb->status) {
+	errno_dbg("Later-finish URB with status:%d, later-status:%d\n",
+		  uld->urb->status, uld->status);
+      }
+      if(uld != urb_priv->later_data) {
+	panic("Scheduled uld not same as URBs uld\n");
+      }
+      tc_finish_urb(uld->hcd, uld->urb, uld->status);
+    } else {
+      late_warn("Ignoring later finish of URB:0x%x[%d]"
+		", urb_num doesn't match current URB:0x%x[%d]",
+		(unsigned int)(uld->urb), uld->urb_num,
+		(unsigned int)(uld->urb), urb_priv->urb_num);
+    }
+  }
+  local_irq_restore(flags);
+  kmem_cache_free(later_data_cache, uld);
+}
+
+static void tc_finish_urb_later(struct usb_hcd *hcd, struct urb *urb,
+				int status) {
+  struct crisv10_urb_priv *urb_priv = urb->hcpriv;
+  struct urb_later_data* uld;
+
+  ASSERT(urb_priv);
+
+  if(urb_priv->later_data != NULL) {
+    /* Later-finish allready scheduled for this URB, just update status to
+       return when finishing later */
+    errno_dbg("Later-finish schedule change URB status:%d with new"
+	      " status:%d\n", urb_priv->later_data->status, status);
+    
+    urb_priv->later_data->status = status;
+    return;
+  }
+
+  uld = kmem_cache_alloc(later_data_cache, GFP_ATOMIC);
+  ASSERT(uld);
+
+  uld->hcd = hcd;
+  uld->urb = urb;
+  uld->urb_num = urb_priv->urb_num;
+  uld->status = status;
+
+  //INIT_WORK(&uld->ws, tc_finish_urb_later_proc, uld);
+  INIT_DELAYED_WORK(&uld->ws, tc_finish_urb_later_proc);
+  urb_priv->later_data = uld;
+
+  /* Schedule the finishing of the URB to happen later */
+  schedule_delayed_work(&uld->ws, LATER_TIMER_DELAY);
+}
+
+  /* hinko ignore usb_pipeisoc */
+#if 0
+static void tc_finish_isoc_urb(struct usb_hcd *hcd, struct urb *urb,
+			       int status);
+#endif
+
+static void tc_finish_urb(struct usb_hcd *hcd, struct urb *urb, int status) {
+  struct crisv10_hcd* crisv10_hcd = hcd_to_crisv10_hcd(hcd);
+  struct crisv10_urb_priv *urb_priv = urb->hcpriv;
+  int epid;
+  char toggle;
+  int urb_num;
+  unsigned long flags;
+
+  DBFENTER;
+  ASSERT(urb_priv != NULL);
+  epid = urb_priv->epid;
+  urb_num = urb_priv->urb_num;
+
+  if(urb != activeUrbList[epid]) {
+    if(urb_list_entry(urb, epid)) {
+      /* Remove this URB from the list. Only happens when URB are finished
+	 before having been processed (dequeing) */
+      urb_list_del(urb, epid);
+    } else {
+      tc_warn("Finishing of URB:0x%x[%d] neither active or in queue for"
+	      " epid:%d\n", (unsigned int)urb, urb_num, epid);
+    }
+  }
+
+  /* Cancel any pending later-finish of this URB */
+  if(urb_priv->later_data) {
+    urb_priv->later_data->urb = NULL;
+  }
+
+  /* For an IN pipe, we always set the actual length, regardless of whether
+     there was an error or not (which means the device driver can use the data
+     if it wants to). */
+  if(usb_pipein(urb->pipe)) {
+    urb->actual_length = urb_priv->rx_offset;
+  } else {
+    /* Set actual_length for OUT urbs also; the USB mass storage driver seems
+       to want that. */
+    if (status == 0 && urb->status == -EINPROGRESS) {
+      urb->actual_length = urb->transfer_buffer_length;
+    } else {
+      /*  We wouldn't know of any partial writes if there was an error. */
+      urb->actual_length = 0;
+    }
+  }
+
+
+  /* URB status mangling */
+  if(urb->status == -EINPROGRESS) {
+    /* The USB core hasn't changed the status, let's set our finish status */
+    urb->status = status;
+
+    if ((status == 0) && (urb->transfer_flags & URB_SHORT_NOT_OK) &&
+	usb_pipein(urb->pipe) &&
+	(urb->actual_length != urb->transfer_buffer_length)) {
+      /* URB_SHORT_NOT_OK means that short reads (shorter than the endpoint's
+	 max length) is to be treated as an error. */
+      errno_dbg("Finishing URB:0x%x[%d] with SHORT_NOT_OK flag and short"
+		" data:%d\n", (unsigned int)urb, urb_num,
+		urb->actual_length);
+      urb->status = -EREMOTEIO;
+    }
+
+    if(urb_priv->urb_state == UNLINK) {
+      /* URB has been requested to be unlinked asynchronously */
+      urb->status = -ECONNRESET;
+      errno_dbg("Fixing unlink status of URB:0x%x[%d] to:%d\n",
+		(unsigned int)urb, urb_num, urb->status);
+    }
+  } else {
+    /* The USB Core wants to signal some error via the URB, pass it through */
+  }
+
+  /* hinko ignore usb_pipeisoc */
+#if 0
+  /* use completely different finish function for Isoc URBs */
+  if(usb_pipeisoc(urb->pipe)) {
+    tc_finish_isoc_urb(hcd, urb, status);
+    return;
+  }
+#endif
+
+  /* Do special unlinking of EPs for Intr traffic */
+  if(usb_pipeint(urb->pipe)) {
+    tc_dma_unlink_intr_urb(urb);
+  }
+
+  /* hinko ignore usb_pipeisoc */
+#if 0
+  /* Release allocated bandwidth for periodic transfers */
+  if(usb_pipeint(urb->pipe) || usb_pipeisoc(urb->pipe))
+    usb_release_bandwidth(urb->dev, urb, 0);
+#endif
+  
+  /* This URB is active on EP */
+  if(urb == activeUrbList[epid]) {
+    /* We need to fiddle with the toggle bits because the hardware doesn't do
+       it for us. */
+    toggle = etrax_epid_get_toggle(epid, usb_pipeout(urb->pipe));
+    usb_settoggle(urb->dev, usb_pipeendpoint(urb->pipe),
+		  usb_pipeout(urb->pipe), toggle);
+
+    /* Checks for Ctrl and Bulk EPs */
+    switch(usb_pipetype(urb->pipe)) {
+    case PIPE_BULK:
+      /* Check so Bulk EP realy is disabled before finishing active URB  */
+      ASSERT((TxBulkEPList[epid].command & IO_MASK(USB_EP_command, enable)) ==
+	     IO_STATE(USB_EP_command, enable, no));
+      /* Disable sub-pointer for EP to avoid next tx_interrupt() to
+	 process Bulk EP. */
+      TxBulkEPList[epid].sub = 0;
+      /* No need to wait for the DMA before changing the next pointer.
+	 The modulo NBR_OF_EPIDS isn't actually necessary, since we will never use
+	 the last one (INVALID_EPID) for actual traffic. */
+      TxBulkEPList[epid].next = 
+	virt_to_phys(&TxBulkEPList[(epid + 1) % NBR_OF_EPIDS]);
+      break;
+    case PIPE_CONTROL:
+      /* Check so Ctrl EP realy is disabled before finishing active URB  */
+      ASSERT((TxCtrlEPList[epid].command & IO_MASK(USB_EP_command, enable)) ==
+	     IO_STATE(USB_EP_command, enable, no));
+      /* Disable sub-pointer for EP to avoid next tx_interrupt() to
+	 process Ctrl EP. */
+      TxCtrlEPList[epid].sub = 0;
+      break;
+    }
+  }
+
+  /* Free HC-private URB data*/
+  urb_priv_free(hcd, urb);
+
+  if(urb->status) {
+    errno_dbg("finish_urb (URB:0x%x[%d] %s %s) (data:%d) status:%d\n",
+	      (unsigned int)urb, urb_num, str_dir(urb->pipe),
+	      str_type(urb->pipe), urb->actual_length, urb->status);
+  } else {
+    tc_dbg("finish_urb (URB:0x%x[%d] %s %s) (data:%d) status:%d\n",
+	   (unsigned int)urb, urb_num, str_dir(urb->pipe),
+	   str_type(urb->pipe), urb->actual_length, urb->status);
+  }
+
+  /* If we just finished an active URB, clear active pointer. */
+  if (urb == activeUrbList[epid]) {
+    /* Make URB not active on EP anymore */
+    activeUrbList[epid] = NULL;
+
+    if(urb->status == 0) {
+      /* URB finished sucessfully, process queue to see if there are any more
+	 URBs waiting before we call completion function.*/
+      if(crisv10_hcd->running) {
+	/* Only process queue if USB controller is running */
+	tc_dma_process_queue(epid);
+      } else {
+	tc_warn("No processing of queue for epid:%d, USB Controller not"
+		" running\n", epid);
+      }
+    }
+  }
+
+  /*  Hand the URB from HCD to its USB device driver, using its completion
+      functions */
+//  usb_hcd_giveback_urb (hcd, urb);
+	/**
+	 * usb_hcd_unlink_urb_from_ep - remove an URB from its endpoint queue
+	 * @hcd: host controller to which @urb was submitted
+	 * @urb: URB being unlinked
+	 *
+	 * Host controller drivers should call this routine before calling
+	 * usb_hcd_giveback_urb().  The HCD's private spinlock must be held and
+	 * interrupts must be disabled.  The actions carried out here are required
+	 * for URB completion.
+	 */
+  
+  /*hinko link/unlink urb -> ep */
+  //spin_lock(&crisv10_hcd->lock);
+  spin_lock_irqsave(&crisv10_hcd->lock, flags);
+  usb_hcd_unlink_urb_from_ep(hcd, urb);
+  usb_hcd_giveback_urb(hcd, urb, status);
+  //spin_unlock(&crisv10_hcd->lock);
+  spin_unlock_irqrestore(&crisv10_hcd->lock, flags);
+
+  /* Check the queue once more if the URB returned with error, because we
+     didn't do it before the completion function because the specification
+     states that the queue should not restart until all it's unlinked
+     URBs have been fully retired, with the completion functions run */
+  if(crisv10_hcd->running) {
+    /* Only process queue if USB controller is running */
+    tc_dma_process_queue(epid);
+  } else {
+    tc_warn("No processing of queue for epid:%d, USB Controller not running\n",
+	    epid);
+  }
+
+  DBFEXIT;
+}
+
+  /* hinko ignore usb_pipeisoc */
+#if 0
+static void tc_finish_isoc_urb(struct usb_hcd *hcd, struct urb *urb,
+			       int status) {
+  struct crisv10_urb_priv *urb_priv = urb->hcpriv;
+  int epid, i;
+  volatile int timeout = 10000;
+
+  ASSERT(urb_priv);
+  epid = urb_priv->epid;
+
+  ASSERT(usb_pipeisoc(urb->pipe));
+
+  /* Set that all isoc packets have status and length set before
+     completing the urb. */
+  for (i = urb_priv->isoc_packet_counter; i < urb->number_of_packets; i++){
+    urb->iso_frame_desc[i].actual_length = 0;
+    urb->iso_frame_desc[i].status = -EPROTO;
+  }
+
+  /* Check if the URB is currently active (done or error) */
+  if(urb == activeUrbList[epid]) {
+    /* Check if there are another In Isoc URB queued for this epid */
+    if (!list_empty(&urb_list[epid])&& !epid_state[epid].disabled) {
+      /* Move it from queue to active and mark it started so Isoc transfers
+	 won't be interrupted.
+	 All Isoc URBs data transfers are already added to DMA lists so we
+	 don't have to insert anything in DMA lists here. */
+      activeUrbList[epid] = urb_list_first(epid);
+      ((struct crisv10_urb_priv *)(activeUrbList[epid]->hcpriv))->urb_state =
+	STARTED;
+      urb_list_del(activeUrbList[epid], epid);
+
+      if(urb->status) {
+	errno_dbg("finish_isoc_urb (URB:0x%x[%d] %s %s) (%d of %d packets)"
+		  " status:%d, new waiting URB:0x%x[%d]\n",
+		  (unsigned int)urb, urb_priv->urb_num, str_dir(urb->pipe),
+		  str_type(urb->pipe), urb_priv->isoc_packet_counter,
+		  urb->number_of_packets, urb->status,
+		  (unsigned int)activeUrbList[epid],
+		  ((struct crisv10_urb_priv *)(activeUrbList[epid]->hcpriv))->urb_num);
+      }
+
+    } else { /* No other URB queued for this epid */
+      if(urb->status) {
+	errno_dbg("finish_isoc_urb (URB:0x%x[%d] %s %s) (%d of %d packets)"
+		  " status:%d, no new URB waiting\n",
+		  (unsigned int)urb, urb_priv->urb_num, str_dir(urb->pipe),
+		  str_type(urb->pipe), urb_priv->isoc_packet_counter,
+		  urb->number_of_packets, urb->status);
+      }
+
+      /* Check if EP is still enabled, then shut it down. */
+      if (TxIsocEPList[epid].command & IO_MASK(USB_EP_command, enable)) {
+	isoc_dbg("Isoc EP enabled for epid:%d, disabling it\n", epid);
+
+	/* Should only occur for In Isoc EPs where SB isn't consumed. */
+	ASSERT(usb_pipein(urb->pipe));
+
+	/* Disable it and wait for it to stop */
+	TxIsocEPList[epid].command &= ~IO_MASK(USB_EP_command, enable);
+	
+	/* Ah, the luxury of busy-wait. */
+	while((*R_DMA_CH8_SUB3_EP == virt_to_phys(&TxIsocEPList[epid])) &&
+	      (timeout-- > 0));
+	if(timeout == 0) {
+	  warn("Timeout while waiting for DMA-TX-Isoc to leave EP for epid:%d\n", epid);
+	}
+      }
+
+      /* Unlink SB to say that epid is finished. */
+      TxIsocEPList[epid].sub = 0;
+      TxIsocEPList[epid].hw_len = 0;
+
+      /* No URB active for EP anymore */
+      activeUrbList[epid] = NULL;
+    }
+  } else { /* Finishing of not active URB (queued up with SBs thought) */
+    isoc_warn("finish_isoc_urb (URB:0x%x %s) (%d of %d packets) status:%d,"
+	      " SB queued but not active\n",
+	      (unsigned int)urb, str_dir(urb->pipe),
+	      urb_priv->isoc_packet_counter, urb->number_of_packets,
+	      urb->status);
+    if(usb_pipeout(urb->pipe)) {
+      /* Finishing of not yet active Out Isoc URB needs unlinking of SBs. */
+      struct USB_SB_Desc *iter_sb, *prev_sb, *next_sb;
+
+      iter_sb = TxIsocEPList[epid].sub ?
+	phys_to_virt(TxIsocEPList[epid].sub) : 0;
+      prev_sb = 0;
+
+      /* SB that is linked before this URBs first SB */
+      while (iter_sb && (iter_sb != urb_priv->first_sb)) {
+	prev_sb = iter_sb;
+	iter_sb = iter_sb->next ? phys_to_virt(iter_sb->next) : 0;
+      }
+
+      if (iter_sb == 0) {
+	/* Unlink of the URB currently being transmitted. */
+	prev_sb = 0;
+	iter_sb = TxIsocEPList[epid].sub ? phys_to_virt(TxIsocEPList[epid].sub) : 0;
+      }
+
+      while (iter_sb && (iter_sb != urb_priv->last_sb)) {
+	iter_sb = iter_sb->next ? phys_to_virt(iter_sb->next) : 0;
+      }
+
+      if (iter_sb) {
+	next_sb = iter_sb->next ? phys_to_virt(iter_sb->next) : 0;
+      } else {
+	/* This should only happen if the DMA has completed
+	   processing the SB list for this EP while interrupts
+	   are disabled. */
+	isoc_dbg("Isoc urb not found, already sent?\n");
+	next_sb = 0;
+      }
+      if (prev_sb) {
+	prev_sb->next = next_sb ? virt_to_phys(next_sb) : 0;
+      } else {
+	TxIsocEPList[epid].sub = next_sb ? virt_to_phys(next_sb) : 0;
+      }
+    }
+  }
+
+  /* Free HC-private URB data*/
+  urb_priv_free(hcd, urb);
+
+  usb_release_bandwidth(urb->dev, urb, 0);
+
+  /*  Hand the URB from HCD to its USB device driver, using its completion
+      functions */
+  usb_hcd_giveback_urb (hcd, urb);
+}
+#endif
+
+static __u32 urb_num = 0;
+
+/* allocate and initialize URB private data */
+static int urb_priv_create(struct usb_hcd *hcd, struct urb *urb, int epid,
+			   int mem_flags) {
+  struct crisv10_urb_priv *urb_priv;
+  
+  urb_priv = kmalloc(sizeof *urb_priv, mem_flags);
+  if (!urb_priv)
+    return -ENOMEM;
+  memset(urb_priv, 0, sizeof *urb_priv);
+
+  urb_priv->epid = epid;
+  urb_priv->urb_state = NOT_STARTED;
+
+  urb->hcpriv = urb_priv;
+  /* Assign URB a sequence number, and increment counter */
+  urb_priv->urb_num = urb_num;
+  urb_num++;
+  return 0;
+}
+
+/* free URB private data */
+static void urb_priv_free(struct usb_hcd *hcd, struct urb *urb) {
+  int i;
+  struct crisv10_urb_priv *urb_priv = urb->hcpriv;
+  ASSERT(urb_priv != 0);
+
+  /* Check it has any SBs linked that needs to be freed*/
+  if(urb_priv->first_sb != NULL) {
+    struct USB_SB_Desc *next_sb, *first_sb, *last_sb;
+    int i = 0;
+    first_sb = urb_priv->first_sb;
+    last_sb = urb_priv->last_sb;
+    ASSERT(last_sb);
+    while(first_sb != last_sb) {
+      next_sb = (struct USB_SB_Desc *)phys_to_virt(first_sb->next);
+      kmem_cache_free(usb_desc_cache, first_sb);
+      first_sb = next_sb;
+      i++;
+    }
+    kmem_cache_free(usb_desc_cache, last_sb);
+    i++;
+  }
+
+  /* Check if it has any EPs in its Intr pool that also needs to be freed */
+  if(urb_priv->intr_ep_pool_length > 0) {
+    for(i = 0; i < urb_priv->intr_ep_pool_length; i++) {
+      kfree(urb_priv->intr_ep_pool[i]);
+    }
+    /*
+    tc_dbg("Freed %d EPs from URB:0x%x EP pool\n",
+	     urb_priv->intr_ep_pool_length, (unsigned int)urb);
+    */
+  }
+
+  kfree(urb_priv);
+  urb->hcpriv = NULL;
+}
+
+static int ep_priv_create(struct usb_host_endpoint *ep, int mem_flags) {
+  struct crisv10_ep_priv *ep_priv;
+  
+  ep_priv = kmalloc(sizeof *ep_priv, mem_flags);
+  if (!ep_priv)
+    return -ENOMEM;
+  memset(ep_priv, 0, sizeof *ep_priv);
+
+  ep->hcpriv = ep_priv;
+  return 0;
+}
+
+static void ep_priv_free(struct usb_host_endpoint *ep) {
+  struct crisv10_ep_priv *ep_priv = ep->hcpriv;
+  ASSERT(ep_priv);
+  kfree(ep_priv);
+  ep->hcpriv = NULL;
+}
+
+/* EPID handling functions, managing EP-list in Etrax through wrappers */
+/* ------------------------------------------------------------------- */
+
+/* Sets up a new EPID for an endpoint or returns existing if found */
+//static int tc_setup_epid(struct usb_host_endpoint *ep, struct urb *urb,
+//			 int mem_flags) {
+static int tc_setup_epid(struct urb *urb, int mem_flags)
+{
+  int epid;
+  char devnum, endpoint, out_traffic, slow;
+  int maxlen;
+  __u32 epid_data;
+  struct usb_host_endpoint *ep = urb->ep;
+  struct crisv10_ep_priv *ep_priv = ep->hcpriv;
+  
+  DBFENTER;
+  
+  /* Check if a valid epid already is setup for this endpoint */
+  if(ep_priv != NULL) {
+    return ep_priv->epid;
+  }
+
+  /* We must find and initiate a new epid for this urb. */
+  epid = tc_allocate_epid();
+  
+  if (epid == -1) {
+    /* Failed to allocate a new epid. */
+    DBFEXIT;
+    return epid;
+  }
+  
+  /* We now have a new epid to use. Claim it. */
+  epid_state[epid].inuse = 1;
+  
+  /* Init private data for new endpoint */
+  if(ep_priv_create(ep, mem_flags) != 0) {
+    return -ENOMEM;
+  }
+  ep_priv = ep->hcpriv;
+  ep_priv->epid = epid;
+
+  devnum = usb_pipedevice(urb->pipe);
+  endpoint = usb_pipeendpoint(urb->pipe);
+  slow = (urb->dev->speed == USB_SPEED_LOW);
+  maxlen = usb_maxpacket(urb->dev, urb->pipe, usb_pipeout(urb->pipe));
+
+  if (usb_pipetype(urb->pipe) == PIPE_CONTROL) {
+    /* We want both IN and OUT control traffic to be put on the same
+       EP/SB list. */
+    out_traffic = 1;
+  } else {
+    out_traffic = usb_pipeout(urb->pipe);
+  }
+    
+  if (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {
+    epid_data = IO_STATE(R_USB_EPT_DATA_ISO, valid, yes) |
+      /* FIXME: Change any to the actual port? */
+      IO_STATE(R_USB_EPT_DATA_ISO, port, any) |
+      IO_FIELD(R_USB_EPT_DATA_ISO, max_len, maxlen) |
+      IO_FIELD(R_USB_EPT_DATA_ISO, ep, endpoint) |
+      IO_FIELD(R_USB_EPT_DATA_ISO, dev, devnum);
+    etrax_epid_iso_set(epid, epid_data);
+  } else {
+    epid_data = IO_STATE(R_USB_EPT_DATA, valid, yes) |
+      IO_FIELD(R_USB_EPT_DATA, low_speed, slow) |
+      /* FIXME: Change any to the actual port? */
+      IO_STATE(R_USB_EPT_DATA, port, any) |
+      IO_FIELD(R_USB_EPT_DATA, max_len, maxlen) |
+      IO_FIELD(R_USB_EPT_DATA, ep, endpoint) |
+      IO_FIELD(R_USB_EPT_DATA, dev, devnum);
+    etrax_epid_set(epid, epid_data);
+  }
+  
+  epid_state[epid].out_traffic = out_traffic;
+  epid_state[epid].type = usb_pipetype(urb->pipe);
+
+  tc_warn("Setting up ep:0x%x epid:%d (addr:%d endp:%d max_len:%d %s %s %s)\n",
+	  (unsigned int)ep, epid, devnum, endpoint, maxlen,
+	  str_type(urb->pipe), out_traffic ? "out" : "in",
+	  slow ? "low" : "full");
+
+  /* Enable Isoc eof interrupt if we set up the first Isoc epid */
+  if(usb_pipeisoc(urb->pipe)) {
+    isoc_epid_counter++;
+    if(isoc_epid_counter == 1) {
+      isoc_warn("Enabled Isoc eof interrupt\n");
+      *R_USB_IRQ_MASK_SET |= IO_STATE(R_USB_IRQ_MASK_SET, iso_eof, set);
+    }
+  }
+
+  DBFEXIT;
+  return epid;
+}
+
+static void tc_free_epid(struct usb_host_endpoint *ep) {
+  unsigned long flags;
+  struct crisv10_ep_priv *ep_priv = ep->hcpriv;
+  int epid;
+  volatile int timeout = 10000;
+
+  DBFENTER;
+
+  if (ep_priv == NULL) {
+    tc_warn("Trying to free unused epid on ep:0x%x\n", (unsigned int)ep);
+    DBFEXIT;
+    return;
+  }
+
+  epid = ep_priv->epid;
+
+  /* Disable Isoc eof interrupt if we free the last Isoc epid */
+  if(epid_isoc(epid)) {
+    ASSERT(isoc_epid_counter > 0);
+    isoc_epid_counter--;
+    if(isoc_epid_counter == 0) {
+      *R_USB_IRQ_MASK_SET &= ~IO_STATE(R_USB_IRQ_MASK_SET, iso_eof, set);
+      isoc_warn("Disabled Isoc eof interrupt\n");
+    }
+  }
+
+  /* Take lock manualy instead of in epid_x_x wrappers,
+     because we need to be polling here */
+  spin_lock_irqsave(&etrax_epid_lock, flags);
+  
+  *R_USB_EPT_INDEX = IO_FIELD(R_USB_EPT_INDEX, value, epid);
+  nop();
+  while((*R_USB_EPT_DATA & IO_MASK(R_USB_EPT_DATA, hold)) &&
+	(timeout-- > 0));
+  if(timeout == 0) {
+    warn("Timeout while waiting for epid:%d to drop hold\n", epid);
+  }
+  /* This will, among other things, set the valid field to 0. */
+  *R_USB_EPT_DATA = 0;
+  spin_unlock_irqrestore(&etrax_epid_lock, flags);
+  
+  /* Free resource in software state info list */
+  epid_state[epid].inuse = 0;
+
+  /* Free private endpoint data */
+  ep_priv_free(ep);
+  
+  DBFEXIT;
+}
+
+static int tc_allocate_epid(void) {
+  int i;
+  DBFENTER;
+  for (i = 0; i < NBR_OF_EPIDS; i++) {
+    if (!epid_inuse(i)) {
+      DBFEXIT;
+      return i;
+    }
+  }
+  
+  tc_warn("Found no free epids\n");
+  DBFEXIT;
+  return -1;
+}
+
+
+/* Wrappers around the list functions (include/linux/list.h). */
+/* ---------------------------------------------------------- */
+static inline int __urb_list_empty(int epid) {
+  int retval;
+  retval = list_empty(&urb_list[epid]);
+  return retval;
+}
+
+/* Returns first urb for this epid, or NULL if list is empty. */
+static inline struct urb *urb_list_first(int epid) {
+  unsigned long flags;
+  struct urb *first_urb = 0;
+  spin_lock_irqsave(&urb_list_lock, flags);
+  if (!__urb_list_empty(epid)) {
+    /* Get the first urb (i.e. head->next). */
+    urb_entry_t *urb_entry = list_entry((&urb_list[epid])->next, urb_entry_t, list);
+    first_urb = urb_entry->urb;
+  }
+  spin_unlock_irqrestore(&urb_list_lock, flags);
+  return first_urb;
+}
+
+/* Adds an urb_entry last in the list for this epid. */
+static inline void urb_list_add(struct urb *urb, int epid, int mem_flags) {
+  unsigned long flags;
+  urb_entry_t *urb_entry = (urb_entry_t *)kmalloc(sizeof(urb_entry_t), mem_flags);
+  ASSERT(urb_entry);
+  
+  urb_entry->urb = urb;
+  spin_lock_irqsave(&urb_list_lock, flags);
+  list_add_tail(&urb_entry->list, &urb_list[epid]);
+  spin_unlock_irqrestore(&urb_list_lock, flags);
+}
+
+/* Search through the list for an element that contains this urb. (The list
+   is expected to be short and the one we are about to delete will often be
+   the first in the list.)
+   Should be protected by spin_locks in calling function */
+static inline urb_entry_t *__urb_list_entry(struct urb *urb, int epid) {
+  struct list_head *entry;
+  struct list_head *tmp;
+  urb_entry_t *urb_entry;
+  
+  list_for_each_safe(entry, tmp, &urb_list[epid]) {
+    urb_entry = list_entry(entry, urb_entry_t, list);
+    ASSERT(urb_entry);
+    ASSERT(urb_entry->urb);
+    
+    if (urb_entry->urb == urb) {
+      return urb_entry;
+    }
+  }
+  return 0;
+}
+
+/* Same function as above but for global use. Protects list by spinlock */
+static inline urb_entry_t *urb_list_entry(struct urb *urb, int epid) {
+  unsigned long flags;
+  urb_entry_t *urb_entry;
+  spin_lock_irqsave(&urb_list_lock, flags);
+  urb_entry = __urb_list_entry(urb, epid);
+  spin_unlock_irqrestore(&urb_list_lock, flags);
+  return (urb_entry);
+}
+
+/* Delete an urb from the list. */
+static inline void urb_list_del(struct urb *urb, int epid) {
+  unsigned long flags;
+  urb_entry_t *urb_entry;
+
+  /* Delete entry and free. */
+  spin_lock_irqsave(&urb_list_lock, flags);
+  urb_entry = __urb_list_entry(urb, epid);
+  ASSERT(urb_entry);
+
+  list_del(&urb_entry->list);
+  spin_unlock_irqrestore(&urb_list_lock, flags);
+  kfree(urb_entry);
+}
+
+/* Move an urb to the end of the list. */
+static inline void urb_list_move_last(struct urb *urb, int epid) {
+  unsigned long flags;
+  urb_entry_t *urb_entry;
+  
+  spin_lock_irqsave(&urb_list_lock, flags);
+  urb_entry = __urb_list_entry(urb, epid);
+  ASSERT(urb_entry);
+
+  list_del(&urb_entry->list);
+  list_add_tail(&urb_entry->list, &urb_list[epid]);
+  spin_unlock_irqrestore(&urb_list_lock, flags);
+}
+
+/* Get the next urb in the list. */
+static inline struct urb *urb_list_next(struct urb *urb, int epid) {
+  unsigned long flags;
+  urb_entry_t *urb_entry;
+
+  spin_lock_irqsave(&urb_list_lock, flags);
+  urb_entry = __urb_list_entry(urb, epid);
+  ASSERT(urb_entry);
+
+  if (urb_entry->list.next != &urb_list[epid]) {
+    struct list_head *elem = urb_entry->list.next;
+    urb_entry = list_entry(elem, urb_entry_t, list);
+    spin_unlock_irqrestore(&urb_list_lock, flags);
+    return urb_entry->urb;
+  } else {
+    spin_unlock_irqrestore(&urb_list_lock, flags);
+    return NULL;
+  }
+}
+
+struct USB_EP_Desc* create_ep(int epid, struct USB_SB_Desc* sb_desc,
+			      int mem_flags) {
+  struct USB_EP_Desc *ep_desc;
+  ep_desc = (struct USB_EP_Desc *) kmem_cache_alloc(usb_desc_cache, mem_flags);
+  if(ep_desc == NULL)
+    return NULL;
+  memset(ep_desc, 0, sizeof(struct USB_EP_Desc));
+
+  ep_desc->hw_len = 0;
+  ep_desc->command = (IO_FIELD(USB_EP_command, epid, epid) |
+		      IO_STATE(USB_EP_command, enable, yes));
+  if(sb_desc == NULL) {
+    ep_desc->sub = 0;
+  } else {
+    ep_desc->sub = virt_to_phys(sb_desc);
+  }
+  return ep_desc;
+}
+
+#define TT_ZOUT  0
+#define TT_IN    1
+#define TT_OUT   2
+#define TT_SETUP 3
+
+#define CMD_EOL  IO_STATE(USB_SB_command, eol, yes)
+#define CMD_INTR IO_STATE(USB_SB_command, intr, yes)
+#define CMD_FULL IO_STATE(USB_SB_command, full, yes)
+
+/* Allocation and setup of a generic SB. Used to create SETUP, OUT and ZOUT
+   SBs. Also used by create_sb_in() to avoid same allocation procedure at two
+   places */
+struct USB_SB_Desc* create_sb(struct USB_SB_Desc* sb_prev, int tt, void* data,
+			      int datalen, int mem_flags) {
+  struct USB_SB_Desc *sb_desc;
+  sb_desc = (struct USB_SB_Desc*)kmem_cache_alloc(usb_desc_cache, mem_flags);
+  if(sb_desc == NULL)
+    return NULL;
+  memset(sb_desc, 0, sizeof(struct USB_SB_Desc));
+
+  sb_desc->command = IO_FIELD(USB_SB_command, tt, tt) |
+                     IO_STATE(USB_SB_command, eot, yes);
+
+  sb_desc->sw_len = datalen;
+  if(data != NULL) {
+    sb_desc->buf = virt_to_phys(data);
+  } else {
+    sb_desc->buf = 0;
+  }
+  if(sb_prev != NULL) {
+    sb_prev->next = virt_to_phys(sb_desc);
+  }
+  return sb_desc;
+}
+
+/* Creates a copy of an existing SB by allocation space for it and copy
+   settings */
+struct USB_SB_Desc* create_sb_copy(struct USB_SB_Desc* sb_orig, int mem_flags) {
+  struct USB_SB_Desc *sb_desc;
+  sb_desc = (struct USB_SB_Desc*)kmem_cache_alloc(usb_desc_cache, mem_flags);
+  if(sb_desc == NULL)
+    return NULL;
+
+  memcpy(sb_desc, sb_orig, sizeof(struct USB_SB_Desc));
+  return sb_desc;
+}
+
+/* A specific create_sb function for creation of in SBs. This is due to
+   that datalen in In SBs shows how many packets we are expecting. It also
+   sets up the rem field to show if how many bytes we expect in last packet
+   if it's not a full one */
+struct USB_SB_Desc* create_sb_in(struct USB_SB_Desc* sb_prev, int datalen,
+				 int maxlen, int mem_flags) {
+  struct USB_SB_Desc *sb_desc;
+  sb_desc = create_sb(sb_prev, TT_IN, NULL,
+		      datalen ? (datalen - 1) / maxlen + 1 : 0, mem_flags);
+  if(sb_desc == NULL)
+    return NULL;
+  sb_desc->command |= IO_FIELD(USB_SB_command, rem, datalen % maxlen);
+  return sb_desc;
+}
+
+void set_sb_cmds(struct USB_SB_Desc *sb_desc, __u16 flags) {
+  sb_desc->command |= flags;
+}
+
+int create_sb_for_urb(struct urb *urb, int mem_flags) {
+  int is_out = !usb_pipein(urb->pipe);
+  int type = usb_pipetype(urb->pipe);
+  int maxlen = usb_maxpacket(urb->dev, urb->pipe, is_out);
+  int buf_len = urb->transfer_buffer_length;
+  void *buf = buf_len > 0 ? urb->transfer_buffer : NULL;
+  struct USB_SB_Desc *sb_desc = NULL;
+
+  struct crisv10_urb_priv *urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+  ASSERT(urb_priv != NULL);
+
+  switch(type) {
+  case PIPE_CONTROL:
+    /* Setup stage */
+    sb_desc = create_sb(NULL, TT_SETUP, urb->setup_packet, 8, mem_flags);
+    if(sb_desc == NULL)
+      return -ENOMEM;
+    set_sb_cmds(sb_desc, CMD_FULL);
+
+    /* Attach first SB to URB */
+    urb_priv->first_sb = sb_desc;    
+
+    if (is_out) { /* Out Control URB */
+      /* If this Control OUT transfer has an optional data stage we add
+	 an OUT token before the mandatory IN (status) token */
+      if ((buf_len > 0) && buf) {
+	sb_desc = create_sb(sb_desc, TT_OUT, buf, buf_len, mem_flags);
+	if(sb_desc == NULL)
+	  return -ENOMEM;
+	set_sb_cmds(sb_desc, CMD_FULL);
+      }
+
+      /* Status stage */
+      /* The data length has to be exactly 1. This is due to a requirement
+         of the USB specification that a host must be prepared to receive
+         data in the status phase */
+      sb_desc = create_sb(sb_desc, TT_IN, NULL, 1, mem_flags);
+      if(sb_desc == NULL)
+	return -ENOMEM;
+    } else { /* In control URB */
+      /* Data stage */
+      sb_desc = create_sb_in(sb_desc, buf_len, maxlen, mem_flags);
+      if(sb_desc == NULL)
+	return -ENOMEM;
+
+      /* Status stage */
+      /* Read comment at zout_buffer declaration for an explanation to this. */
+      sb_desc = create_sb(sb_desc, TT_ZOUT, &zout_buffer[0], 1, mem_flags);
+      if(sb_desc == NULL)
+	return -ENOMEM;
+      /* Set descriptor interrupt flag for in URBs so we can finish URB after
+         zout-packet has been sent */
+      set_sb_cmds(sb_desc, CMD_INTR | CMD_FULL);
+    }
+    /* Set end-of-list flag in last SB */
+    set_sb_cmds(sb_desc, CMD_EOL);
+    /* Attach last SB to URB */
+    urb_priv->last_sb = sb_desc;
+    break;
+
+  case PIPE_BULK:
+    if (is_out) { /* Out Bulk URB */
+      sb_desc = create_sb(NULL, TT_OUT, buf, buf_len, mem_flags);
+      if(sb_desc == NULL)
+	return -ENOMEM;
+      /* The full field is set to yes, even if we don't actually check that
+	 this is a full-length transfer (i.e., that transfer_buffer_length %
+	 maxlen = 0).
+	 Setting full prevents the USB controller from sending an empty packet
+	 in that case.  However, if URB_ZERO_PACKET was set we want that. */
+      if (!(urb->transfer_flags & URB_ZERO_PACKET)) {
+	set_sb_cmds(sb_desc, CMD_FULL);
+      }
+    } else { /* In Bulk URB */
+      sb_desc = create_sb_in(NULL, buf_len, maxlen, mem_flags);
+      if(sb_desc == NULL)
+	return -ENOMEM;
+    }
+    /* Set end-of-list flag for last SB */
+    set_sb_cmds(sb_desc, CMD_EOL);
+
+    /* Attach SB to URB */
+    urb_priv->first_sb = sb_desc;
+    urb_priv->last_sb = sb_desc;
+    break;
+
+  case PIPE_INTERRUPT:
+    if(is_out) { /* Out Intr URB */
+      sb_desc = create_sb(NULL, TT_OUT, buf, buf_len, mem_flags);
+      if(sb_desc == NULL)
+	return -ENOMEM;
+
+      /* The full field is set to yes, even if we don't actually check that
+	 this is a full-length transfer (i.e., that transfer_buffer_length %
+	 maxlen = 0).
+	 Setting full prevents the USB controller from sending an empty packet
+	 in that case.  However, if URB_ZERO_PACKET was set we want that. */
+      if (!(urb->transfer_flags & URB_ZERO_PACKET)) {
+	set_sb_cmds(sb_desc, CMD_FULL);
+      }
+      /* Only generate TX interrupt if it's a Out URB*/
+      set_sb_cmds(sb_desc, CMD_INTR);
+
+    } else { /* In Intr URB */
+      sb_desc = create_sb_in(NULL, buf_len, maxlen, mem_flags);
+      if(sb_desc == NULL)
+	return -ENOMEM;
+    }
+    /* Set end-of-list flag for last SB */
+    set_sb_cmds(sb_desc, CMD_EOL);
+
+    /* Attach SB to URB */
+    urb_priv->first_sb = sb_desc;
+    urb_priv->last_sb = sb_desc;
+
+    break;
+  case PIPE_ISOCHRONOUS:
+    if(is_out) { /* Out Isoc URB */
+      int i;
+      if(urb->number_of_packets == 0) {
+	tc_err("Can't create SBs for Isoc URB with zero packets\n");
+	return -EPIPE;
+      }
+      /* Create one SB descriptor for each packet and link them together. */
+      for(i = 0; i < urb->number_of_packets; i++) {
+	if (urb->iso_frame_desc[i].length > 0) {
+
+	  sb_desc = create_sb(sb_desc, TT_OUT, urb->transfer_buffer +
+			      urb->iso_frame_desc[i].offset,
+			      urb->iso_frame_desc[i].length, mem_flags);
+	  if(sb_desc == NULL)
+	    return -ENOMEM;
+
+	  /* Check if it's a full length packet */
+	  if (urb->iso_frame_desc[i].length ==
+	      usb_maxpacket(urb->dev, urb->pipe, usb_pipeout(urb->pipe))) {
+	    set_sb_cmds(sb_desc, CMD_FULL);
+	  }
+	  
+	} else { /* zero length packet */
+	  sb_desc = create_sb(sb_desc, TT_ZOUT, &zout_buffer[0], 1, mem_flags);
+	  if(sb_desc == NULL)
+	    return -ENOMEM;
+	  set_sb_cmds(sb_desc, CMD_FULL);
+	}
+	/* Attach first SB descriptor to URB */
+	if (i == 0) {
+	  urb_priv->first_sb = sb_desc;
+	}
+      }
+      /* Set interrupt and end-of-list flags in last SB */
+      set_sb_cmds(sb_desc, CMD_INTR | CMD_EOL);
+      /* Attach last SB descriptor to URB */
+      urb_priv->last_sb = sb_desc;
+      tc_dbg("Created %d out SBs for Isoc URB:0x%x\n",
+	       urb->number_of_packets, (unsigned int)urb);
+    } else { /* In Isoc URB */
+      /* Actual number of packets is not relevant for periodic in traffic as
+	 long as it is more than zero.  Set to 1 always. */
+      sb_desc = create_sb(sb_desc, TT_IN, NULL, 1, mem_flags);
+      if(sb_desc == NULL)
+	return -ENOMEM;
+      /* Set end-of-list flags for SB */
+      set_sb_cmds(sb_desc, CMD_EOL);
+
+      /* Attach SB to URB */
+      urb_priv->first_sb = sb_desc;
+      urb_priv->last_sb = sb_desc;
+    }
+    break;
+  default:
+    tc_err("Unknown pipe-type\n");
+    return -EPIPE;
+    break;
+  }
+  return 0;
+}
+
+int init_intr_urb(struct urb *urb, int mem_flags) {
+  struct crisv10_urb_priv *urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+  struct USB_EP_Desc* ep_desc;
+  int interval;
+  int i;
+  int ep_count;
+
+  ASSERT(urb_priv != NULL);
+  ASSERT(usb_pipeint(urb->pipe));
+  /* We can't support interval longer than amount of eof descriptors in
+     TxIntrEPList */
+  if(urb->interval > MAX_INTR_INTERVAL) {
+    tc_err("Interrupt interval %dms too big (max: %dms)\n", urb->interval,
+	   MAX_INTR_INTERVAL);
+    return -EINVAL;
+  }
+
+  /* We assume that the SB descriptors already have been setup */
+  ASSERT(urb_priv->first_sb != NULL);
+
+  /* Round of the interval to 2^n, it is obvious that this code favours
+     smaller numbers, but that is actually a good thing */
+  /* FIXME: The "rounding error" for larger intervals will be quite
+     large. For in traffic this shouldn't be a problem since it will only
+     mean that we "poll" more often. */
+  interval = urb->interval;
+  for (i = 0; interval; i++) {
+    interval = interval >> 1;
+  }
+  urb_priv->interval = 1 << (i - 1);
+
+  /* We can only have max interval for Out Interrupt due to that we can only
+     handle one linked in EP for a certain epid in the Intr descr array at the
+     time. The USB Controller in the Etrax 100LX continues to process Intr EPs
+     so we have no way of knowing which one that caused the actual transfer if
+     we have several linked in. */
+  if(usb_pipeout(urb->pipe)) {
+    urb_priv->interval = MAX_INTR_INTERVAL;
+  }
+
+  /* Calculate amount of EPs needed */
+  ep_count = MAX_INTR_INTERVAL / urb_priv->interval;
+
+  for(i = 0; i < ep_count; i++) {
+    ep_desc = create_ep(urb_priv->epid, urb_priv->first_sb, mem_flags);
+    if(ep_desc == NULL) {
+      /* Free any descriptors that we may have allocated before failure */
+      while(i > 0) {
+	i--;
+	kfree(urb_priv->intr_ep_pool[i]);
+      }
+      return -ENOMEM;
+    }
+    urb_priv->intr_ep_pool[i] = ep_desc;
+  }
+  urb_priv->intr_ep_pool_length = ep_count;
+  return 0;
+}
+
+/* DMA RX/TX functions */
+/* ----------------------- */
+
+static void tc_dma_init_rx_list(void) {
+  int i;
+
+  /* Setup descriptor list except last one */
+  for (i = 0; i < (NBR_OF_RX_DESC - 1); i++) {
+    RxDescList[i].sw_len = RX_DESC_BUF_SIZE;
+    RxDescList[i].command = 0;
+    RxDescList[i].next = virt_to_phys(&RxDescList[i + 1]);
+    RxDescList[i].buf = virt_to_phys(RxBuf + (i * RX_DESC_BUF_SIZE));
+    RxDescList[i].hw_len = 0;
+    RxDescList[i].status = 0;
+    
+    /* DMA IN cache bug. (struct etrax_dma_descr has the same layout as
+       USB_IN_Desc for the relevant fields.) */
+    prepare_rx_descriptor((struct etrax_dma_descr*)&RxDescList[i]);
+    
+  }
+  /* Special handling of last descriptor */
+  RxDescList[i].sw_len = RX_DESC_BUF_SIZE;
+  RxDescList[i].command = IO_STATE(USB_IN_command, eol, yes);
+  RxDescList[i].next = virt_to_phys(&RxDescList[0]);
+  RxDescList[i].buf = virt_to_phys(RxBuf + (i * RX_DESC_BUF_SIZE));
+  RxDescList[i].hw_len = 0;
+  RxDescList[i].status = 0;
+  
+  /* Setup list pointers that show progress in list */
+  myNextRxDesc = &RxDescList[0];
+  myLastRxDesc = &RxDescList[NBR_OF_RX_DESC - 1];
+  
+  flush_etrax_cache();
+  /* Point DMA to first descriptor in list and start it */
+  *R_DMA_CH9_FIRST = virt_to_phys(myNextRxDesc);
+  *R_DMA_CH9_CMD = IO_STATE(R_DMA_CH9_CMD, cmd, start);
+}
+
+
+static void tc_dma_init_tx_bulk_list(void) {
+  int i;
+  volatile struct USB_EP_Desc *epDescr;
+
+  for (i = 0; i < (NBR_OF_EPIDS - 1); i++) {
+    epDescr = &(TxBulkEPList[i]);
+    CHECK_ALIGN(epDescr);
+    epDescr->hw_len = 0;
+    epDescr->command = IO_FIELD(USB_EP_command, epid, i);
+    epDescr->sub = 0;
+    epDescr->next = virt_to_phys(&TxBulkEPList[i + 1]);
+
+    /* Initiate two EPs, disabled and with the eol flag set. No need for any
+       preserved epid. */
+    
+    /* The first one has the intr flag set so we get an interrupt when the DMA
+       channel is about to become disabled. */
+    CHECK_ALIGN(&TxBulkDummyEPList[i][0]);
+    TxBulkDummyEPList[i][0].hw_len = 0;
+    TxBulkDummyEPList[i][0].command = (IO_FIELD(USB_EP_command, epid, DUMMY_EPID) |
+				       IO_STATE(USB_EP_command, eol, yes) |
+				       IO_STATE(USB_EP_command, intr, yes));
+    TxBulkDummyEPList[i][0].sub = 0;
+    TxBulkDummyEPList[i][0].next = virt_to_phys(&TxBulkDummyEPList[i][1]);
+    
+    /* The second one. */
+    CHECK_ALIGN(&TxBulkDummyEPList[i][1]);
+    TxBulkDummyEPList[i][1].hw_len = 0;
+    TxBulkDummyEPList[i][1].command = (IO_FIELD(USB_EP_command, epid, DUMMY_EPID) |
+				       IO_STATE(USB_EP_command, eol, yes));
+    TxBulkDummyEPList[i][1].sub = 0;
+    /* The last dummy's next pointer is the same as the current EP's next pointer. */
+    TxBulkDummyEPList[i][1].next = virt_to_phys(&TxBulkEPList[i + 1]);
+  }
+
+  /* Special handling of last descr in list, make list circular */
+  epDescr = &TxBulkEPList[i];
+  CHECK_ALIGN(epDescr);
+  epDescr->hw_len = 0;
+  epDescr->command = IO_STATE(USB_EP_command, eol, yes) |
+    IO_FIELD(USB_EP_command, epid, i);
+  epDescr->sub = 0;
+  epDescr->next = virt_to_phys(&TxBulkEPList[0]);
+  
+  /* Init DMA sub-channel pointers to last item in each list */
+  *R_DMA_CH8_SUB0_EP = virt_to_phys(&TxBulkEPList[i]);
+  /* No point in starting the bulk channel yet.
+   *R_DMA_CH8_SUB0_CMD = IO_STATE(R_DMA_CH8_SUB0_CMD, cmd, start); */
+}
+
+static void tc_dma_init_tx_ctrl_list(void) {
+  int i;
+  volatile struct USB_EP_Desc *epDescr;
+
+  for (i = 0; i < (NBR_OF_EPIDS - 1); i++) {
+    epDescr = &(TxCtrlEPList[i]);
+    CHECK_ALIGN(epDescr);
+    epDescr->hw_len = 0;
+    epDescr->command = IO_FIELD(USB_EP_command, epid, i);
+    epDescr->sub = 0;
+    epDescr->next = virt_to_phys(&TxCtrlEPList[i + 1]);
+  }
+  /* Special handling of last descr in list, make list circular */
+  epDescr = &TxCtrlEPList[i];
+  CHECK_ALIGN(epDescr);
+  epDescr->hw_len = 0;
+  epDescr->command = IO_STATE(USB_EP_command, eol, yes) |
+    IO_FIELD(USB_EP_command, epid, i);
+  epDescr->sub = 0;
+  epDescr->next = virt_to_phys(&TxCtrlEPList[0]);
+  
+  /* Init DMA sub-channel pointers to last item in each list */
+  *R_DMA_CH8_SUB1_EP = virt_to_phys(&TxCtrlEPList[i]);
+  /* No point in starting the ctrl channel yet.
+   *R_DMA_CH8_SUB1_CMD = IO_STATE(R_DMA_CH8_SUB0_CMD, cmd, start); */
+}
+
+
+static void tc_dma_init_tx_intr_list(void) {
+  int i;
+
+  TxIntrSB_zout.sw_len = 1;
+  TxIntrSB_zout.next = 0;
+  TxIntrSB_zout.buf = virt_to_phys(&zout_buffer[0]);
+  TxIntrSB_zout.command = (IO_FIELD(USB_SB_command, rem, 0) |
+			   IO_STATE(USB_SB_command, tt, zout) |
+			   IO_STATE(USB_SB_command, full, yes) |
+			   IO_STATE(USB_SB_command, eot, yes) |
+			   IO_STATE(USB_SB_command, eol, yes));
+  
+  for (i = 0; i < (MAX_INTR_INTERVAL - 1); i++) {
+    CHECK_ALIGN(&TxIntrEPList[i]);
+    TxIntrEPList[i].hw_len = 0;
+    TxIntrEPList[i].command =
+      (IO_STATE(USB_EP_command, eof, yes) |
+       IO_STATE(USB_EP_command, enable, yes) |
+       IO_FIELD(USB_EP_command, epid, INVALID_EPID));
+    TxIntrEPList[i].sub = virt_to_phys(&TxIntrSB_zout);
+    TxIntrEPList[i].next = virt_to_phys(&TxIntrEPList[i + 1]);
+  }
+
+  /* Special handling of last descr in list, make list circular */
+  CHECK_ALIGN(&TxIntrEPList[i]);
+  TxIntrEPList[i].hw_len = 0;
+  TxIntrEPList[i].command =
+    (IO_STATE(USB_EP_command, eof, yes) |
+     IO_STATE(USB_EP_command, eol, yes) |
+     IO_STATE(USB_EP_command, enable, yes) |
+     IO_FIELD(USB_EP_command, epid, INVALID_EPID));
+  TxIntrEPList[i].sub = virt_to_phys(&TxIntrSB_zout);
+  TxIntrEPList[i].next = virt_to_phys(&TxIntrEPList[0]);
+
+  intr_dbg("Initiated Intr EP descriptor list\n");
+
+
+  /* Connect DMA 8 sub-channel 2 to first in list */
+  *R_DMA_CH8_SUB2_EP = virt_to_phys(&TxIntrEPList[0]);
+}
+
+static void tc_dma_init_tx_isoc_list(void) {
+  int i;
+
+  DBFENTER;
+
+  /* Read comment at zout_buffer declaration for an explanation to this. */
+  TxIsocSB_zout.sw_len = 1;
+  TxIsocSB_zout.next = 0;
+  TxIsocSB_zout.buf = virt_to_phys(&zout_buffer[0]);
+  TxIsocSB_zout.command = (IO_FIELD(USB_SB_command, rem, 0) |
+			   IO_STATE(USB_SB_command, tt, zout) |
+			   IO_STATE(USB_SB_command, full, yes) |
+			   IO_STATE(USB_SB_command, eot, yes) |
+			   IO_STATE(USB_SB_command, eol, yes));
+
+  /* The last isochronous EP descriptor is a dummy. */
+  for (i = 0; i < (NBR_OF_EPIDS - 1); i++) {
+    CHECK_ALIGN(&TxIsocEPList[i]);
+    TxIsocEPList[i].hw_len = 0;
+    TxIsocEPList[i].command = IO_FIELD(USB_EP_command, epid, i);
+    TxIsocEPList[i].sub = 0;
+    TxIsocEPList[i].next = virt_to_phys(&TxIsocEPList[i + 1]);
+  }
+
+  CHECK_ALIGN(&TxIsocEPList[i]);
+  TxIsocEPList[i].hw_len = 0;
+
+  /* Must enable the last EP descr to get eof interrupt. */
+  TxIsocEPList[i].command = (IO_STATE(USB_EP_command, enable, yes) |
+			     IO_STATE(USB_EP_command, eof, yes) |
+			     IO_STATE(USB_EP_command, eol, yes) |
+			     IO_FIELD(USB_EP_command, epid, INVALID_EPID));
+  TxIsocEPList[i].sub = virt_to_phys(&TxIsocSB_zout);
+  TxIsocEPList[i].next = virt_to_phys(&TxIsocEPList[0]);
+
+  *R_DMA_CH8_SUB3_EP = virt_to_phys(&TxIsocEPList[0]);
+  *R_DMA_CH8_SUB3_CMD = IO_STATE(R_DMA_CH8_SUB3_CMD, cmd, start);
+}
+
+static int tc_dma_init(struct usb_hcd *hcd) {
+  tc_dma_init_rx_list();
+  tc_dma_init_tx_bulk_list();
+  tc_dma_init_tx_ctrl_list();
+  tc_dma_init_tx_intr_list();
+  tc_dma_init_tx_isoc_list();
+
+  if (cris_request_dma(USB_TX_DMA_NBR,
+		       "ETRAX 100LX built-in USB (Tx)",
+		       DMA_VERBOSE_ON_ERROR,
+		       dma_usb)) {
+    err("Could not allocate DMA ch 8 for USB");
+    return -EBUSY;
+  }
+ 	
+  if (cris_request_dma(USB_RX_DMA_NBR,
+		       "ETRAX 100LX built-in USB (Rx)",
+		       DMA_VERBOSE_ON_ERROR,
+		       dma_usb)) {
+    err("Could not allocate DMA ch 9 for USB");
+    return -EBUSY;
+  }
+
+  *R_IRQ_MASK2_SET =
+    /* Note that these interrupts are not used. */
+    IO_STATE(R_IRQ_MASK2_SET, dma8_sub0_descr, set) |
+    /* Sub channel 1 (ctrl) descr. interrupts are used. */
+    IO_STATE(R_IRQ_MASK2_SET, dma8_sub1_descr, set) |
+    IO_STATE(R_IRQ_MASK2_SET, dma8_sub2_descr, set) |
+    /* Sub channel 3 (isoc) descr. interrupts are used. */
+    IO_STATE(R_IRQ_MASK2_SET, dma8_sub3_descr, set);
+  
+  /* Note that the dma9_descr interrupt is not used. */
+  *R_IRQ_MASK2_SET =
+    IO_STATE(R_IRQ_MASK2_SET, dma9_eop, set) |
+    IO_STATE(R_IRQ_MASK2_SET, dma9_descr, set);
+
+  if (request_irq(ETRAX_USB_RX_IRQ, tc_dma_rx_interrupt, 0,
+		  "ETRAX 100LX built-in USB (Rx)", hcd)) {
+    err("Could not allocate IRQ %d for USB", ETRAX_USB_RX_IRQ);
+    return -EBUSY;
+  }
+  
+  if (request_irq(ETRAX_USB_TX_IRQ, tc_dma_tx_interrupt, 0,
+		  "ETRAX 100LX built-in USB (Tx)", hcd)) {
+    err("Could not allocate IRQ %d for USB", ETRAX_USB_TX_IRQ);
+    return -EBUSY;
+  }
+
+  return 0;
+}
+
+static void tc_dma_destroy(void) {
+  free_irq(ETRAX_USB_RX_IRQ, NULL);
+  free_irq(ETRAX_USB_TX_IRQ, NULL);
+
+  cris_free_dma(USB_TX_DMA_NBR, "ETRAX 100LX built-in USB (Tx)");
+  cris_free_dma(USB_RX_DMA_NBR, "ETRAX 100LX built-in USB (Rx)");
+
+}
+
+static void tc_dma_link_intr_urb(struct urb *urb);
+
+/* Handle processing of Bulk, Ctrl and Intr queues */
+static void tc_dma_process_queue(int epid) {
+  struct urb *urb;
+  struct crisv10_urb_priv *urb_priv = urb->hcpriv;
+  unsigned long flags;
+  char toggle;
+
+  if(epid_state[epid].disabled) {
+    /* Don't process any URBs on a disabled endpoint */
+    return;
+  }
+
+  /* Do not disturb us while fiddling with EPs and epids */
+  local_irq_save(flags);
+
+  /* For bulk, Ctrl and Intr can we only have one URB active at a time for
+     a specific EP. */
+  if(activeUrbList[epid] != NULL) {
+    /* An URB is already active on EP, skip checking queue */
+    local_irq_restore(flags);
+    return;
+  }
+
+  urb = urb_list_first(epid);
+  if(urb == NULL) {
+    /* No URB waiting in EP queue. Nothing do to */
+    local_irq_restore(flags);
+    return;
+  }
+
+  urb_priv = urb->hcpriv;
+  ASSERT(urb_priv != NULL);
+  ASSERT(urb_priv->urb_state == NOT_STARTED);
+  ASSERT(!usb_pipeisoc(urb->pipe));
+
+  /* Remove this URB from the queue and move it to active */
+  activeUrbList[epid] = urb;
+  urb_list_del(urb, epid);
+
+  urb_priv->urb_state = STARTED;
+
+  /* Reset error counters (regardless of which direction this traffic is). */
+  etrax_epid_clear_error(epid);
+
+  /* Special handling of Intr EP lists */
+  if(usb_pipeint(urb->pipe)) {
+    tc_dma_link_intr_urb(urb);
+    local_irq_restore(flags);
+    return;
+  }
+
+  /* Software must preset the toggle bits for Bulk and Ctrl */
+  if(usb_pipecontrol(urb->pipe)) {
+    /* Toggle bits are initialized only during setup transaction in a
+       CTRL transfer */
+    etrax_epid_set_toggle(epid, 0, 0);
+    etrax_epid_set_toggle(epid, 1, 0);
+  } else {
+    toggle = usb_gettoggle(urb->dev, usb_pipeendpoint(urb->pipe),
+			   usb_pipeout(urb->pipe));
+    etrax_epid_set_toggle(epid, usb_pipeout(urb->pipe), toggle);
+  }
+
+  tc_dbg("Added SBs from (URB:0x%x %s %s) to epid %d: %s\n",
+	 (unsigned int)urb, str_dir(urb->pipe), str_type(urb->pipe), epid,
+	 sblist_to_str(urb_priv->first_sb));
+
+  /* We start the DMA sub channel without checking if it's running or not,
+     because:
+     1) If it's already running, issuing the start command is a nop.
+     2) We avoid a test-and-set race condition. */
+  switch(usb_pipetype(urb->pipe)) {
+  case PIPE_BULK:
+    /* Assert that the EP descriptor is disabled. */
+    ASSERT(!(TxBulkEPList[epid].command & IO_MASK(USB_EP_command, enable)));
+
+    /* Set up and enable the EP descriptor. */
+    TxBulkEPList[epid].sub = virt_to_phys(urb_priv->first_sb);
+    TxBulkEPList[epid].hw_len = 0;
+    TxBulkEPList[epid].command |= IO_STATE(USB_EP_command, enable, yes);
+
+    /* Check if the dummy list is already with us (if several urbs were queued). */
+    if (usb_pipein(urb->pipe) && (TxBulkEPList[epid].next != virt_to_phys(&TxBulkDummyEPList[epid][0]))) {
+      tc_dbg("Inviting dummy list to the party for urb 0x%lx, epid %d", 
+	     (unsigned long)urb, epid);
+      
+      /* We don't need to check if the DMA is at this EP or not before changing the
+	 next pointer, since we will do it in one 32-bit write (EP descriptors are
+	 32-bit aligned). */
+      TxBulkEPList[epid].next = virt_to_phys(&TxBulkDummyEPList[epid][0]);
+    }
+
+    restart_dma8_sub0();
+
+    /* Update/restart the bulk start timer since we just started the channel.*/
+    mod_timer(&bulk_start_timer, jiffies + BULK_START_TIMER_INTERVAL);
+    /* Update/restart the bulk eot timer since we just inserted traffic. */
+    mod_timer(&bulk_eot_timer, jiffies + BULK_EOT_TIMER_INTERVAL);
+    break;
+  case PIPE_CONTROL:
+    /* Assert that the EP descriptor is disabled. */
+    ASSERT(!(TxCtrlEPList[epid].command & IO_MASK(USB_EP_command, enable)));
+
+    /* Set up and enable the EP descriptor. */
+    TxCtrlEPList[epid].sub = virt_to_phys(urb_priv->first_sb);
+    TxCtrlEPList[epid].hw_len = 0;
+    TxCtrlEPList[epid].command |= IO_STATE(USB_EP_command, enable, yes);
+
+    *R_DMA_CH8_SUB1_CMD = IO_STATE(R_DMA_CH8_SUB1_CMD, cmd, start);
+    break;
+  }
+  local_irq_restore(flags);
+}
+
+static void tc_dma_link_intr_urb(struct urb *urb) {
+  struct crisv10_urb_priv *urb_priv = urb->hcpriv;
+  volatile struct USB_EP_Desc *tmp_ep;
+  struct USB_EP_Desc *ep_desc;
+  int i = 0, epid;
+  int pool_idx = 0;
+
+  ASSERT(urb_priv != NULL);
+  epid = urb_priv->epid;
+  ASSERT(urb_priv->interval > 0);
+  ASSERT(urb_priv->intr_ep_pool_length > 0);
+
+  tmp_ep = &TxIntrEPList[0];
+
+  /* Only insert one EP descriptor in list for Out Intr URBs.
+     We can only handle Out Intr with interval of 128ms because
+     it's not possible to insert several Out Intr EPs because they
+     are not consumed by the DMA. */
+  if(usb_pipeout(urb->pipe)) {
+    ep_desc = urb_priv->intr_ep_pool[0];
+    ASSERT(ep_desc);
+    ep_desc->next = tmp_ep->next;
+    tmp_ep->next = virt_to_phys(ep_desc);
+    i++;
+  } else {
+    /* Loop through Intr EP descriptor list and insert EP for URB at
+       specified interval */
+    do {
+      /* Each EP descriptor with eof flag sat signals a new frame */
+      if (tmp_ep->command & IO_MASK(USB_EP_command, eof)) {
+	/* Insert a EP from URBs EP pool at correct interval */
+	if ((i % urb_priv->interval) == 0) {
+	  ep_desc = urb_priv->intr_ep_pool[pool_idx];
+	  ASSERT(ep_desc);
+	  ep_desc->next = tmp_ep->next;
+	  tmp_ep->next = virt_to_phys(ep_desc);
+	  pool_idx++;
+	  ASSERT(pool_idx <= urb_priv->intr_ep_pool_length);
+	}
+	i++;
+      }
+      tmp_ep = (struct USB_EP_Desc *)phys_to_virt(tmp_ep->next);
+    } while(tmp_ep != &TxIntrEPList[0]);
+  }
+
+  intr_dbg("Added SBs to intr epid %d: %s interval:%d (%d EP)\n", epid,
+	   sblist_to_str(urb_priv->first_sb), urb_priv->interval, pool_idx);
+
+  /* We start the DMA sub channel without checking if it's running or not,
+     because:
+     1) If it's already running, issuing the start command is a nop.
+     2) We avoid a test-and-set race condition. */
+  *R_DMA_CH8_SUB2_CMD = IO_STATE(R_DMA_CH8_SUB2_CMD, cmd, start);
+}
+
+  /* hinko ignore usb_pipeisoc */
+#if 0
+static void tc_dma_process_isoc_urb(struct urb *urb) {
+  unsigned long flags;
+  struct crisv10_urb_priv *urb_priv = urb->hcpriv;
+  int epid;
+
+  /* Do not disturb us while fiddling with EPs and epids */
+  local_irq_save(flags);
+
+  ASSERT(urb_priv);
+  ASSERT(urb_priv->first_sb);
+  epid = urb_priv->epid;
+
+  if(activeUrbList[epid] == NULL) {
+    /* EP is idle, so make this URB active */
+    activeUrbList[epid] = urb;
+    urb_list_del(urb, epid);
+    ASSERT(TxIsocEPList[epid].sub == 0);
+    ASSERT(!(TxIsocEPList[epid].command &
+	     IO_STATE(USB_EP_command, enable, yes)));
+
+    /* Differentiate between In and Out Isoc. Because In SBs are not consumed*/
+    if(usb_pipein(urb->pipe)) {
+    /* Each EP for In Isoc will have only one SB descriptor, setup when
+       submitting the first active urb. We do it here by copying from URBs
+       pre-allocated SB. */
+      memcpy((void *)&(TxIsocSBList[epid]), urb_priv->first_sb,
+	     sizeof(TxIsocSBList[epid]));
+      TxIsocEPList[epid].hw_len = 0;
+      TxIsocEPList[epid].sub = virt_to_phys(&(TxIsocSBList[epid]));
+    } else {
+      /* For Out Isoc we attach the pre-allocated list of SBs for the URB */
+      TxIsocEPList[epid].hw_len = 0;
+      TxIsocEPList[epid].sub = virt_to_phys(urb_priv->first_sb);
+
+      isoc_dbg("Attached first URB:0x%x[%d] to epid:%d first_sb:0x%x"
+	       " last_sb::0x%x\n",
+	       (unsigned int)urb, urb_priv->urb_num, epid,
+	       (unsigned int)(urb_priv->first_sb),
+	       (unsigned int)(urb_priv->last_sb));
+    }
+
+    if (urb->transfer_flags & URB_ISO_ASAP) {
+      /* The isoc transfer should be started as soon as possible. The
+	 start_frame field is a return value if URB_ISO_ASAP was set. Comparing
+	 R_USB_FM_NUMBER with a USB Chief trace shows that the first isoc IN
+	 token is sent 2 frames later. I'm not sure how this affects usage of
+	 the start_frame field by the device driver, or how it affects things
+	 when USB_ISO_ASAP is not set, so therefore there's no compensation for
+	 the 2 frame "lag" here. */
+      urb->start_frame = (*R_USB_FM_NUMBER & 0x7ff);
+      TxIsocEPList[epid].command |= IO_STATE(USB_EP_command, enable, yes);
+      urb_priv->urb_state = STARTED;
+      isoc_dbg("URB_ISO_ASAP set, urb->start_frame set to %d\n",
+	       urb->start_frame);
+    } else {
+      /* Not started yet. */
+      urb_priv->urb_state = NOT_STARTED;
+      isoc_warn("urb_priv->urb_state set to NOT_STARTED for URB:0x%x\n",
+		(unsigned int)urb);
+    }
+
+  } else {
+    /* An URB is already active on the EP. Leave URB in queue and let
+       finish_isoc_urb process it after current active URB */
+    ASSERT(TxIsocEPList[epid].sub != 0);
+
+    if(usb_pipein(urb->pipe)) {
+      /* Because there already is a active In URB on this epid we do nothing
+         and the finish_isoc_urb() function will handle switching to next URB*/
+
+    } else { /* For Out Isoc, insert new URBs traffic last in SB-list. */
+      struct USB_SB_Desc *temp_sb_desc;
+
+      /* Set state STARTED to all Out Isoc URBs added to SB list because we
+         don't know how many of them that are finished before descr interrupt*/
+      urb_priv->urb_state = STARTED;
+
+      /* Find end of current SB list by looking for SB with eol flag sat */
+      temp_sb_desc = phys_to_virt(TxIsocEPList[epid].sub);
+      while ((temp_sb_desc->command & IO_MASK(USB_SB_command, eol)) !=
+	     IO_STATE(USB_SB_command, eol, yes)) {
+	ASSERT(temp_sb_desc->next);
+	temp_sb_desc = phys_to_virt(temp_sb_desc->next);
+      }
+
+      isoc_dbg("Appended URB:0x%x[%d] (first:0x%x last:0x%x) to epid:%d"
+	       " sub:0x%x eol:0x%x\n",
+	       (unsigned int)urb, urb_priv->urb_num,
+	       (unsigned int)(urb_priv->first_sb),
+	       (unsigned int)(urb_priv->last_sb), epid,
+	       (unsigned int)phys_to_virt(TxIsocEPList[epid].sub),
+	       (unsigned int)temp_sb_desc);
+
+      /* Next pointer must be set before eol is removed. */
+      temp_sb_desc->next = virt_to_phys(urb_priv->first_sb);
+      /* Clear the previous end of list flag since there is a new in the
+	 added SB descriptor list. */
+      temp_sb_desc->command &= ~IO_MASK(USB_SB_command, eol);
+
+      if (!(TxIsocEPList[epid].command & IO_MASK(USB_EP_command, enable))) {
+	__u32 epid_data;
+	/* 8.8.5 in Designer's Reference says we should check for and correct
+	   any errors in the EP here.  That should not be necessary if
+	   epid_attn is handled correctly, so we assume all is ok. */
+	epid_data = etrax_epid_iso_get(epid);
+	if (IO_EXTRACT(R_USB_EPT_DATA, error_code, epid_data) !=
+	    IO_STATE_VALUE(R_USB_EPT_DATA, error_code, no_error)) {
+	  isoc_err("Disabled Isoc EP with error:%d on epid:%d when appending"
+		   " URB:0x%x[%d]\n",
+		   IO_EXTRACT(R_USB_EPT_DATA, error_code, epid_data), epid,
+		   (unsigned int)urb, urb_priv->urb_num);
+	}
+
+	/* The SB list was exhausted. */
+	if (virt_to_phys(urb_priv->last_sb) != TxIsocEPList[epid].sub) {
+	  /* The new sublist did not get processed before the EP was
+	     disabled.  Setup the EP again. */
+
+	  if(virt_to_phys(temp_sb_desc) == TxIsocEPList[epid].sub) {
+	    isoc_dbg("EP for epid:%d stoped at SB:0x%x before newly inserted"
+		     ", restarting from this URBs SB:0x%x\n",
+		     epid, (unsigned int)temp_sb_desc,
+		     (unsigned int)(urb_priv->first_sb));
+	    TxIsocEPList[epid].hw_len = 0;
+	    TxIsocEPList[epid].sub = virt_to_phys(urb_priv->first_sb);
+	    urb->start_frame = (*R_USB_FM_NUMBER & 0x7ff);
+	    /* Enable the EP again so data gets processed this time */
+	    TxIsocEPList[epid].command |=
+	      IO_STATE(USB_EP_command, enable, yes);
+
+	  } else {
+	    /* The EP has been disabled but not at end this URB (god knows
+	       where). This should generate an epid_attn so we should not be
+	       here */
+	    isoc_warn("EP was disabled on sb:0x%x before SB list for"
+		     " URB:0x%x[%d] got processed\n",
+		     (unsigned int)phys_to_virt(TxIsocEPList[epid].sub),
+		     (unsigned int)urb, urb_priv->urb_num);
+	  }
+	} else {
+	  /* This might happend if we are slow on this function and isn't
+	     an error. */
+	  isoc_dbg("EP was disabled and finished with SBs from appended"
+		   " URB:0x%x[%d]\n", (unsigned int)urb, urb_priv->urb_num);
+	}
+      }
+    }
+  }
+  
+  /* Start the DMA sub channel */
+  *R_DMA_CH8_SUB3_CMD = IO_STATE(R_DMA_CH8_SUB3_CMD, cmd, start);
+
+  local_irq_restore(flags);
+}
+#endif
+
+static void tc_dma_unlink_intr_urb(struct urb *urb) {
+  struct crisv10_urb_priv *urb_priv = urb->hcpriv;
+  volatile struct USB_EP_Desc *first_ep;  /* First EP in the list. */
+  volatile struct USB_EP_Desc *curr_ep;   /* Current EP, the iterator. */
+  volatile struct USB_EP_Desc *next_ep;   /* The EP after current. */
+  volatile struct USB_EP_Desc *unlink_ep; /* The one we should remove from
+					     the list. */
+  int count = 0;
+  volatile int timeout = 10000;
+  int epid;
+
+  /* Read 8.8.4 in Designer's Reference, "Removing an EP Descriptor from the
+     List". */
+  ASSERT(urb_priv);
+  ASSERT(urb_priv->intr_ep_pool_length > 0);
+  epid = urb_priv->epid;
+
+  /* First disable all Intr EPs belonging to epid for this URB */
+  first_ep = &TxIntrEPList[0];
+  curr_ep = first_ep;
+  do {
+    next_ep = (struct USB_EP_Desc *)phys_to_virt(curr_ep->next);
+    if (IO_EXTRACT(USB_EP_command, epid, next_ep->command) == epid) {
+      /* Disable EP */
+      next_ep->command &= ~IO_MASK(USB_EP_command, enable);
+    }
+    curr_ep = phys_to_virt(curr_ep->next);
+  } while (curr_ep != first_ep);
+
+
+  /* Now unlink all EPs belonging to this epid from Descr list */
+  first_ep = &TxIntrEPList[0];
+  curr_ep = first_ep;
+  do {
+    next_ep = (struct USB_EP_Desc *)phys_to_virt(curr_ep->next);
+    if (IO_EXTRACT(USB_EP_command, epid, next_ep->command) == epid) {
+      /* This is the one we should unlink. */
+      unlink_ep = next_ep;
+
+      /* Actually unlink the EP from the DMA list. */
+      curr_ep->next = unlink_ep->next;
+
+      /* Wait until the DMA is no longer at this descriptor. */
+      while((*R_DMA_CH8_SUB2_EP == virt_to_phys(unlink_ep)) &&
+	    (timeout-- > 0));
+      if(timeout == 0) {
+	warn("Timeout while waiting for DMA-TX-Intr to leave unlink EP\n");
+      }
+      
+      count++;
+    }
+    curr_ep = phys_to_virt(curr_ep->next);
+  } while (curr_ep != first_ep);
+
+  if(count != urb_priv->intr_ep_pool_length) {
+    intr_warn("Unlinked %d of %d Intr EPs for URB:0x%x[%d]\n", count,
+	      urb_priv->intr_ep_pool_length, (unsigned int)urb,
+	      urb_priv->urb_num);
+  } else {
+    intr_dbg("Unlinked %d of %d interrupt EPs for URB:0x%x\n", count,
+	     urb_priv->intr_ep_pool_length, (unsigned int)urb);
+  }
+}
+
+static void check_finished_bulk_tx_epids(struct usb_hcd *hcd,
+						    int timer) {
+  unsigned long flags;
+  int epid;
+  struct urb *urb;
+  struct crisv10_urb_priv * urb_priv;
+  __u32 epid_data;
+
+  /* Protect TxEPList */
+  local_irq_save(flags);
+
+  for (epid = 0; epid < NBR_OF_EPIDS; epid++) {
+    /* A finished EP descriptor is disabled and has a valid sub pointer */
+    if (!(TxBulkEPList[epid].command & IO_MASK(USB_EP_command, enable)) &&
+	(TxBulkEPList[epid].sub != 0)) {
+
+      /* Get the active URB for this epid */
+      urb = activeUrbList[epid];
+      /* Sanity checks */
+      ASSERT(urb);
+      urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+      ASSERT(urb_priv);
+      
+      /* Only handle finished out Bulk EPs here,
+	 and let RX interrupt take care of the rest */
+      if(!epid_out_traffic(epid)) {
+	continue;
+      }
+
+      if(timer) {
+	tc_warn("Found finished %s Bulk epid:%d URB:0x%x[%d] from timeout\n",
+		epid_out_traffic(epid) ? "Out" : "In", epid, (unsigned int)urb,
+		urb_priv->urb_num);
+      } else {
+	tc_dbg("Found finished %s Bulk epid:%d URB:0x%x[%d] from interrupt\n",
+	       epid_out_traffic(epid) ? "Out" : "In", epid, (unsigned int)urb,
+	       urb_priv->urb_num);
+      }
+
+      if(urb_priv->urb_state == UNLINK) {
+	/* This Bulk URB is requested to be unlinked, that means that the EP
+	   has been disabled and we might not have sent all data */
+	tc_finish_urb(hcd, urb, urb->status);
+	continue;
+      }
+
+      ASSERT(urb_priv->urb_state == STARTED);
+      if (phys_to_virt(TxBulkEPList[epid].sub) != urb_priv->last_sb) {
+	tc_err("Endpoint got disabled before reaching last sb\n");
+      }
+	
+      epid_data = etrax_epid_get(epid);
+      if (IO_EXTRACT(R_USB_EPT_DATA, error_code, epid_data) ==
+	  IO_STATE_VALUE(R_USB_EPT_DATA, error_code, no_error)) {
+	/* This means that the endpoint has no error, is disabled
+	   and had inserted traffic, i.e. transfer successfully completed. */
+	tc_finish_urb(hcd, urb, 0);
+      } else {
+	/* Shouldn't happen. We expect errors to be caught by epid
+	   attention. */
+	tc_err("Found disabled bulk EP desc (epid:%d error:%d)\n",
+	       epid, IO_EXTRACT(R_USB_EPT_DATA, error_code, epid_data));
+      }
+    } else {
+      tc_dbg("Ignoring In Bulk epid:%d, let RX interrupt handle it\n", epid);
+    }
+  }
+
+  local_irq_restore(flags);
+}
+
+static void check_finished_ctrl_tx_epids(struct usb_hcd *hcd) {
+  unsigned long flags;
+  int epid;
+  struct urb *urb;
+  struct crisv10_urb_priv * urb_priv;
+  __u32 epid_data;
+
+  /* Protect TxEPList */
+  local_irq_save(flags);
+
+  for (epid = 0; epid < NBR_OF_EPIDS; epid++) {
+    if(epid == DUMMY_EPID)
+      continue;
+
+    /* A finished EP descriptor is disabled and has a valid sub pointer */
+    if (!(TxCtrlEPList[epid].command & IO_MASK(USB_EP_command, enable)) &&
+	(TxCtrlEPList[epid].sub != 0)) {
+      
+      /* Get the active URB for this epid */
+      urb = activeUrbList[epid];
+
+      if(urb == NULL) {
+	tc_warn("Found finished Ctrl epid:%d with no active URB\n", epid);
+	continue;
+      }
+      
+      /* Sanity checks */
+      ASSERT(usb_pipein(urb->pipe));
+      urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+      ASSERT(urb_priv);
+      if (phys_to_virt(TxCtrlEPList[epid].sub) != urb_priv->last_sb) {
+	tc_err("Endpoint got disabled before reaching last sb\n");
+      }
+
+      epid_data = etrax_epid_get(epid);
+      if (IO_EXTRACT(R_USB_EPT_DATA, error_code, epid_data) ==
+	  IO_STATE_VALUE(R_USB_EPT_DATA, error_code, no_error)) {
+	/* This means that the endpoint has no error, is disabled
+	   and had inserted traffic, i.e. transfer successfully completed. */
+
+	/* Check if RX-interrupt for In Ctrl has been processed before
+	   finishing the URB */
+	if(urb_priv->ctrl_rx_done) {
+	  tc_dbg("Finishing In Ctrl URB:0x%x[%d] in tx_interrupt\n",
+		 (unsigned int)urb, urb_priv->urb_num);
+	  tc_finish_urb(hcd, urb, 0);
+	} else {
+	  /* If we get zout descriptor interrupt before RX was done for a
+	     In Ctrl transfer, then we flag that and it will be finished
+	     in the RX-Interrupt */
+	  urb_priv->ctrl_zout_done = 1;
+	  tc_dbg("Got zout descr interrupt before RX interrupt\n");
+	}
+      } else {
+	/* Shouldn't happen. We expect errors to be caught by epid
+	   attention. */
+	tc_err("Found disabled Ctrl EP desc (epid:%d URB:0x%x[%d]) error_code:%d\n", epid, (unsigned int)urb, urb_priv->urb_num, IO_EXTRACT(R_USB_EPT_DATA, error_code, epid_data));
+	__dump_ep_desc(&(TxCtrlEPList[epid]));
+	__dump_ept_data(epid);
+      }      
+    }
+  }
+  local_irq_restore(flags);
+}
+
+  /* hinko ignore usb_pipeisoc */
+#if 0
+/* This function goes through all epids that are setup for Out Isoc transfers
+   and marks (isoc_out_done) all queued URBs that the DMA has finished
+   transfer for.
+   No URB completetion is done here to make interrupt routine return quickly.
+   URBs are completed later with help of complete_isoc_bottom_half() that
+   becomes schedules when this functions is finished. */
+static void check_finished_isoc_tx_epids(void) {
+  unsigned long flags;
+  int epid;
+  struct urb *urb;
+  struct crisv10_urb_priv * urb_priv;
+  struct USB_SB_Desc* sb_desc;
+  int epid_done;
+
+  /* Protect TxIsocEPList */
+  local_irq_save(flags);
+
+  for (epid = 0; epid < NBR_OF_EPIDS; epid++) {
+    if (TxIsocEPList[epid].sub == 0 || epid == INVALID_EPID ||
+	!epid_out_traffic(epid)) {
+      /* Nothing here to see. */
+      continue;
+    }
+    ASSERT(epid_inuse(epid));
+    ASSERT(epid_isoc(epid));
+
+    sb_desc = phys_to_virt(TxIsocEPList[epid].sub);
+    /* Find the last descriptor of the currently active URB for this ep.
+       This is the first descriptor in the sub list marked for a descriptor
+       interrupt. */
+    while (sb_desc && !IO_EXTRACT(USB_SB_command, intr, sb_desc->command)) {
+      sb_desc = sb_desc->next ? phys_to_virt(sb_desc->next) : 0;
+    }
+    ASSERT(sb_desc);
+
+    isoc_dbg("Descr IRQ checking epid:%d sub:0x%x intr:0x%x\n",
+	     epid, (unsigned int)phys_to_virt(TxIsocEPList[epid].sub),
+	     (unsigned int)sb_desc);
+
+    urb = activeUrbList[epid];
+    if(urb == NULL) {
+      isoc_err("Isoc Descr irq on epid:%d with no active URB\n", epid);
+      continue;
+    }
+
+    epid_done = 0;
+    while(urb && !epid_done) {
+      /* Sanity check. */
+      ASSERT(usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS);
+      ASSERT(usb_pipeout(urb->pipe));
+      
+      urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+      ASSERT(urb_priv);
+      ASSERT(urb_priv->urb_state == STARTED ||
+	     urb_priv->urb_state == UNLINK);
+      
+      if (sb_desc != urb_priv->last_sb) {
+	/* This urb has been sent. */
+	urb_priv->isoc_out_done = 1;
+
+      } else { /* Found URB that has last_sb as the interrupt reason */
+
+	/* Check if EP has been disabled, meaning that all transfers are done*/
+	if(!(TxIsocEPList[epid].command & IO_MASK(USB_EP_command, enable))) {
+	  ASSERT((sb_desc->command & IO_MASK(USB_SB_command, eol)) ==
+		 IO_STATE(USB_SB_command, eol, yes));
+	  ASSERT(sb_desc->next == 0);
+	  urb_priv->isoc_out_done = 1;
+	} else {
+	  isoc_dbg("Skipping URB:0x%x[%d] because EP not disabled yet\n",
+		   (unsigned int)urb, urb_priv->urb_num);
+	}
+	/* Stop looking any further in queue */
+	epid_done = 1;	
+      }
+
+      if (!epid_done) {
+	if(urb == activeUrbList[epid]) {
+	  urb = urb_list_first(epid);
+	} else {
+	  urb = urb_list_next(urb, epid);
+	}
+      }
+    } /* END: while(urb && !epid_done) */
+  }
+
+  local_irq_restore(flags);
+}
+
+
+/* This is where the Out Isoc URBs are realy completed. This function is
+   scheduled from tc_dma_tx_interrupt() when one or more Out Isoc transfers
+   are done. This functions completes all URBs earlier marked with
+   isoc_out_done by fast interrupt routine check_finished_isoc_tx_epids() */
+
+static void complete_isoc_bottom_half(void *data) {
+  struct crisv10_isoc_complete_data *comp_data;
+  struct usb_iso_packet_descriptor *packet;
+  struct crisv10_urb_priv * urb_priv;
+  unsigned long flags;
+  struct urb* urb;
+  int epid_done;
+  int epid;
+  int i;
+
+  comp_data = (struct crisv10_isoc_complete_data*)data;
+
+  local_irq_save(flags);
+
+  for (epid = 0; epid < NBR_OF_EPIDS - 1; epid++) {
+    if(!epid_inuse(epid) || !epid_isoc(epid) || !epid_out_traffic(epid) || epid == DUMMY_EPID) {
+      /* Only check valid Out Isoc epids */
+      continue;
+    }
+
+    isoc_dbg("Isoc bottom-half checking epid:%d, sub:0x%x\n", epid,
+	     (unsigned int)phys_to_virt(TxIsocEPList[epid].sub));
+
+    /* The descriptor interrupt handler has marked all transmitted Out Isoc
+       URBs with isoc_out_done.  Now we traverse all epids and for all that
+       have out Isoc traffic we traverse its URB list and complete the
+       transmitted URBs. */
+    epid_done = 0;
+    while (!epid_done) {
+
+      /* Get the active urb (if any) */
+      urb = activeUrbList[epid];
+      if (urb == 0) {
+	isoc_dbg("No active URB on epid:%d anymore\n", epid);
+	epid_done = 1;
+	continue;
+      }
+
+      /* Sanity check. */
+      ASSERT(usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS);
+      ASSERT(usb_pipeout(urb->pipe));
+
+      urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+      ASSERT(urb_priv);
+
+      if (!(urb_priv->isoc_out_done)) {
+	/* We have reached URB that isn't flaged done yet, stop traversing. */
+	isoc_dbg("Stoped traversing Out Isoc URBs on epid:%d"
+		 " before not yet flaged URB:0x%x[%d]\n",
+		 epid, (unsigned int)urb, urb_priv->urb_num);
+	epid_done = 1;
+	continue;
+      }
+
+      /* This urb has been sent. */
+      isoc_dbg("Found URB:0x%x[%d] that is flaged isoc_out_done\n",
+	       (unsigned int)urb, urb_priv->urb_num);
+
+      /* Set ok on transfered packets for this URB and finish it */
+      for (i = 0; i < urb->number_of_packets; i++) {
+	packet = &urb->iso_frame_desc[i];
+	packet->status = 0;
+	packet->actual_length = packet->length;
+      }
+      urb_priv->isoc_packet_counter = urb->number_of_packets;
+      tc_finish_urb(comp_data->hcd, urb, 0);
+
+    } /* END: while(!epid_done) */
+  } /* END: for(epid...) */
+
+  local_irq_restore(flags);
+  kmem_cache_free(isoc_compl_cache, comp_data);
+}
+#endif
+
+static void check_finished_intr_tx_epids(struct usb_hcd *hcd) {
+  unsigned long flags;
+  int epid;
+  struct urb *urb;
+  struct crisv10_urb_priv * urb_priv;
+  volatile struct USB_EP_Desc *curr_ep;   /* Current EP, the iterator. */
+  volatile struct USB_EP_Desc *next_ep;   /* The EP after current. */
+
+  /* Protect TxintrEPList */
+  local_irq_save(flags);
+
+  for (epid = 0; epid < NBR_OF_EPIDS; epid++) {
+    if(!epid_inuse(epid) || !epid_intr(epid) || !epid_out_traffic(epid)) {
+      /* Nothing to see on this epid. Only check valid Out Intr epids */
+      continue;
+    }
+
+    urb = activeUrbList[epid];
+    if(urb == 0) {
+      intr_warn("Found Out Intr epid:%d with no active URB\n", epid);
+      continue;
+    }
+
+    /* Sanity check. */
+    ASSERT(usb_pipetype(urb->pipe) == PIPE_INTERRUPT);
+    ASSERT(usb_pipeout(urb->pipe));
+    
+    urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+    ASSERT(urb_priv);
+
+    /* Go through EPs between first and second sof-EP. It's here Out Intr EPs
+       are inserted.*/
+    curr_ep = &TxIntrEPList[0];
+    do {
+      next_ep = (struct USB_EP_Desc *)phys_to_virt(curr_ep->next);
+      if(next_ep == urb_priv->intr_ep_pool[0]) {
+	/* We found the Out Intr EP for this epid */
+	
+	/* Disable it so it doesn't get processed again */
+	next_ep->command &= ~IO_MASK(USB_EP_command, enable);
+
+	/* Finish the active Out Intr URB with status OK */
+	tc_finish_urb(hcd, urb, 0);
+      }
+      curr_ep = phys_to_virt(curr_ep->next);
+    } while (curr_ep != &TxIntrEPList[1]);
+
+  }
+  local_irq_restore(flags);
+}
+
+/* Interrupt handler for DMA8/IRQ24 with subchannels (called from hardware intr) */
+static irqreturn_t tc_dma_tx_interrupt(int irq, void *vhc) {
+  struct usb_hcd *hcd = (struct usb_hcd*)vhc;
+  ASSERT(hcd);
+
+  if (*R_IRQ_READ2 & IO_MASK(R_IRQ_READ2, dma8_sub0_descr)) {
+    /* Clear this interrupt */
+    *R_DMA_CH8_SUB0_CLR_INTR = IO_STATE(R_DMA_CH8_SUB0_CLR_INTR, clr_descr, do);
+    restart_dma8_sub0();
+  }
+
+  if (*R_IRQ_READ2 & IO_MASK(R_IRQ_READ2, dma8_sub1_descr)) {
+    /* Clear this interrupt */
+    *R_DMA_CH8_SUB1_CLR_INTR = IO_STATE(R_DMA_CH8_SUB1_CLR_INTR, clr_descr, do);
+    check_finished_ctrl_tx_epids(hcd);
+  }
+
+  if (*R_IRQ_READ2 & IO_MASK(R_IRQ_READ2, dma8_sub2_descr)) {
+    /* Clear this interrupt */
+    *R_DMA_CH8_SUB2_CLR_INTR = IO_STATE(R_DMA_CH8_SUB2_CLR_INTR, clr_descr, do);
+    check_finished_intr_tx_epids(hcd);
+  }
+
+  /* hinko ignore usb_pipeisoc */
+#if 0
+  if (*R_IRQ_READ2 & IO_MASK(R_IRQ_READ2, dma8_sub3_descr)) {
+    struct crisv10_isoc_complete_data* comp_data;
+
+    /* Flag done Out Isoc for later completion */
+    check_finished_isoc_tx_epids();
+
+    /* Clear this interrupt */
+    *R_DMA_CH8_SUB3_CLR_INTR = IO_STATE(R_DMA_CH8_SUB3_CLR_INTR, clr_descr, do);
+    /* Schedule bottom half of Out Isoc completion function. This function
+       finishes the URBs marked with isoc_out_done */
+    comp_data = (struct crisv10_isoc_complete_data*)
+      kmem_cache_alloc(isoc_compl_cache, GFP_ATOMIC);
+    ASSERT(comp_data != NULL);
+    comp_data ->hcd = hcd;
+
+    //INIT_WORK(&comp_data->usb_bh, complete_isoc_bottom_half, comp_data);
+    INIT_WORK(&comp_data->usb_bh, complete_isoc_bottom_half);
+    schedule_work(&comp_data->usb_bh);
+  }
+#endif
+
+  return IRQ_HANDLED;
+}
+
+/* Interrupt handler for DMA9/IRQ25 (called from hardware intr) */
+static irqreturn_t tc_dma_rx_interrupt(int irq, void *vhc) {
+  unsigned long flags;
+  struct urb *urb;
+  struct usb_hcd *hcd = (struct usb_hcd*)vhc;
+  struct crisv10_urb_priv *urb_priv;
+  int epid = 0;
+  int real_error;
+
+  ASSERT(hcd);
+
+  /* Clear this interrupt. */
+  *R_DMA_CH9_CLR_INTR = IO_STATE(R_DMA_CH9_CLR_INTR, clr_eop, do);
+
+  /* Custom clear interrupt for this interrupt */
+  /* The reason we cli here is that we call the driver's callback functions. */
+  local_irq_save(flags);
+
+  /* Note that this while loop assumes that all packets span only
+     one rx descriptor. */
+  while(myNextRxDesc->status & IO_MASK(USB_IN_status, eop)) {
+    epid = IO_EXTRACT(USB_IN_status, epid, myNextRxDesc->status);
+    /* Get the active URB for this epid */
+    urb = activeUrbList[epid];
+
+    ASSERT(epid_inuse(epid));
+    if (!urb) {
+      dma_err("No urb for epid %d in rx interrupt\n", epid);
+      goto skip_out;
+    }
+
+    /* Check if any errors on epid */
+    real_error = 0;
+    if (myNextRxDesc->status & IO_MASK(USB_IN_status, error)) {
+      __u32 r_usb_ept_data;
+
+      if (usb_pipeisoc(urb->pipe)) {
+	r_usb_ept_data = etrax_epid_iso_get(epid);
+	if((r_usb_ept_data & IO_MASK(R_USB_EPT_DATA_ISO, valid)) &&
+	   (IO_EXTRACT(R_USB_EPT_DATA_ISO, error_code, r_usb_ept_data) == 0) &&
+	   (myNextRxDesc->status & IO_MASK(USB_IN_status, nodata))) {
+	  /* Not an error, just a failure to receive an expected iso
+	     in packet in this frame.  This is not documented
+	     in the designers reference. Continue processing.
+	  */
+	} else real_error = 1;
+      } else real_error = 1;
+    }
+
+    if(real_error) {
+      dma_err("Error in RX descr on epid:%d for URB 0x%x",
+	      epid, (unsigned int)urb);
+      dump_ept_data(epid);
+      dump_in_desc(myNextRxDesc);
+      goto skip_out;
+    }
+
+    urb_priv = (struct crisv10_urb_priv *)urb->hcpriv;
+    ASSERT(urb_priv);
+    ASSERT(urb_priv->urb_state == STARTED ||
+	   urb_priv->urb_state == UNLINK);
+
+    if ((usb_pipetype(urb->pipe) == PIPE_BULK) ||
+	(usb_pipetype(urb->pipe) == PIPE_CONTROL) ||
+	(usb_pipetype(urb->pipe) == PIPE_INTERRUPT)) {
+
+      /* We get nodata for empty data transactions, and the rx descriptor's
+	 hw_len field is not valid in that case. No data to copy in other
+	 words. */
+      if (myNextRxDesc->status & IO_MASK(USB_IN_status, nodata)) {
+	/* No data to copy */
+      } else {
+	/*
+	dma_dbg("Processing RX for URB:0x%x epid:%d (data:%d ofs:%d)\n",
+		(unsigned int)urb, epid, myNextRxDesc->hw_len,
+		urb_priv->rx_offset);
+	*/
+	/* Only copy data if URB isn't flaged to be unlinked*/
+	if(urb_priv->urb_state != UNLINK) {
+	  /* Make sure the data fits in the buffer. */
+	  if(urb_priv->rx_offset + myNextRxDesc->hw_len
+	     <= urb->transfer_buffer_length) {
+
+	    /* Copy the data to URBs buffer */
+	    memcpy(urb->transfer_buffer + urb_priv->rx_offset,
+		   phys_to_virt(myNextRxDesc->buf), myNextRxDesc->hw_len);
+	    urb_priv->rx_offset += myNextRxDesc->hw_len;
+	  } else {
+	    /* Signal overflow when returning URB */
+	    urb->status = -EOVERFLOW;
+	    tc_finish_urb_later(hcd, urb, urb->status);
+	  }
+	}
+      }
+
+      /* Check if it was the last packet in the transfer */
+      if (myNextRxDesc->status & IO_MASK(USB_IN_status, eot)) {
+	/* Special handling for In Ctrl URBs. */
+	if(usb_pipecontrol(urb->pipe) && usb_pipein(urb->pipe) &&
+	   !(urb_priv->ctrl_zout_done)) {
+	  /* Flag that RX part of Ctrl transfer is done. Because zout descr
+	     interrupt hasn't happend yet will the URB be finished in the
+	     TX-Interrupt. */
+	  urb_priv->ctrl_rx_done = 1;
+	  tc_dbg("Not finishing In Ctrl URB:0x%x from rx_interrupt, waiting"
+		 " for zout\n", (unsigned int)urb);
+	} else {
+	  tc_finish_urb(hcd, urb, 0);
+	}
+      }
+    } else { /* ISOC RX */
+      /*
+      isoc_dbg("Processing RX for epid:%d (URB:0x%x) ISOC pipe\n",
+	       epid, (unsigned int)urb);
+      */
+
+      struct usb_iso_packet_descriptor *packet;
+
+      if (urb_priv->urb_state == UNLINK) {
+	isoc_warn("Ignoring Isoc Rx data for urb being unlinked.\n");
+	goto skip_out;
+      } else if (urb_priv->urb_state == NOT_STARTED) {
+	isoc_err("What? Got Rx data for Isoc urb that isn't started?\n");
+	goto skip_out;
+      }
+
+      packet = &urb->iso_frame_desc[urb_priv->isoc_packet_counter];
+      ASSERT(packet);
+      packet->status = 0;
+
+      if (myNextRxDesc->status & IO_MASK(USB_IN_status, nodata)) {
+	/* We get nodata for empty data transactions, and the rx descriptor's
+	   hw_len field is not valid in that case. We copy 0 bytes however to
+	   stay in synch. */
+	packet->actual_length = 0;
+      } else {
+	packet->actual_length = myNextRxDesc->hw_len;
+	/* Make sure the data fits in the buffer. */
+	ASSERT(packet->actual_length <= packet->length);
+	memcpy(urb->transfer_buffer + packet->offset,
+	       phys_to_virt(myNextRxDesc->buf), packet->actual_length);
+	if(packet->actual_length > 0)
+	  isoc_dbg("Copied %d bytes, packet %d for URB:0x%x[%d]\n",
+		   packet->actual_length, urb_priv->isoc_packet_counter,
+		   (unsigned int)urb, urb_priv->urb_num);
+      }
+
+      /* Increment the packet counter. */
+      urb_priv->isoc_packet_counter++;
+
+      /* Note that we don't care about the eot field in the rx descriptor's
+	 status. It will always be set for isoc traffic. */
+      if (urb->number_of_packets == urb_priv->isoc_packet_counter) {
+	/* Complete the urb with status OK. */
+	tc_finish_urb(hcd, urb, 0);
+      }
+    }
+
+  skip_out:
+    myNextRxDesc->status = 0;
+    myNextRxDesc->command |= IO_MASK(USB_IN_command, eol);
+    myLastRxDesc->command &= ~IO_MASK(USB_IN_command, eol);
+    myLastRxDesc = myNextRxDesc;
+    myNextRxDesc = phys_to_virt(myNextRxDesc->next);
+    flush_etrax_cache();
+    *R_DMA_CH9_CMD = IO_STATE(R_DMA_CH9_CMD, cmd, restart);
+  }
+
+  local_irq_restore(flags);
+
+  return IRQ_HANDLED;
+}
+
+static void tc_bulk_start_timer_func(unsigned long dummy) {
+  /* We might enable an EP descriptor behind the current DMA position when
+     it's about to decide that there are no more bulk traffic and it should
+     stop the bulk channel.
+     Therefore we periodically check if the bulk channel is stopped and there
+     is an enabled bulk EP descriptor, in which case we start the bulk
+     channel. */
+  
+  if (!(*R_DMA_CH8_SUB0_CMD & IO_MASK(R_DMA_CH8_SUB0_CMD, cmd))) {
+    int epid;
+
+    timer_dbg("bulk_start_timer: Bulk DMA channel not running.\n");
+
+    for (epid = 0; epid < NBR_OF_EPIDS; epid++) {
+      if (TxBulkEPList[epid].command & IO_MASK(USB_EP_command, enable)) {
+	timer_warn("Found enabled EP for epid %d, starting bulk channel.\n",
+		   epid);
+	restart_dma8_sub0();
+
+	/* Restart the bulk eot timer since we just started the bulk channel.*/
+	mod_timer(&bulk_eot_timer, jiffies + BULK_EOT_TIMER_INTERVAL);
+
+	/* No need to search any further. */
+	break;
+      }
+    }
+  } else {
+    timer_dbg("bulk_start_timer: Bulk DMA channel running.\n");
+  }
+}
+
+static void tc_bulk_eot_timer_func(unsigned long dummy) {
+  struct usb_hcd *hcd = (struct usb_hcd*)dummy;
+  ASSERT(hcd);
+  /* Because of a race condition in the top half, we might miss a bulk eot.
+     This timer "simulates" a bulk eot if we don't get one for a while,
+     hopefully correcting the situation. */
+  timer_dbg("bulk_eot_timer timed out.\n");
+  check_finished_bulk_tx_epids(hcd, 1);
+}
+
+
+/*************************************************************/
+/*************************************************************/
+/* Device driver block                                       */
+/*************************************************************/
+/*************************************************************/
+
+/* Forward declarations for device driver functions */
+static int devdrv_hcd_probe(struct device *);
+static int devdrv_hcd_remove(struct device *);
+#ifdef CONFIG_PM
+static int devdrv_hcd_suspend(struct device *, u32, u32);
+static int devdrv_hcd_resume(struct device *, u32);
+#endif /* CONFIG_PM */
+
+/* the device */
+static struct platform_device *devdrv_hc_platform_device;
+
+/* device driver interface */
+static struct device_driver devdrv_hc_device_driver = {
+  .name =			(char *) hc_name,
+  .bus =			&platform_bus_type,
+
+  .probe =		devdrv_hcd_probe,
+  .remove =		devdrv_hcd_remove,
+
+#ifdef CONFIG_PM
+  .suspend =		devdrv_hcd_suspend,
+  .resume =		devdrv_hcd_resume,
+#endif /* CONFIG_PM */
+};
+
+/* initialize the host controller and driver  */
+static int __init_or_module devdrv_hcd_probe(struct device *dev)
+{
+  struct usb_hcd *hcd;
+  struct crisv10_hcd *crisv10_hcd;
+  int retval;
+  int rev_maj, rev_min;
+
+  /* Check DMA burst length */
+  if(IO_EXTRACT(R_BUS_CONFIG, dma_burst, *R_BUS_CONFIG) !=
+     IO_STATE(R_BUS_CONFIG, dma_burst, burst32)) {
+    devdrv_err("Invalid DMA burst length in Etrax 100LX,"
+	       " needs to be 32\n");
+    return -EPERM;
+  }
+
+  hcd = usb_create_hcd(&crisv10_hc_driver, dev, dev_name(dev));
+  if (!hcd)
+    return -ENOMEM;
+
+  crisv10_hcd = hcd_to_crisv10_hcd(hcd);
+  spin_lock_init(&crisv10_hcd->lock);
+  crisv10_hcd->num_ports = num_ports();
+  crisv10_hcd->running = 0;
+
+  dev_set_drvdata(dev, crisv10_hcd);
+
+  devdrv_dbg("ETRAX USB IRQs HC:%d  RX:%d  TX:%d\n", ETRAX_USB_HC_IRQ,
+	  ETRAX_USB_RX_IRQ, ETRAX_USB_TX_IRQ);
+
+  /* Print out chip version read from registers */
+  rev_maj = *R_USB_REVISION & IO_MASK(R_USB_REVISION, major);
+  rev_min = *R_USB_REVISION & IO_MASK(R_USB_REVISION, minor);
+  if(rev_min == 0) {
+    devdrv_info("Etrax 100LX USB Revision %d v1,2\n", rev_maj);
+  } else {
+    devdrv_info("Etrax 100LX USB Revision %d v%d\n", rev_maj, rev_min);
+  }
+
+  devdrv_info("Bulk timer interval, start:%d eot:%d\n",
+	      BULK_START_TIMER_INTERVAL,
+	      BULK_EOT_TIMER_INTERVAL);
+
+
+  /* Init root hub data structures */
+  if(rh_init()) {
+    devdrv_err("Failed init data for Root Hub\n");
+    retval = -ENOMEM;
+  }
+
+  if(port_in_use(0)) {
+    if (cris_request_io_interface(if_usb_1, "ETRAX100LX USB-HCD")) {
+      printk(KERN_CRIT "usb-host: request IO interface usb1 failed");
+      retval = -EBUSY;
+      goto out;
+    }
+    devdrv_info("Claimed interface for USB physical port 1\n");
+  }
+  if(port_in_use(1)) {
+    if (cris_request_io_interface(if_usb_2, "ETRAX100LX USB-HCD")) {
+      /* Free first interface if second failed to be claimed */
+      if(port_in_use(0)) {
+	cris_free_io_interface(if_usb_1);
+      }
+      printk(KERN_CRIT "usb-host: request IO interface usb2 failed");
+      retval = -EBUSY;
+      goto out;
+    }
+    devdrv_info("Claimed interface for USB physical port 2\n");
+  }
+  
+  /* Init transfer controller structs and locks */
+  if((retval = tc_init(hcd)) != 0) {
+    goto out;
+  }
+
+  /* Attach interrupt functions for DMA and init DMA controller */
+  if((retval = tc_dma_init(hcd)) != 0) {
+    goto out;
+  }
+
+  /* Attach the top IRQ handler for USB controller interrupts */
+  if (request_irq(ETRAX_USB_HC_IRQ, crisv10_hcd_top_irq, 0,
+		  "ETRAX 100LX built-in USB (HC)", hcd)) {
+    err("Could not allocate IRQ %d for USB", ETRAX_USB_HC_IRQ);
+    retval = -EBUSY;
+    goto out;
+  }
+
+  /* iso_eof is only enabled when isoc traffic is running. */
+  *R_USB_IRQ_MASK_SET =
+    /* IO_STATE(R_USB_IRQ_MASK_SET, iso_eof, set) | */
+    IO_STATE(R_USB_IRQ_MASK_SET, bulk_eot, set) |
+    IO_STATE(R_USB_IRQ_MASK_SET, epid_attn, set) |
+    IO_STATE(R_USB_IRQ_MASK_SET, port_status, set) |
+    IO_STATE(R_USB_IRQ_MASK_SET, ctl_status, set);
+
+
+  crisv10_ready_wait();
+  /* Reset the USB interface. */
+  *R_USB_COMMAND =
+    IO_STATE(R_USB_COMMAND, port_sel, nop) |
+    IO_STATE(R_USB_COMMAND, port_cmd, reset) |
+    IO_STATE(R_USB_COMMAND, ctrl_cmd, reset);
+
+  /* Designer's Reference, p. 8 - 10 says we should Initate R_USB_FM_PSTART to
+     0x2A30 (10800), to guarantee that control traffic gets 10% of the
+     bandwidth, and periodic transfer may allocate the rest (90%).
+     This doesn't work though.
+     The value 11960 is chosen to be just after the SOF token, with a couple
+     of bit times extra for possible bit stuffing. */
+  *R_USB_FM_PSTART = IO_FIELD(R_USB_FM_PSTART, value, 11960);
+
+  crisv10_ready_wait();
+  /* Configure the USB interface as a host controller. */
+  *R_USB_COMMAND =
+    IO_STATE(R_USB_COMMAND, port_sel, nop) |
+    IO_STATE(R_USB_COMMAND, port_cmd, reset) |
+    IO_STATE(R_USB_COMMAND, ctrl_cmd, host_config);
+
+
+  /* Check so controller not busy before enabling ports */
+  crisv10_ready_wait();
+
+  /* Enable selected USB ports */
+  if(port_in_use(0)) {
+    *R_USB_PORT1_DISABLE = IO_STATE(R_USB_PORT1_DISABLE, disable, no);
+  } else {
+    *R_USB_PORT1_DISABLE = IO_STATE(R_USB_PORT1_DISABLE, disable, yes);
+  }
+  if(port_in_use(1)) {
+    *R_USB_PORT2_DISABLE = IO_STATE(R_USB_PORT2_DISABLE, disable, no);
+  } else {
+    *R_USB_PORT2_DISABLE = IO_STATE(R_USB_PORT2_DISABLE, disable, yes);
+  }
+
+  crisv10_ready_wait();
+  /* Start processing of USB traffic. */
+  *R_USB_COMMAND =
+    IO_STATE(R_USB_COMMAND, port_sel, nop) |
+    IO_STATE(R_USB_COMMAND, port_cmd, reset) |
+    IO_STATE(R_USB_COMMAND, ctrl_cmd, host_run);
+
+  /* Do not continue probing initialization before USB interface is done */
+  crisv10_ready_wait();
+
+  /* Register our Host Controller to USB Core
+   * Finish the remaining parts of generic HCD initialization: allocate the
+   * buffers of consistent memory, register the bus
+   * and call the driver's reset() and start() routines. */
+  retval = usb_add_hcd(hcd, ETRAX_USB_HC_IRQ, IRQF_DISABLED);
+  if (retval != 0) {
+    devdrv_err("Failed registering HCD driver\n");
+    goto out;
+  }
+
+  return 0;
+
+ out:
+  devdrv_hcd_remove(dev);
+  return retval;
+}
+
+
+/* cleanup after the host controller and driver */
+static int __init_or_module devdrv_hcd_remove(struct device *dev)
+{
+  struct crisv10_hcd *crisv10_hcd = dev_get_drvdata(dev);
+  struct usb_hcd *hcd;
+
+  if (!crisv10_hcd)
+    return 0;
+  hcd = crisv10_hcd_to_hcd(crisv10_hcd);
+
+
+  /* Stop USB Controller in Etrax 100LX */
+  crisv10_hcd_reset(hcd);
+
+  usb_remove_hcd(hcd);
+  devdrv_dbg("Removed HCD from USB Core\n");
+
+  /* Free USB Controller IRQ */
+  free_irq(ETRAX_USB_HC_IRQ, NULL);
+
+  /* Free resources */
+  tc_dma_destroy();
+  tc_destroy();
+
+
+  if(port_in_use(0)) {
+    cris_free_io_interface(if_usb_1);
+  }
+  if(port_in_use(1)) {
+    cris_free_io_interface(if_usb_2);
+  }
+
+  devdrv_dbg("Freed all claimed resources\n");
+
+  return 0;
+}
+
+
+#ifdef	CONFIG_PM
+
+static int devdrv_hcd_suspend(struct usb_hcd *hcd, u32 state, u32 level)
+{
+  return 0; /* no-op for now */
+}
+
+static int devdrv_hcd_resume(struct usb_hcd *hcd, u32 level)
+{
+  return 0; /* no-op for now */
+}
+
+#endif /* CONFIG_PM */
+
+
+
+/*************************************************************/
+/*************************************************************/
+/* Module block                                              */
+/*************************************************************/
+/*************************************************************/
+ 
+/* register driver */
+static int __init module_hcd_init(void) 
+{
+  
+  if (usb_disabled())
+    return -ENODEV;
+
+  /* Here we select enabled ports by following defines created from
+     menuconfig */
+#ifndef CONFIG_ETRAX_USB_HOST_PORT1
+  ports &= ~(1<<0);
+#endif
+#ifndef CONFIG_ETRAX_USB_HOST_PORT2
+  ports &= ~(1<<1);
+#endif
+
+  printk(KERN_INFO "%s version "VERSION" "COPYRIGHT"\n", product_desc);
+
+  devdrv_hc_platform_device =
+    platform_device_register_simple((char *) hc_name, 0, NULL, 0);
+
+  if (IS_ERR(devdrv_hc_platform_device))
+    return PTR_ERR(devdrv_hc_platform_device);
+  return driver_register(&devdrv_hc_device_driver);
+  /* 
+   * Note that we do not set the DMA mask for the device,
+   * i.e. we pretend that we will use PIO, since no specific
+   * allocation routines are needed for DMA buffers. This will
+   * cause the HCD buffer allocation routines to fall back to
+   * kmalloc().
+   */
+}
+
+/* unregister driver */
+static void __exit module_hcd_exit(void) 
+{	
+  driver_unregister(&devdrv_hc_device_driver);
+}
+
+
+/* Module hooks */
+module_init(module_hcd_init);
+module_exit(module_hcd_exit);
diff -Nur linux-2.6.39.orig/drivers/usb/host/hc-crisv10.h linux-2.6.39/drivers/usb/host/hc-crisv10.h
--- linux-2.6.39.orig/drivers/usb/host/hc-crisv10.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.39/drivers/usb/host/hc-crisv10.h	2011-07-28 16:16:37.757174124 +0200
@@ -0,0 +1,331 @@
+#ifndef __LINUX_ETRAX_USB_H
+#define __LINUX_ETRAX_USB_H
+
+#include <linux/types.h>
+#include <linux/list.h>
+
+struct USB_IN_Desc {
+  volatile __u16 sw_len;
+  volatile __u16 command;
+  volatile unsigned long next;
+  volatile unsigned long buf;
+  volatile __u16 hw_len;
+  volatile __u16 status;
+};
+
+struct USB_SB_Desc {
+  volatile __u16 sw_len;
+  volatile __u16 command;
+  volatile unsigned long next;
+  volatile unsigned long buf;
+};
+
+struct USB_EP_Desc {
+  volatile __u16 hw_len;
+  volatile __u16 command;
+  volatile unsigned long sub;
+  volatile unsigned long next;
+};
+
+
+/* Root Hub port status struct */
+struct crisv10_rh {
+  volatile __u16 wPortChange[2];
+  volatile __u16 wPortStatusPrev[2];
+};
+
+/* HCD description */
+struct crisv10_hcd {
+  spinlock_t		lock;
+  __u8			num_ports;
+  __u8                  running;
+};
+
+
+/* Endpoint HC private data description */
+struct crisv10_ep_priv {
+  int epid;
+};
+
+/* Additional software state info for a USB Controller epid */
+struct etrax_epid {
+  __u8 inuse;       /* !0 = setup in Etrax and used for a endpoint */
+  __u8 disabled;    /* !0 = Temporarly disabled to avoid resubmission */
+  __u8 type;        /* Setup as: PIPE_BULK, PIPE_CONTROL ... */
+  __u8 out_traffic; /* !0 = This epid is for out traffic */
+};
+
+/* Struct to hold information of scheduled later URB completion */
+struct urb_later_data {
+//  struct work_struct ws;
+  struct delayed_work ws;
+  struct usb_hcd *hcd;
+  struct urb *urb;
+  int urb_num;
+  int status;
+};
+
+
+typedef enum {
+  STARTED,
+  NOT_STARTED,
+  UNLINK,
+} crisv10_urb_state_t;
+
+
+struct crisv10_urb_priv {
+  /* Sequence number for this URB. Every new submited URB gets this from
+     a incrementing counter. Used when a URB is scheduled for later finish to
+     be sure that the intended URB hasn't already been completed (device
+     drivers has a tendency to reuse URBs once they are completed, causing us
+     to not be able to single old ones out only based on the URB pointer.) */
+  __u32 urb_num;
+
+  /* The first_sb field is used for freeing all SB descriptors belonging
+     to an urb. The corresponding ep descriptor's sub pointer cannot be
+     used for this since the DMA advances the sub pointer as it processes
+     the sb list. */
+  struct USB_SB_Desc *first_sb;
+
+  /* The last_sb field referes to the last SB descriptor that belongs to
+     this urb. This is important to know so we can free the SB descriptors
+     that ranges between first_sb and last_sb. */
+  struct USB_SB_Desc *last_sb;
+  
+  /* The rx_offset field is used in ctrl and bulk traffic to keep track
+     of the offset in the urb's transfer_buffer where incoming data should be
+     copied to. */
+  __u32 rx_offset;
+  
+  /* Counter used in isochronous transfers to keep track of the
+     number of packets received/transmitted.  */
+  __u32 isoc_packet_counter;
+
+  /* Flag that marks if this Isoc Out URB has finished it's transfer. Used
+     because several URBs can be finished before list is processed */
+  __u8  isoc_out_done;
+  
+  /* This field is used to pass information about the urb's current state
+     between the various interrupt handlers (thus marked volatile). */
+  volatile crisv10_urb_state_t urb_state;
+  
+  /* In Ctrl transfers consist of (at least) 3 packets: SETUP, IN and ZOUT.
+     When DMA8 sub-channel 2 has processed the SB list for this sequence we
+     get a interrupt. We also get a interrupt for In transfers and which
+     one of these interrupts that comes first depends of data size and device.
+     To be sure that we have got both interrupts before we complete the URB
+     we have these to flags that shows which part that has completed.
+     We can then check when we get one of the interrupts that if the other has
+     occured it's safe for us to complete the URB, otherwise we set appropriate
+     flag and do the completion when we get the other interrupt. */
+  volatile unsigned char ctrl_zout_done;
+  volatile unsigned char ctrl_rx_done;
+
+  /* Connection between the submitted urb and ETRAX epid number */
+  __u8 epid;
+  
+  /* The rx_data_list field is used for periodic traffic, to hold
+     received data for later processing in the the complete_urb functions,
+     where the data us copied to the urb's transfer_buffer. Basically, we
+     use this intermediate storage because we don't know when it's safe to
+     reuse the transfer_buffer (FIXME?). */
+  struct list_head rx_data_list;
+
+
+  /* The interval time rounded up to closest 2^N */
+  int interval;
+
+  /* Pool of EP descriptors needed if it's a INTR transfer.
+     Amount of EPs in pool correspons to how many INTR that should
+     be inserted in TxIntrEPList (max 128, defined by MAX_INTR_INTERVAL) */
+  struct USB_EP_Desc* intr_ep_pool[128];
+
+  /* The mount of EPs allocated for this INTR URB */
+  int intr_ep_pool_length;
+
+  /* Pointer to info struct if URB is scheduled to be finished later */
+  struct urb_later_data* later_data;
+};
+
+
+/* This struct is for passing data from the top half to the bottom half irq
+   handlers */
+struct crisv10_irq_reg {
+  struct usb_hcd* hcd;
+  __u32 r_usb_epid_attn;
+  __u8 r_usb_status;
+  __u16 r_usb_rh_port_status_1;
+  __u16 r_usb_rh_port_status_2;
+  __u32 r_usb_irq_mask_read;
+  __u32 r_usb_fm_number;
+  struct work_struct usb_bh;
+};
+
+
+/* This struct is for passing data from the isoc top half to the isoc bottom
+   half. */
+struct crisv10_isoc_complete_data {
+  struct usb_hcd *hcd;
+  struct urb *urb;
+  struct work_struct usb_bh;
+};
+
+/* Entry item for URB lists for each endpint */
+typedef struct urb_entry
+{
+	struct urb *urb;
+	struct list_head list;
+} urb_entry_t;
+
+/* ---------------------------------------------------------------------------
+   Virtual Root HUB
+   ------------------------------------------------------------------------- */
+/* destination of request */
+#define RH_INTERFACE               0x01
+#define RH_ENDPOINT                0x02
+#define RH_OTHER                   0x03
+
+#define RH_CLASS                   0x20
+#define RH_VENDOR                  0x40
+
+/* Requests: bRequest << 8 | bmRequestType */
+#define RH_GET_STATUS           0x0080
+#define RH_CLEAR_FEATURE        0x0100
+#define RH_SET_FEATURE          0x0300
+#define RH_SET_ADDRESS		0x0500
+#define RH_GET_DESCRIPTOR	0x0680
+#define RH_SET_DESCRIPTOR       0x0700
+#define RH_GET_CONFIGURATION	0x0880
+#define RH_SET_CONFIGURATION	0x0900
+#define RH_GET_STATE            0x0280
+#define RH_GET_INTERFACE        0x0A80
+#define RH_SET_INTERFACE        0x0B00
+#define RH_SYNC_FRAME           0x0C80
+/* Our Vendor Specific Request */
+#define RH_SET_EP               0x2000
+
+
+/* Hub port features */
+#define RH_PORT_CONNECTION         0x00
+#define RH_PORT_ENABLE             0x01
+#define RH_PORT_SUSPEND            0x02
+#define RH_PORT_OVER_CURRENT       0x03
+#define RH_PORT_RESET              0x04
+#define RH_PORT_POWER              0x08
+#define RH_PORT_LOW_SPEED          0x09
+#define RH_C_PORT_CONNECTION       0x10
+#define RH_C_PORT_ENABLE           0x11
+#define RH_C_PORT_SUSPEND          0x12
+#define RH_C_PORT_OVER_CURRENT     0x13
+#define RH_C_PORT_RESET            0x14
+
+/* Hub features */
+#define RH_C_HUB_LOCAL_POWER       0x00
+#define RH_C_HUB_OVER_CURRENT      0x01
+
+#define RH_DEVICE_REMOTE_WAKEUP    0x00
+#define RH_ENDPOINT_STALL          0x01
+
+/* Our Vendor Specific feature */
+#define RH_REMOVE_EP               0x00
+
+
+#define RH_ACK                     0x01
+#define RH_REQ_ERR                 -1
+#define RH_NACK                    0x00
+
+/* Field definitions for */
+
+#define USB_IN_command__eol__BITNR      0 /* command macros */
+#define USB_IN_command__eol__WIDTH      1
+#define USB_IN_command__eol__no         0
+#define USB_IN_command__eol__yes        1
+
+#define USB_IN_command__intr__BITNR     3
+#define USB_IN_command__intr__WIDTH     1
+#define USB_IN_command__intr__no        0
+#define USB_IN_command__intr__yes       1
+
+#define USB_IN_status__eop__BITNR       1 /* status macros. */
+#define USB_IN_status__eop__WIDTH       1
+#define USB_IN_status__eop__no          0
+#define USB_IN_status__eop__yes         1
+
+#define USB_IN_status__eot__BITNR       5
+#define USB_IN_status__eot__WIDTH       1
+#define USB_IN_status__eot__no          0
+#define USB_IN_status__eot__yes         1
+
+#define USB_IN_status__error__BITNR     6
+#define USB_IN_status__error__WIDTH     1
+#define USB_IN_status__error__no        0
+#define USB_IN_status__error__yes       1
+
+#define USB_IN_status__nodata__BITNR    7
+#define USB_IN_status__nodata__WIDTH    1
+#define USB_IN_status__nodata__no       0
+#define USB_IN_status__nodata__yes      1
+
+#define USB_IN_status__epid__BITNR      8
+#define USB_IN_status__epid__WIDTH      5
+
+#define USB_EP_command__eol__BITNR      0
+#define USB_EP_command__eol__WIDTH      1
+#define USB_EP_command__eol__no         0
+#define USB_EP_command__eol__yes        1
+
+#define USB_EP_command__eof__BITNR      1
+#define USB_EP_command__eof__WIDTH      1
+#define USB_EP_command__eof__no         0
+#define USB_EP_command__eof__yes        1
+
+#define USB_EP_command__intr__BITNR     3
+#define USB_EP_command__intr__WIDTH     1
+#define USB_EP_command__intr__no        0
+#define USB_EP_command__intr__yes       1
+
+#define USB_EP_command__enable__BITNR   4
+#define USB_EP_command__enable__WIDTH   1
+#define USB_EP_command__enable__no      0
+#define USB_EP_command__enable__yes     1
+
+#define USB_EP_command__hw_valid__BITNR 5
+#define USB_EP_command__hw_valid__WIDTH 1
+#define USB_EP_command__hw_valid__no    0
+#define USB_EP_command__hw_valid__yes   1
+
+#define USB_EP_command__epid__BITNR     8
+#define USB_EP_command__epid__WIDTH     5
+
+#define USB_SB_command__eol__BITNR      0 /* command macros. */
+#define USB_SB_command__eol__WIDTH      1
+#define USB_SB_command__eol__no         0
+#define USB_SB_command__eol__yes        1
+
+#define USB_SB_command__eot__BITNR      1
+#define USB_SB_command__eot__WIDTH      1
+#define USB_SB_command__eot__no         0
+#define USB_SB_command__eot__yes        1
+
+#define USB_SB_command__intr__BITNR     3
+#define USB_SB_command__intr__WIDTH     1
+#define USB_SB_command__intr__no        0
+#define USB_SB_command__intr__yes       1
+
+#define USB_SB_command__tt__BITNR       4
+#define USB_SB_command__tt__WIDTH       2
+#define USB_SB_command__tt__zout        0
+#define USB_SB_command__tt__in          1
+#define USB_SB_command__tt__out         2
+#define USB_SB_command__tt__setup       3
+
+
+#define USB_SB_command__rem__BITNR      8
+#define USB_SB_command__rem__WIDTH      6
+
+#define USB_SB_command__full__BITNR     6
+#define USB_SB_command__full__WIDTH     1
+#define USB_SB_command__full__no        0
+#define USB_SB_command__full__yes       1
+
+#endif
diff -Nur linux-2.6.39.orig/drivers/usb/host/Makefile linux-2.6.39/drivers/usb/host/Makefile
--- linux-2.6.39.orig/drivers/usb/host/Makefile	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/drivers/usb/host/Makefile	2011-07-28 16:16:37.863421513 +0200
@@ -32,6 +32,7 @@
 obj-$(CONFIG_USB_R8A66597_HCD)	+= r8a66597-hcd.o
 obj-$(CONFIG_USB_ISP1760_HCD)	+= isp1760.o
 obj-$(CONFIG_USB_HWA_HCD)	+= hwa-hc.o
+obj-$(CONFIG_ETRAX_USB_HOST)	+= hc-crisv10.o
 obj-$(CONFIG_USB_IMX21_HCD)	+= imx21-hcd.o
 obj-$(CONFIG_USB_FSL_MPH_DR_OF)	+= fsl-mph-dr-of.o
 obj-$(CONFIG_USB_OCTEON2_COMMON) += octeon2-common.o
diff -Nur linux-2.6.39.orig/drivers/usb/Makefile linux-2.6.39/drivers/usb/Makefile
--- linux-2.6.39.orig/drivers/usb/Makefile	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/drivers/usb/Makefile	2011-07-28 16:16:37.993659487 +0200
@@ -21,6 +21,7 @@
 obj-$(CONFIG_USB_R8A66597_HCD)	+= host/
 obj-$(CONFIG_USB_HWA_HCD)	+= host/
 obj-$(CONFIG_USB_ISP1760_HCD)	+= host/
+obj-$(CONFIG_ETRAX_USB_HOST)	+= host/
 obj-$(CONFIG_USB_IMX21_HCD)	+= host/
 
 obj-$(CONFIG_USB_C67X00_HCD)	+= c67x00/
diff -Nur linux-2.6.39.orig/lib/klist.c linux-2.6.39/lib/klist.c
--- linux-2.6.39.orig/lib/klist.c	2011-05-19 06:06:34.000000000 +0200
+++ linux-2.6.39/lib/klist.c	2011-07-28 16:16:38.103425277 +0200
@@ -60,7 +60,7 @@
 {
 	knode->n_klist = klist;
 	/* no knode deserves to start its life dead */
-	WARN_ON(knode_dead(knode));
+	//WARN_ON(knode_dead(knode));
 }
 
 static void knode_kill(struct klist_node *knode)
